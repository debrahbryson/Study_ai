[
  {
    "subject": "books",
    "text": "\u2022Atwo-port network (four-terminals network ) is an electrical network (circuit) or device with two pairs of terminals to connect to \u2022Two terminals constitute a port if the currents applied to them satisfy the \u2751theelectric current entering one terminal must equal to the current emerging from the other terminal on the same port."
  },
  {
    "subject": "books",
    "text": "\u2751the points where signals are applied or outputs are taken. \u2022In a two -port network, often port 1 is considered the input port and port \u2022The two -port network model is used in mathematical circuit analysis techniques to isolate portions of larger circuits."
  },
  {
    "subject": "books",
    "text": "\u2022A two -port network is regarded as a \"black box\" with its properties \u2751The response of the network to signals applied to the ports can be calculated easily, without solving for all the internal voltages and \u2751It also allows similar circuits or devices to be compared easily ."
  },
  {
    "subject": "books",
    "text": "\u2022Anylinear circuit with four terminals can be regarded as a two -port network provided that it does not contain an independent source and \u2022Examples of circuits analyzed as two -ports are filters, matching networks, transmission lines, transformers, and small -signal models for \u2022In two -port mathematical models, the network is described by a 2 by 2 \u2022The common models that are used are referred to as z-parameters ,  y- parameters ,h-parameters ,g-parameters , and ABCD -parameters ."
  },
  {
    "subject": "books",
    "text": "\u2022These are usually expressed in matrix notation, and they establish relations Detemine the Z parameter matrix of the port networks below."
  },
  {
    "subject": "books",
    "text": "CHINNA RAO, Mr E.MAHENDAR REDDY Mr V SHIVA RAJKUMA R, MR KLN PRASAD, MR M ANANTHA GUPTHA, This is a fundamental course, basic knowledge of which is required by all the circuit branch engineers 1. To familiarize the student with the principal of operat ion, analysis and design of junction diode .BJT and FET transistors and amplifier circuits."
  },
  {
    "subject": "books",
    "text": "Understand and Analyse the different types of diodes, operation and its characteristics 2. Design and analyse the DC bias circuitry of BJT and FET 3. Design biasing circuits using diodes and transistors. 4. To analyze and design diode application circuit s, amplifier circuits and oscillators employing BJT, Insulator : An insulator is a material that offers a very low level  (or negligible) of conductivity when voltage is applied."
  },
  {
    "subject": "books",
    "text": "Eg: Paper, Mica,  glass, quartz. Typical resistivity level of an insulator is of the order of a mater ial defines the band of energy levels that an electron can occupy. Valance band is the range of electron energy where the electron remain bended too the atom and do not contribute to the electric current."
  },
  {
    "subject": "books",
    "text": "Conduction bend is the range of electron energies higher than valance band where electrons are free to accelerate under the influence of external voltage source resulting in the flow of The energy ban d between the valance band and conduction band is called as forbidden band gap."
  },
  {
    "subject": "books",
    "text": "It is the energy required by an electron to move from balance band to conduction band i.e. the energy required for a valance electron to become a free electron. Because of this large gap there a very few electrons in the CB and hence the conductivity of insulator is poor."
  },
  {
    "subject": "books",
    "text": "Even an increase in temperature or app lied electric field is insufficient to transfer electrons from Conductors: A conductor is a material which supports a generous flow of charge when a voltage is applied across its terminals. i.e. it has very high conductivity."
  },
  {
    "subject": "books",
    "text": "Eg: Copper, Aluminum, Silver, Gold.  The resistivity of a conductor i s in the order of 10-4 and 10-6 \u2126-cm.  The Valance and conduction bands band. This implies that there are free electrons in CB even at absolute zero temperature (0K)."
  },
  {
    "subject": "books",
    "text": "Therefore at room t emperature when electric field is applied large current flows through the Semiconductor : A semiconductor is a material that has its conductivity somewhere between the insulator and conductor.  The resistivity level is in the range of 10 and 104 \u2126-cm."
  },
  {
    "subject": "books",
    "text": "Two of the most commonly used are Silicon (Si =14 atomic no. ) and germanium (Ge =32 atomic no. ). Both have 4 valance electrons. The forbidden band gap is in the order of 1eV. For eg., the band gap energy for Si, Ge and temperatures, the valance band electrons do not have sufficient energy to move from V to CB."
  },
  {
    "subject": "books",
    "text": "Thus semiconductors act a insulators at 0K. as the temperature increases, a large number of valanc e electrons acquire sufficient energy to leave the VB, cross the forbidden bandgap and reach CB. These are now free electrons as they can move freely under the influence of electric field."
  },
  {
    "subject": "books",
    "text": "At room temperature there are sufficient electrons in the CB and he nce the semiconductor is capable of Inversely related to the conductivity of a material is its resistance to the flow of charge or current. Typical resistivity values for various materials\u2019 are given as follows ."
  },
  {
    "subject": "books",
    "text": "A pure form of semiconductors is called as intrinsic semiconductor. Conduction in intrinsic sc is either due to thermal excitation  or crystal defects. Si and Ge are the two most important semiconductors used. Other examples include Gallium arsenide GaAs, Indium Antimonide (InSb) etc."
  },
  {
    "subject": "books",
    "text": "Let us consider the structure of Si.  A Si atomic no. is 14 and it has 4 valance electrons. These 4 electrons are shared by four neighboring atoms in the crystal structure by means of covalent bond. Fig. conductivity (due to lack of free electrons) at l ow or absolute zero temperature."
  },
  {
    "subject": "books",
    "text": "At room temperature some of the covalent bonds break up to thermal  energy as shown in fig The absence of electrons in covalent bond  is represented by a small circle usually referred  to as hole which is of positive charge. Even a hole serves as carrier of electricity in a manner similar  to that The mechanism by which a hole contributes to conductivity is explained as  follows: When a bond is in complete so that a hole exists, it is relatively easy for a valance electron  in the neighboring  atom to leave its  covalent bond to fill this hole."
  },
  {
    "subject": "books",
    "text": "Here  we have a mechanism for conductio n of opposite to that of motion of electron. Hence we consider holes as physical entities whose movement In a pure semiconductor, the number of holes is equal to t he number of free electrons."
  },
  {
    "subject": "books",
    "text": "This process of adding impurities is called as doping. The amount of impurity added is 1 part in 106 atom s. N type semiconductor: If the added impurity is a pentavalent atom then the resultant semiconductor is called N -type semiconductor."
  },
  {
    "subject": "books",
    "text": "Examples of pentavalent impurities are Phosphorus, Arsenic, Bismuth, semiconductor material where four out of five valance electrons  of the impurity atom(antimony)  forms covalent bond with the four  intrinsic semiconductor  atoms. The fifth electron is loosely bou nd to the impurity atom."
  },
  {
    "subject": "books",
    "text": "This loosely bound electron can be easily Excited from  the valance band to the conduction band by the appl ication of electric field or increasing the thermal energy. The energy required to detach the fifth electron form the impurity atom is very The effect of doping creates a discrete energy level called  donor energy level in the forbidden band energy levels of the conducting  band and the donor energy level is the energy required to free the fifth from the donor impurity atom are raised to conduction band and hence the number of electrons in the conduction band increases significantly."
  },
  {
    "subject": "books",
    "text": "Thus  every antim ony atom contributes  to one conduction In the N -type sc the no.  of electrons increases and the no. of holes decreases  compared to those available in an intrinsic sc. The reason for decrease in the no. of holes is that the  larger no."
  },
  {
    "subject": "books",
    "text": "of electrons present increases the recombination of electrons with holes. Thus current in N type sc is dominated by electrons which are referred  to as majority carriers. Holes are the minority carriers in N type sc P type semiconductor: If the added impurity is a trivalent atom then the resultant semiconductor is called P -type semiconductor."
  },
  {
    "subject": "books",
    "text": "Examples of trivalent impurities are Boron, Gallium , indium etc. The crystal structure of   p type sc is shown in the fig1. 5a. The three valance electrons  of the impurity (boon) forms three covalent bonds with the neighboring atoms and a vacancy exists in the fourth bond giving rise to the holes."
  },
  {
    "subject": "books",
    "text": "The hole is ready to accept an electron from the neighboring atoms. Each trivalent atom contributes to one hole generation and thus introduces a large no. of holes in the valance band. At the same time the no. electrons are decreased compared to those available in intrinsic sc because of increased recombination due to creation of additional holes."
  },
  {
    "subject": "books",
    "text": "Thus in P type sc , holes are majority carriers and electrons are minority carriers. Since each trivalent impurity atoms  are capable accepting an electron,  these are  called as acceptor atoms . The \uf0b7 The conductivity of N type sc is greater than that of P type sc as the mobility of electron is \uf0b7 For the same level of doping in N type sc and P type sc, the conductivity of an Ntype sc is In a pure sc, the no."
  },
  {
    "subject": "books",
    "text": "of holes is equal to the no. of electrons. Thermal agitation co ntinue to produce new electron - hole pairs and the electron hole pairs disappear because of recombination. w ith each electron hole pair created , two charge carrying particles are formed ."
  },
  {
    "subject": "books",
    "text": "One is negative which is a free electron with mobility  \u00b5 n . The ot her is a positive i.e., hole with mobility \u00b5 p . The electrons and hole move  in opppsitte direction in a an electric field E, but since they are of opposite sign, the current due to each is in the same direction."
  },
  {
    "subject": "books",
    "text": "Hence the total current density  J within the  intrinsic sc is given by Where n=no. of electrons / unit volume i.e., concentration of free electrons P= no. of holes / unit volume i.e., concentration of holes Hence, \u03c2 is the conductivity o f sc which is equal to (n \u00b5 n + p \u00b5 p)q."
  },
  {
    "subject": "books",
    "text": "he resistivity of sc is reciprocal It is evident from the above equation that current density with in a sc is directly proportional to For pure sc, n=p=  ni where ni = intrinsic concentration. The value of n i  is given by Hence conductivity in intrinsic sc is   \u03c2i= n i ( \u00b5n +  \u00b5 p) q Intrinsic conductivity increases at the rate of 5% per o C for Ge and 7% per o C for Si."
  },
  {
    "subject": "books",
    "text": "Conductivity in extrinsic sc (N Type  and P Type): The conductivity of intrinsic sc is given by \u03c2i= n i ( \u00b5n +  \u00b5 p) q = (n \u00b5 n + p \u00b5 p)q Under thermal equilibrium for any semiconductor, the product of the no."
  },
  {
    "subject": "books",
    "text": "of holes and the concentration of electrons is constant and is independent of amount of donor and acceptor impurity Hence  in N type sc , as the no. of electrons  increase the no. of holes decreases. Similarly in P type as the no."
  },
  {
    "subject": "books",
    "text": "of holes increases the no. of electrons  decreases. Thus the prod uct is constant and is equal to n i2 in case of intrinsic as well as extrinsic sc. The law of mass action has given the relationship between free electrons concentration and hole concentration."
  },
  {
    "subject": "books",
    "text": "These concentrations are further related by the law of electric al neutrality as Sc materials are electrically neutral. According to the law of electrical neutrality, in an electrically neutral material, the magnitude of positive charge concentration is equal to tat of negative charge concentration."
  },
  {
    "subject": "books",
    "text": "Let us consider  a sc that has N D donor  atoms per cubic centimeter and N A acceptor atoms  per cubic centimeter i.e ., the concentration  of donor and acceptor atoms are N D and NA respectively.  Therefore N D positively charged ions per cubic centimeter are contributed by donor atoms and N A negatively charged ions per cubic centimeter are contributed by the acceptor atoms."
  },
  {
    "subject": "books",
    "text": "Let n, p is concentration of free electrons and holes respectively. Then according to the law of neutrality Hence for N type sc the free electron concentration is approximately equal to the concentration of donor atoms. In later applicatio ns since some confusion may arise as to which type of sc is under consideration a the given moment, the subscript n or p  is added for Ntype or P type respectively."
  },
  {
    "subject": "books",
    "text": "Therefore current density in N type sc is J = N D \u00b5n q E For P type sc, N D = 0 and p>>n. Therefore N A \u2248 p Hence for P type sc the hole concentration is approximately equal to the concentration of Therefore current density in N type sc is J  = N A \u00b5p q E In a piece of sc, if one half is doped by p type impurity and the other half is dope d by n type impurity, a PN junction is formed."
  },
  {
    "subject": "books",
    "text": "The plane dividing the two halves or zones is called PN junction . As shown in t he fig the n type  material has high  concentration of free electrons, while p type material has high concentration of holes.  Therefore at the junction there is  a tendency of free electrons to diffuse over to the P side and the holes to the N side."
  },
  {
    "subject": "books",
    "text": "This proc ess is called  diffusion. As the free electrons move across the junction from N  type to P type, the donor a toms become positively charged. Hence  a positive charge is built  on the N -side of the junction. The  free electrons  that cross  the junction uncover the negative acceptor ions by filing the holes."
  },
  {
    "subject": "books",
    "text": "Therefore a negative  charge  is developed on the p \u2013side of the junction.. This net negative charge on the p side prevents further diffusion of electrons into the p side.  Similarly the net positive charge on the N  side repels the hole crossing from p side to N side."
  },
  {
    "subject": "books",
    "text": "Thus a barrier sis set up near the junction which prevents the further movement of charge carriers i.e. electrons and holes. As a consequence of induced electric field across the depletion layer, an electrostatic potential difference is established between P and N regions, which are  called the potential barrier, junction barrier, diffusion potential or contact potential, Vo."
  },
  {
    "subject": "books",
    "text": "The majority holes diffusing out of the P region leave behind negatively charged acceptor atoms bound to the lattice , thus exposing a  negatives  pace charge in a previously neutral region . Similarly ele ctrons diffusing from the N region expose positively  ionized It is noticed that the space charge layers are of opposite sign to the majority carriers diffusing into them, which tends to reduce the diffusion rate."
  },
  {
    "subject": "books",
    "text": "Thus the double space of the layer causes an electric field to be set up across the junction directed from N to P regions, which is in such a direction density, \u03c1, depends upon how diode id doped. Thus the junction region is depleted of mobile charge carriers."
  },
  {
    "subject": "books",
    "text": "Hence it is called depletion layer, space region, and transition region. The depletion region is current flows across the junction and the system is in equilibrium. To the left of this depletion layer, the carr ier concentration is p= N A and to its right it is n= N D."
  },
  {
    "subject": "books",
    "text": "When a diode is connected in a Forward Bias  condition, a negative voltage is applied to the N - type material and a positive voltage is applied to the P -type material. If this external voltage becomes the potential barriers opposition will be overcome and current will star t to flow."
  },
  {
    "subject": "books",
    "text": "This is because the negative voltage pushes or repels electrons towards the junction giving them the energy to cross over and combine with the holes being pushed in the opposite direction towards the junction by the positive voltage. This result s in a characteristics curve of zero current flowing up to this voltage point, called the \"knee\" on the static curves and then a high current flow through the diode with little Forward Characteristics Curve for a Junction Diode The application of a forward biasing voltage on the junction diode results in the depletion layer becoming very thin and narrow which represents a low impedance path through the junction there by allowing high currents to flow."
  },
  {
    "subject": "books",
    "text": "The point at which this sudden increase in current takes place is represented on the static I -V characteristics curve above as the \"knee\" point. Forward Biased Junction Diode showing a Reduction in the Depletion Layer This condition represents the low resistance path through the PN junction allowing very large currents to flow through the diode with only a small increase in bias voltage."
  },
  {
    "subject": "books",
    "text": "The actual potential difference \"infinite\" current above this knee point as it effectively becomes a short circ uit, therefore resistors are used in series with the diode to limit its current flow. Exceeding its maximum forward current specification causes the device to dissipate more power in the form of heat than it was designed for When a diode is connected in a Reverse Bias  condition, a positive voltage is applied to the N -type material and a negative voltage is applied to the P -type mate rial."
  },
  {
    "subject": "books",
    "text": "The positive voltage applied to the N - type material attracts electrons towards the positive electrode and away from the junction, while the holes in the P -type end are also attracted away from the junction towards the negative electrode. The net resu lt is that the depletion layer grows wider due to a lack of electrons and holes and presents a high impedance path, almost an insulator."
  },
  {
    "subject": "books",
    "text": "The result is that a high potential barrier is created thus preventing current from flowing through the semiconductor m aterial. Reverse Biased Junction Diode showing an Increase in the Depletion This condition represents a high resistance value to the PN junction and practically zero current flows through the junction diode with an increas e in bias voltage."
  },
  {
    "subject": "books",
    "text": "However, a very small leakage current does flow through the junction which can be measured in microamperes, ( \u03bcA). One final point, if the reverse bias voltage Vr applied to the diode is increased to a sufficiently high enough value, it will cause the PN junction to overheat and fail due to the avalanche effect around the junction."
  },
  {
    "subject": "books",
    "text": "This may cause the diode to beco me shorted and will result in the flow of maximum circuit current, and this shown as a step downward slope in the reverse static characteristics curve below. Reverse Characteristics Curve for a Junction Diode Some times this avalanche effect has practical applications in voltage stabilizing  circuits where a series limiting resistor is used with the diode to limit this reverse breakdown current to a preset maximum value thereby producing a fixed voltage output across  the diode."
  },
  {
    "subject": "books",
    "text": "These types of diodes are commonly Diode terminal characteristics  equation  for diode junction  current: Io _ temperature -dependent saturation current, \u00b5A Temperature can have a marked effect on the characteristics of a silicon semiconductor diode as shown in Fig. 11  It has been fo und experimentally that the reverse saturation current Io will  just about double in magnitude for every 10\u00b0C increase in temperature."
  },
  {
    "subject": "books",
    "text": "It is not uncommon for a germanium diode with an Io in the order of 1 or 2 A at 25\u00b0C to have a  leakage that of germanium for similar power and current levels. The result is that even  at high temperatur es the levels of Io for silicon diodes do not reach the same high levels obtained ."
  },
  {
    "subject": "books",
    "text": "For germanium \u2014a very important reason that silicon devices enjoy a significantly higher level of  development and utilization in design. Fundamentally, the open -circuit equiv alent in the reverse  bias region is better realized at any temperature with silicon than with germanium."
  },
  {
    "subject": "books",
    "text": "Since ohmmeters typically employ a relatively constant -current  source, the resistance determined will be at a preset current level (typically, a few mill amperes). It is obvious from Eq. 1. 3 that the dc resistance of a diode is independent of the shape o f the characteristic in the region surrounding the point of interest."
  },
  {
    "subject": "books",
    "text": "If a sinusoidal rather than dc input is applied, the situation will change completely. The varying input will move the instantaneous  operating point up and down a region of the character istics and thus defines a specific change in  current and point appearing on Fig."
  },
  {
    "subject": "books",
    "text": "1. 13 determined by the applied dc levels. The  designation Q-point is deriv ed from the word quiescent, which means \u201cstill or unvarying.\u201d  A straight -line drawn tangent to the curve through the Q-point as shown in Fig. 1. 13 will define a  particular change in voltage and current that can be used to determine the ac or dynamic  resis tance for this region of the diode characteristics."
  },
  {
    "subject": "books",
    "text": "In An equivalent circuit is a combination of elements properly chosen to best represent the actua l terminal characteristics of a device, system, or such in a particular operating region. In other  words, once the equivalent circuit is defined, the device symbol can be removed from a  schematic and the equivalent circuit inserted in its place without sev erely affecting the actual  behavior  of the system."
  },
  {
    "subject": "books",
    "text": "The result is often a network that can be solved using traditional circuit analysis techniques. One technique for obtaining an equivalent circuit for a diode is to appr oximate the the straight -line segments do  not result in an exact duplication of the actual characteristics,  especially in the knee region."
  },
  {
    "subject": "books",
    "text": "However, the resulting segments are sufficiently close to the actual  curve to establish an equivalent circuit that will provide an excellent first approximati on to the  actual behaviour of the device. The ideal diode is included to establish that there is only one  direction of conduction through the device, and a reverse -bias condition will result in the open - circuit state for the device."
  },
  {
    "subject": "books",
    "text": "When conduction is established, the resistance of the diode will b e the specified  value of rav. The approximate level of rav can usually be determined from a specified operating point on the specificatio n sheet. For instance, for a silicon semiconductor diode, if IF _ 10 mA (a forward  conduction Electronic devices are inherently sensitive to very high frequencies."
  },
  {
    "subject": "books",
    "text": "Most shunt capacitive effects that can be ignored at lower frequencies because the reactance XC=1/2\u03c0fC is very large  (open - circuit equivalent). This, however, cannot be ignored at very high frequencies. XC will become sufficiently small due to the high value of f to introduce a low -reactance \u201cshorting\u201d path."
  },
  {
    "subject": "books",
    "text": "In the p-n semiconductor diod e, there are two capacitive effects to be considered. In the reverse -bias region we have the transition - or depletion region capacitance (CT), while in the forward -bias region we have the diffusion (CD) or storage capacitance."
  },
  {
    "subject": "books",
    "text": "Recall that the basic equatio n for  the capacitance of a parallel - plate capacitor is defined by C=\u20acA/d, where \u20ac is the permittivity of  the dielectric (insulator) between the plates of area A separated by a distance d. In the reverse -, bias region there is a depletion region (free of carriers) that behaves essentially like an insulator  between the lay ers of opposite charge."
  },
  {
    "subject": "books",
    "text": "Since capacitance will decrease. The fact that the  capacitance is dependent on the applied reverse -bias potential has application in a number of  electronic systems. Although the effect described above will also be present in the forward -bias region, it is over shadowed by a capacitance effect directly dependent on the rate at which charge  is injected into the regions just outside the  depletion region."
  },
  {
    "subject": "books",
    "text": "The capacitive effects described  above are represented by a capacitor in parallel with the ideal diode, capacitor is  normally not incl uded in the diode symbol. Diode capacitances:  The diode exhibits two types of capacitances transition capacitance and diffusion \uf0d8 Transition c apacitance: The capacitance which appears between positive ion layer in n -region \uf0d8 Diffusion capacitance: This capacitance originates due to diffusion of charge carriers in the The transition capacitan ce is very small as compared to the diffusion capacitance."
  },
  {
    "subject": "books",
    "text": "In reverse bias transition, the capacitance is the dominant and is given by: In forward bias, the diffusion capacitance is the dominant and is given by: The diffusion capacitance at low frequencies is given by the formula: The diffusion capacitan ce at high frequencies is inversely proportional to the frequency and is given by Note: The variation of diffusion capacitance with applied voltage is used in the design of varactor."
  },
  {
    "subject": "books",
    "text": "When an ordinary P-N junction diode  is reverse biased, normally only very  small reverse saturation current flows. This current is due to mo vement of minority carriers. It is almost independent of the voltage applied. However, if the reverse bias is increased, a point is reached when the junction breaks down and the reverse current increases abruptly."
  },
  {
    "subject": "books",
    "text": "This current could be large enough to dest roy the junction. If the reverse current is limited by means of a suitable series resistor, the power dissipation at the junction will not be excessive, and the device may be operated continuously in its breakdown region to its normal (reverse saturation) level."
  },
  {
    "subject": "books",
    "text": "It is found that for a suitably designed diode, the breakdown voltage is very stable over a wide range of reverse currents. This quality gives the breakdown  diode  many useful applications as a voltage reference source. The critical value of the volt age, at which the breakdown of a P -N junction diode occurs,  is called the breakdown voltage."
  },
  {
    "subject": "books",
    "text": "The breakdown voltage depends on the width of the depletion region, which, in turn, depends on the doping level. The junction offers almost zero resistance at the breakdown point. There are two mechanisms by which breakdown can occur at a  reverse biased P -N junction: The minority carriers, under reverse biased conditions, flowing through the junction a cquire a kinetic energy which increases with the increase in reverse voltage."
  },
  {
    "subject": "books",
    "text": "This phenomenon is called the avalanche breakdown . The bre akdown region is the  knee of the characteristic curve. Now the current is not controlled by the junction voltage Under a very high reverse voltage, the depletion region expands and the potential barrier increases leading to a very high electric field across the junction."
  },
  {
    "subject": "books",
    "text": "The electric field will break some of the covalent bonds of the semiconductor atoms leading to a large number of free minority carriers, which suddenly increase the reverse current. This is called the Zener effect. The breakdown occurs at a particular and constant value of reverse voltage called the breakdown voltage, it is found that Zener breakdown occurs at electric field intensity of about 3 x 107 V/m."
  },
  {
    "subject": "books",
    "text": "Either of the two (Zener breakdown or avalanche breakdown) may occur independently, or both of these may occur simultaneously. Diode junctions that breakdown below 5 V are caused by Zener effect. Junctions that experience breakdown abov e 5 V are caused by ava lanche effect."
  },
  {
    "subject": "books",
    "text": "Junctions that breakdown around 5 V are usually caused by combination of two effects. The Zener breakdown occurs in heavily doped junctions (P -type semiconductor mod erately doped and N -type heavily doped), which prod uce narrow depletion layers. The ava lanche breakdown occurs in lightly doped junctions, which produce wide depletion layers."
  },
  {
    "subject": "books",
    "text": "With the increase in junction temperature Zener breakdown voltage is reduced while the avalanche breakdown voltage increases. The Zener diodes have a negative tempera ture coefficient while avalanche diodes have a positive temperature coefficient. Diodes that have breakdown voltages around 5 V have zero temperature coefficient."
  },
  {
    "subject": "books",
    "text": "The breakdown phenomenon is reversible and harmless so l ong as the safe operating temperature is maintained. The Zener diode  is like a general -purpose signal diode consisting of a silicon PN junction. When biased in the forward direction it behaves just like a normal signal diode passing the ra ted current, but as soon as a reverse voltage applied across the zener diode exceeds the rated voltage of the device, the diodes breakdown voltage VB is reached at which point a process called Avalanche Breakdown  occurs in the semiconductor depletion layer  and a current starts to flow through the diode to limit this increase in The current now flowing through the zener diode increases dramatically to the maximum circuit value (which is usually limited by a series resistor) and once achieved  this re verse saturation current remains fairly constant over a wide range of applied voltages."
  },
  {
    "subject": "books",
    "text": "This breakdown voltage point, VB is called the \"zener voltage\" for zener diodes and can range from less than one volt to hundreds of volts. The point at which the zener  voltage triggers the current to flow through the diode can be very accurately controlled (to less than 1% tolerance) in the doping stage of the diodes semiconductor zener breakdown voltage on the I -V curve is almost a vertical straight line."
  },
  {
    "subject": "books",
    "text": "The Zener Diode  is used in its \"reverse bias\" or reverse breakdown mode, i.e. the diodes anode connects to the negative supply. From the I -V characteristics curve above, we can see that the zener diode has a region in its reverse bias characteristics of  almost a constant negative voltage regardless of the value of the current flowing through the diode and remains nearly constant even with large changes in current as long as the zener diodes current remains between the breakdown current IZ(min) This ability to control itself can be used to great effect to regulate or stabilize  a voltage source against supply or load variations."
  },
  {
    "subject": "books",
    "text": "The fact that the voltage across the diode in the breakdown region is almost constant turn s out to be an important application of the zener diode as a voltage regulator. The function of a regulator is to provide a constant output voltage to a load connected in parallel with it in spite of the ripples in the supply voltage or the variation in th e load current and the zener diode will continue to regulate the voltage until the diodes current falls below the minimum IZ(min)  value in the A tunnel diode  or Esaki diode  is a type of semiconductor diode which is capable of very fast operation, well into the microwave frequency region, by using quantum mechanical effects."
  },
  {
    "subject": "books",
    "text": "The heavy doping results in a broken bandgap, where conduction band electron states on the n -side are more or less aligned with valence band hole states on the p -side. Tunnel  diodes were manufactured by Sony for the first time in 1957 followed by G eneral Electric and other companies from about 1960, and are still made in low volume today."
  },
  {
    "subject": "books",
    "text": "Tunnel diodes are usually made from germanium, but can also be made in gallium arsenide and silicon materials. They can be used as oscillators, amplifiers, frequen cy converters In a conventional semiconductor diode, conduction takes place while the p \u2013n junction is forward biased and blocks current flow when the junction is reverse biased."
  },
  {
    "subject": "books",
    "text": "This occurs up to a point known as the \u201cr everse breakdown voltage\u201d when conduction begins (often accompanied by destruction of the device). In the tunnel diode, the dopant concentration in the p and n layers are increased to the point where the reverse breakdown voltage  becomes zero  and the diode  conducts in the reverse direction."
  },
  {
    "subject": "books",
    "text": "However, when forward -biased, an odd effect occurs called \u201cquantum mechanical tunnelling\u201d which gives rise to a region where an increase  in forward voltage is accompanied by a decrease  in forward current. This negative r esistance region can be exploited in a solid state version of the dynatron oscillator which normally uses  a tetrode  thermionic valve (or tube)."
  },
  {
    "subject": "books",
    "text": "As voltage increases further these states become more misaligned and the current drops  \u2013 this is called negative resistance  because current decreases with increasing voltage. As voltage increases yet further, the diode begins to operate as a no rmal diode, where electrons travel by conduction across the p \u2013n junction, and no longer by tunneling through the p \u2013n junction barrier."
  },
  {
    "subject": "books",
    "text": "Thus the most important operating region for a tunnel diode is the negative resistance region. Whe n used in the reverse direction they are called back diodes  and can act as fast rectifiers with zero offset voltage and extreme linearity for power signals (they have an accurate square law characteristic Under reverse bias fille d states on the p -side become increasingly aligned with empty states on the n - side and electrons now tunnel through the pn junction barrier in reverse direction  \u2013 this is the Zener A rough approximation of the VI curve for a tunnel diode, showing the negative differential resistance region."
  },
  {
    "subject": "books",
    "text": "The current -voltage characteristic of the diode is represented in Figure 1 .20a . In this sketch i p and Up are the peak, and iv and Uv are the valley values for the current and voltage respectively . The form of this dependence can be qualitatively explained by considering the tunneling processes that take place in a thin p -n junction."
  },
  {
    "subject": "books",
    "text": "For the degenerated semi conductors, the energy band diagram at thermal equilibrium is presented in \uf0b7 Environmental immunity i.e. peak point is not a function of temperature. \uf0b7 High speed i.e. tunneling takes place very fast at the speed of light in the order of nanoseconds \uf0b7 Simplicity  i.e."
  },
  {
    "subject": "books",
    "text": "Varactor diode is a special type of diode which uses transition capacitance property i.e voltage variable capacitance .These are also call ed as varicap,VVC(voltage variable capacitance) or tuning diodes. The varactor diode symbol is shown below with a diagram representation. When a rever se voltage is applied to a PN junction,  the holes in the p -region are attracted to the anode terminal and electrons in the n -region are attracted to the cathode terminal creating a region where there is little current."
  },
  {
    "subject": "books",
    "text": "This  region ,the depletion region, is  essentially devoid of carriers and behaves as The depletion region increases as reverse voltage across it increases; and since capacitance varies inversely as dielectric thickness, the junction capacitance will decrease  as the voltage across the PN junction increases."
  },
  {
    "subject": "books",
    "text": "So by varying the reverse voltage across a PN junction the junction capacitance can be varied .This is shown in the typical varactor voltage -capacitance curve below. Notice the nonlinear increase in capacitance as the reverse voltage is decreased. This nonlinearity allows the varactor to be used also as a harmonic generator."
  },
  {
    "subject": "books",
    "text": "A silicon -controlled rectifier  (or semiconductor -controlled rectifier ) is a four -layer solid state  device that controls current . The name \"silicon controlled rectifier\" or SCR is General Electric 's trade name for a type of thyristor . The SCR was developed by a team of power engineers  led by Gordon Hall and commercialized by Frank W."
  },
  {
    "subject": "books",
    "text": "\"Bill\" Gutzwiller in 1957 .symbol of SCR is given below: An SCR consists of four layers of alternating P and N type semiconductor  materials. Silicon is used as the intrinsic semiconductor, to which the proper dopants  are added. The junctions are either diffused or al loyed."
  },
  {
    "subject": "books",
    "text": "The planar construction is used for low power SCRs (and all the junctions are diffused). The mesa type construction is used for high power SCRs. In this case, junction J2 is obtained by the diffusion method and then the outer two layers are alloyed  to it, since the PNPN pellet is required to handle large currents ."
  },
  {
    "subject": "books",
    "text": "It is properly braced with tungsten  or molybdenum  plates to provide greater mechanical strength. One of these plates is hard soldered to a copper  stud, which is threaded for attachment of heat sink . The doping of PNPN will depend on the application of SCR, since its characteristics are si milar to those of the thyratron ."
  },
  {
    "subject": "books",
    "text": "Today, the term thyristor applies to the larger family of multilayer devices that exhibit bistable state -change behaviour, that is, switching either ON or The operation of a SCR and other thyristors  can be understood in terms of a pair of tightly coupled bipolar junction transistors , arranged to cause the self -latching action.The following figures are construction of SCR,its two transistor model and symbol respectively region is the anode, the end N -region is the cathode and the inner P -region is the gate."
  },
  {
    "subject": "books",
    "text": "The anode to cathode is connected in series with the load circuit. Essentially the device is a switch. Ideally it remains off (voltage blocking state), or appears t o have an infinite impedance until both the anode and gate terminals have suitable positive voltages with respect to the cathode terminal."
  },
  {
    "subject": "books",
    "text": "Current can flow only in In absence of external bias voltages,  the majority carrier in each layer diffuses until there is a built -in voltage that retards further diffusion. Some majority carriers have enough energy to cross the barrier caused by the retarding electric field at each junction."
  },
  {
    "subject": "books",
    "text": "As already mentioned, the SCR is a four -layer device with three terminals, namely, the anode, the cathode and the gate. When the anode is made positive with respect to the cathode, junctions J 1 and J 3 are forward biased and junction J 2 is reverse -biased and only the leakage current will flow through the device."
  },
  {
    "subject": "books",
    "text": "The SCR is then said to be in the forward blocking state or in the forward mode or off state. But when the cathode is made positive with respect to the anode, junctions J 1 and J 3 are reverse -biased, a small reverse leakage current will flow through the SCR and the SGR is said to be in the reverse When the anode is positive with respec t to cathode i.e."
  },
  {
    "subject": "books",
    "text": "when the SCR is in forward mode, the SCR does not conduct unless the forward voltage exceeds certain value, called the forward breakover voltage, VFB0. In non -conducting state, the current through the SCR is the leakage current which is v ery small and is negligible."
  },
  {
    "subject": "books",
    "text": "If a positive gate current is supplied, the SCR can become conducting at a voltage much lesser than forward break -over voltage. The larger the gate current, lower the break -over voltage. With sufficiently large gate current, th e SCR behaves identical to PN rectifier."
  },
  {
    "subject": "books",
    "text": "Once the SCR is switched on, the forward voltage drop across it is suddenly reduced to very small value, say about 1 volt. In the conducting or on -state, the current through the SCR is limited by the external imped ance."
  },
  {
    "subject": "books",
    "text": "When the anode is negative with respect to cathode, that is when the SCR is in reverse mode or in blocking state no current flows through the SCR except very small leakage current of the order of few micro -amperes. But if the reverse voltage is incre ased beyond a certain value, called the reverse break - over voltage, V RB0 avalanche break down takes place."
  },
  {
    "subject": "books",
    "text": "Forward break -over voltage V FB0 is usually higher From the foregoing dis cussion, it can be seen that the SCR ha s two stable and reversible operating states. The change over from off -state to on -state, called turn -on, can be achieved by in creasing the forward voltage beyond VFB0."
  },
  {
    "subject": "books",
    "text": "A more con venient and useful method of turn -on the device employs the gate drive. If the forward voltage is less than the for ward break -over voltage, V FB0, it can be turned -on by applying a positive voltage between the gate and the cathode."
  },
  {
    "subject": "books",
    "text": "This method is called the gate control. An other very important feature of the gate is that once th e SCR is triggered to on -state the The switching action of gate takes place only when (i)  SCR is forward biased i.e."
  },
  {
    "subject": "books",
    "text": "anode is positive with respect to cathode, and (ii) Suitable positive voltage is applied between the gate and the cathode. Once the SCR has been switched on, it has no control on the amount of current flowing through it. The current through the SCR is entirely controlled by the external impedance connected in the circuit and the applied voltage."
  },
  {
    "subject": "books",
    "text": "This is called the holding current rating of SCR. If the current through the SCR is reduced below the level of holding current, the device returns to off -state or blocking state. The SCR can be switched off by reducing the forward  current below the level of holding current which may be done either by reducing the applied voltage or by increasing the circuit impedance."
  },
  {
    "subject": "books",
    "text": "Note : The gate can only trigger or switch -on the SCR, it cannot switch off. Alternatively the SCR can be switched off by applying negative voltage to the anode (reverse mode), Here one point is worth mentioning, the SCR takes certain time to switch off."
  },
  {
    "subject": "books",
    "text": "The time, called the turn - off time, must be allowed before forward voltage m ay be applied again otherwise the device will switch -on with forward voltage without any gate pulse. The turn -off time is about 15 micro -seconds, which is immaterial when dealing with power frequency, but this becomes important in the inverter circuits, wh ich are to operate at high frequency."
  },
  {
    "subject": "books",
    "text": "2.SCRs with high voltage and current ratings are available. 2.External circuits are required for turning it off. SCRs are mainly used in devices where the control of high power, possibly coupled with high voltage, is demanded. Their operation makes them suitable for use in medium to high -voltage AC power control applications, such as lamp dimming, regulators and motor control."
  },
  {
    "subject": "books",
    "text": "SCRs and similar devices are used for rectification of high power AC in high -voltage direct     current The photo diode is a semiconductor p -n junction device whose region of operation is limited  to the reverse biased region.The figure below shows the symbol of photodiode A photodiode is  a type of photo detector  capable of converting light  into either current  or voltage , depending upon the mode of operation."
  },
  {
    "subject": "books",
    "text": "The common, traditional solar cell  used to generate electric solar power  is a large area photodiode. A photodiode is designed to operate in reverse bias. The deletion region width is large. Under  normal conditions it carries small reverse curre nt due to minority charge carriers."
  },
  {
    "subject": "books",
    "text": "When  light is incident  through glass window on the p -n junction, photons  in the light bombard the p -n junction and some energy s imparted to the valence electrons. So  valence electrons break covalent bonds and become fr ee electrons."
  },
  {
    "subject": "books",
    "text": "Thus  more  electron -hole pairs are generated. Thus total number of minority charge carriers increases and hence reverse current increases.This is the basic When the P -N junction is reverse -biased, a reverse saturation current flows due to ther mally generated holes and electrons being swept across the junction as the minority car riers."
  },
  {
    "subject": "books",
    "text": "With the increase in temperature of the junction more and more hole -electron pairs are created and so the reverse saturation cur rent I 0 increases. The same effect can be had by illuminating the junction. When light en - ergy bombards a P -N junction, it dislodges  valence electrons."
  },
  {
    "subject": "books",
    "text": "The more light striking the junction the larger the reverse current in a diode. It is due to generation of more and more charge carriers with the increase in level of illumination. This is clearly shown in \u2018 figure for different intensi ty levels."
  },
  {
    "subject": "books",
    "text": "The dark current  is the current that exists when no light is incident. It is to be noted here that current becomes zero only with a positive ap plied bias equals to V Q. The almost equal spac ing between the curves for the same incre ment in lumi nous flux reveals that the re verse saturation current I 0 increases linearly with the luminous flux as shown in figure."
  },
  {
    "subject": "books",
    "text": "Increase in reverse voltage does not increase the reverse current significantly, because all available charge carriers are already being  swept across the junction. For reducing the reverse saturation current I 0 to zero, it is necessary to forward bias the junction by an amount equal to barrier potential."
  },
  {
    "subject": "books",
    "text": "Thus the photodiode can be used as a photoconductive device. On removal of reverse bias applied across the photodiode, minority charge carriers continue to be swept across the junction while the diode is illuminated. This has  the effect of increasing the concentration of holes in the P -side and that of electrons in the N -side But the barrier potential is negative on the P -side and positive on the N -side, and was created by holes flowing from P to N -side and electrons from N to  P-side during fabrication of junction."
  },
  {
    "subject": "books",
    "text": "Thus the flow of minority carriers tends When an external circuit is connected across the diode terminals, the minority carrier; return to the original side via the external circuit. The electrons which crossed the junction from P to N -side now flow out through the N -terminal and into the P -terminal This means that the device is behaving as a voltage cell with the N -side being the negative terminal and the P -side the positive terminal."
  },
  {
    "subject": "books",
    "text": "Thus, the photodiode is & photovoltaic device as well as photoconductive device. 3.Current needs amplification for driving other circuits. For the operati on of most of the electronics devices and circuits, a d.c. source is required.  So it is advantageous to convert domestic a.c."
  },
  {
    "subject": "books",
    "text": "supply into d.c.voltages. The process of  converting a.c. voltage into d.c. voltage is called as rectification.  This is achieved wi th i) Step -down Transformer, ii) Rectifier, These elements constitute d.c. regulated power supply shown in the fig 1 below. \uf0fc Transformer \u2013 steps down 230V AC mains to low voltage AC."
  },
  {
    "subject": "books",
    "text": "\uf0fc Rectifier \u2013 converts AC to DC, but the DC output is varying. \uf0fc  Smoothing \u2013 smooth the DC from varying greatly to a small ripple. \uf0fc Regulator \u2013 eliminates ripple by setting DC output to a fixed voltage. The block  diagram of a regulated D.C."
  },
  {
    "subject": "books",
    "text": "power supply consists of step -down transformer, rectifier, filter, voltage regulator and load. An ideal regulated power supply is an electronics  circuit designed to provide a predetermined d.c. voltage Vo which is independent o f the load  current and variations in the input voltage ad temperature."
  },
  {
    "subject": "books",
    "text": "If the output of a regulator circuit is  a AC voltage then it is termed as voltage stabilizer, whereas if the output is a DC voltage then it  is termed as voltage regulator. Any electrical device which offers a low resistance to the current in one direction but a high resistance to the current in the opposite direction is called rectifier."
  },
  {
    "subject": "books",
    "text": "Such a device is capable of converting a sinusoidal input waveform, whose average valu e is zero, into a unidirectional Waveform, with a non - zero average component. A rectifier is a device, which converts a.c. voltage (bi -directional) to pulsating Any electrical device w hich offers a low resistance to the current in one direction but a high resistance to the current in the opposite direction is called rectifier."
  },
  {
    "subject": "books",
    "text": "Such a device is capable  of converting a sinusoidal input waveform, whose average value is zero, into a unidire ctional  waveform, with a non - A rectifier is a device, which converts a.c. voltage (bi -directional) to pulsating d.c.. Load currents: They are two types of output current."
  },
  {
    "subject": "books",
    "text": "They are average or d.c. current and RMS currents. Average or  DC current: The average current of a periodic function is defined as the area of one cycle of The effective (or) R.M.S. current squared ofa periodic function of time is given by the area of one cycle of the curve , which  represents the square of the function divided by the base."
  },
  {
    "subject": "books",
    "text": "It is defined as ration of R.M.S. value of a.c. component to the d.c. component in the output is known It is the ratio of d.c output power to the a.c. input power. It signifies, how efficiently the rectifier circuit It is defined as the maximum reverse voltage that a diode can withstand without destroying The d.c."
  },
  {
    "subject": "books",
    "text": "power to be delivered to the load in a rectifier circuit decides the rat ing of the Transformer used in the circuit. So, transformer utilization factor is defined as The variation of the d.c. output voltage as a function of d.c."
  },
  {
    "subject": "books",
    "text": "load current is called r egulation. The Using one or more diodes in the circuit, following rectifier circuits can be designed. using  only one half cycle of the applied a.c. voltage. The a.c. voltage is applied to the rectifier circuit using step -down transformer -rectifying element i.e., p - n junction diode and the source of a.c."
  },
  {
    "subject": "books",
    "text": "voltage, all connected is series. The a.c. voltage is applied to the The input to the rectifier circuit, Where V m is the peak value of secondary a.c. voltage. For the positive half -cycle of input a.c. voltage, the diode D is forward biased an d hence  it conducts."
  },
  {
    "subject": "books",
    "text": "Now a current flows in the circuit and there is a voltage drop across RL. The waveform of the diode For the negative half -cycle of input, the diode D is reverse biased and hence it does not Conduct. Now no current flows in the circuit i.e., i=0 and Vo=0."
  },
  {
    "subject": "books",
    "text": "Thus for the negative half - cycle no In the analysis of a HWR, the following parameters are to be analyzed. Let a sinusoidal voltage Vi be applied to the input of the rectifier. Then V=V m sin (wt ) Where V m is the maximum value of the secondary voltage."
  },
  {
    "subject": "books",
    "text": "Let the diode be idealized to piece -wise linear approximation with resistance Rf in the  forward direction i.e., in the ON state and R r (=\u221e) in the reverse direction i.e., in the OFF state.  Now the c urrent \u2018i\u2019 in the diode (or) in the load resistance RL is given by     V=V m sin (wt) The d.c."
  },
  {
    "subject": "books",
    "text": "power to be delivered to the load in a rectifier circuit decides the rating of the  transformer used in t he circuit. Therefore, transformer utilization factor is defined as The value of TUF is low which shows that in half -wave circuit, th e transformer is not  fully utilized."
  },
  {
    "subject": "books",
    "text": "If the transformer rating is 1 KVA (1000VA) then the half -wave rectifier can deliver It is defined as th e maximum reverse voltage that a diode can withstand without destroying the junction. The peak inverse voltage across a diode is the peak of the negative half - cycle."
  },
  {
    "subject": "books",
    "text": "For half -wave Because of all these disadvantages, the half -wave rectifier circuit is normally not used as a A full -wave rectifier converts an ac voltage into a pulsating dc voltage using both half cycles of the applied ac voltage."
  },
  {
    "subject": "books",
    "text": "In order to rectify both the half cycles of ac input, two diodes are used in this circuit. The diodes feed a common load RL with the  help of a center -tap transformer. A center -tap transformer is the one, which produces two sinusoidal waveforms of same magnitude and frequency but out of phase with respect to the ground in the secondary winding of the transformer."
  },
  {
    "subject": "books",
    "text": "The load current flows through D2 and the voltage drop across RL will be equal to the input voltage.  It is noted that the load current flows in the both the half cycles of ac voltage and in the same direction through the load resistanc e."
  },
  {
    "subject": "books",
    "text": "The d.c. power to be delivered to the load in a rectifier circuit decides the rating of the  transformer used in the circuit. S o, transformer utilization factor is defined as It is defined as the maximum reverse voltage that a diode can withstand without destroying  the junction."
  },
  {
    "subject": "books",
    "text": "The peak inverse voltage across a diode is the peak of the negative half - cycle. For half - wave Another type of circuit that produces the same output waveform as the full wave  rectifier circuit above, is that of the Full Wave Bridge Rectifier ."
  },
  {
    "subject": "books",
    "text": "This type of single phase rectifier uses four individual rectifying diodes connected in a closed loop \"bridge\" configuration to produce the desired output. The main advantage of this brid ge circuit is that it does not require a special centre tapped transformer, thereby reducing its size and cost."
  },
  {
    "subject": "books",
    "text": "The single secondary winding is connected to one side of the diode bridge network and the load to the other side as shown below. The four diodes labelled D1 to D4 are arranged in \"series pairs\" with only two diodes conducting current during each half cycle."
  },
  {
    "subject": "books",
    "text": "During the positive half cycle of the supply, diodes D1 and D2 conduct in series while diodes D3 and D4 are rev erse biased and the current flows through the load as shown below (fig During the negative half cycle of the supply, diodes D3 and D4 conduct in series (fig 8), but diodes D1 and D2 switch \"OFF\" as they are now reverse biased."
  },
  {
    "subject": "books",
    "text": "The current flowing through the load is the same As the current flowing through the load is unidirectional, so the voltage developed across the load is also unidirectional the same as for the previous two diode full -wave rectifier, therefore the average DC through two diodes instead of just one so the amplitude of the output voltage is two  voltage drops ( 2 The output of a rectifier contains dc componen t as well as ac component."
  },
  {
    "subject": "books",
    "text": "Filters are used to minimize the undesirable ac i.e., ripple leaving only the dc component to appear at the output. This is the most simple form of the filter circuit  and in this arrangement a high value capacitor C is placed directly across the output terminals, as shown in figure."
  },
  {
    "subject": "books",
    "text": "During the conduction period it gets charged and stores up energy  to it during non -conduction period. Through this process, the time duration during which Ft is to be noted here that the capacitor C gets charged to the peak because there is no r esistance (except the negligible forward resistance of diode) in the charging path."
  },
  {
    "subject": "books",
    "text": "But the discharging time is quite large (roughly 100 times more than the charging time depending upon the value of RL) because it discharges through load resistance RL. The function of the capacitor filter may be viewed in terms of impedances."
  },
  {
    "subject": "books",
    "text": "The large value capacitor C offers a low impedance shunt path to the ac components or ripples but offers high impedance to the dc component. Thus ripples get bypassed through capacitor  C and only dc component flows through Capacitor filter is very popular because of its low cost, small size, light weight and good The worthnoting points about shunt capacitor filter are: 1.For a fixed -value filter capacitance larger the load resistance RL larger will be the discharge time constant CRL and therefore, lower the ripples and more the output voltage."
  },
  {
    "subject": "books",
    "text": "Large r the filter capacitor, the more charge it can hold and the less it will discharge. Hence the peak -to-peak value of the ripple will be less, and the average dc level will increase. But, the maximum value of the capacitance that can be employed is limited b y another factor."
  },
  {
    "subject": "books",
    "text": "The larger the capacitance value, the greater is the current required to charge the capacitor to a given voltage. The maximum current that can be handled by a diode is limited by the figure quoted by the manufacturer. Thus the maximum value of the capacitance, that can be used in the shunt filter capacitor is limited."
  },
  {
    "subject": "books",
    "text": "In this arrange ment a high value inductor or choke L is connected in series with the rectifier element and the load, as illustrated in figure. The filtering action of an induc tor filter de pends upon its property of opposing any change in the current flowing through it."
  },
  {
    "subject": "books",
    "text": "When the output current of the rectifier increases above a certain value, energy is stored in it in the form of magnetic field and this energy is given up when the output current falls below the average value. Thus by placing a choke coil in series with the rectifier output and load, any sudden change in current that might have occurred in the circuit without an inductor is smoothed out by the presence of the ind uctor L."
  },
  {
    "subject": "books",
    "text": "The function of the inductor filter may be viewed in terms of impedances. The choke offers high impedance to the ac components but offers almost zero resistance to the desired dc components. Thus ripples are removed to a large extent. Nature of th e output voltage without filter and with choke filter For dc (zero frequency), the choke resistance R c in series with the load resistance R L forms a voltage divider and dc voltage across the load is given as where V dc is dc voltage outp ut from a full -wave rectifier."
  },
  {
    "subject": "books",
    "text": "Usually choke coil resistance Rc, is much small than R L and, therefore, almost entire of the dc voltage is available across the load resistance R L. Since the reactance of inductor increases with the increase in frequency, bet ter filter ing of the higher harmonic components takes place, so effect of third and higher harmonic voltages can be neglected."
  },
  {
    "subject": "books",
    "text": "As obvious from equation , if choke coil resistance R c is negligible in comparison  to load resistance R L, then the entire dc com ponent of rectifier output is available across  2 R L and is equal to \u2014 VL max."
  },
  {
    "subject": "books",
    "text": "From economi cal point of view also, neither series inductor nor shunt capacitor type filters are Practical filter -circuits  are derived by combining the voltage stabilizing action of shunt capacitor  with the current smoothing action of series choke coil. By using combination of inductor and capacitor ripple factor can be lowered, diode current can be restricted and simultaneously ripple factor can be made almost independent of load resistance (or loa d current)."
  },
  {
    "subject": "books",
    "text": "Two types of most commonly used combinations are choke -input or L -section filter -and capacitor -input or Pi -Filter. Choke -input filter consists of a choke L connected in series with the rectifier and a c apacitor C connected across the load ."
  },
  {
    "subject": "books",
    "text": "This is also sometimes called the L -section filter because in this arrangement inductor and capacitor are connected, as an inverted L. ln figure only one filter section is shown. But several identical sections are oft en employed to improve the smoothing action."
  },
  {
    "subject": "books",
    "text": "(The choke L on the input side of the filter readily allows dc to pass but opposes the flow of ac components because its dc resistance is negligibly small but ac impedance is large. Any fluctuation that remains in the current even after passing through the choke are largely by -passed around the load by the shunt capacitor because Xc is much smaller than RL."
  },
  {
    "subject": "books",
    "text": "Ripples can be reduced effectively by making XL greater than Xc at ripple frequency. However, a small rippl e still remains in the filtered output and this is considered negligible if it than l%. The rectified and filtered output voltage waveforms from a full -wave Such a filter consists of a shunt capacitor C1  at the input followed by an L -section filter formed by series inductor L and shunt capacitor C 2."
  },
  {
    "subject": "books",
    "text": "This is also called the n-filter because the shape of the circuit diagram for this filter appears like G reek letter n (pi) . Since the rectifier feeds directly into the capaci tor As the rectified output is fed directly into a ca pacitor C1."
  },
  {
    "subject": "books",
    "text": "Such a filter can be used with a half -wave rectifier (series inductor and L-section filters cannot be used with half -wave rectifiers). Usually electrolytic capacitors are used even though their capacitances are large but they occupy minimum space. Usually both capacitors C1 and C 2 are enclosed in one metal container."
  },
  {
    "subject": "books",
    "text": "The metal c ontainer serves as, the common ground for the two capacitors. A capacitor -input or pi- filter is characterized by a high voltage output at low current drains. Such a filter is used, if, for a given transformer, higher voltage than that can be obtained from  an L -section filter is required and if low ripple than that can be obtained from a shunt capacitor filter or L -section filter is desired."
  },
  {
    "subject": "books",
    "text": "In this filter, the input capacitor C1 is selected to offer very low reactance to the ripple frequency. Hence major p art of filtering is accomplished by the input capacitor C1. Most of the remaining ripple is removed by the L -section filter consist ing of a choke L and capacitor C 2.) The action of this filter can best be understood by considering the action of L -section filter, formed by L and C 2, upon the triangular output voltage wave from the input capacitor C 1 The charging and discharging action of input capacitor C1 has already been discussed."
  },
  {
    "subject": "books",
    "text": "The output voltage is roughly the same as across input capacitor C1 less t he dc voltage drop in inductor. The ripples contained in this output are reduced further by L -section filter. The output voltage of pi -filter falls off rapidly with the increase in load -current and, therefore, the voltage regulation with this filter is ver y poor."
  },
  {
    "subject": "books",
    "text": "1. In pi -filter the dc output voltage is much larger than that can be had from an L -section filter with the 2.In pi -filter ripples are less in comparison to those in shunt capacitor  or L-section filter. So smaller valued choke is required in a pi -filter in comparison to that required in L -section filter."
  },
  {
    "subject": "books",
    "text": "3.In pi -filter, the capacitor is to be charged to the peak value hence the rms current in supply transformer is larger as compared in case of L -section filter. 4.Voltage regulation in case of pi -filter is very poor, as already mentioned."
  },
  {
    "subject": "books",
    "text": "So n -filters are suitable for fixed loads whereas L -section filters can work satisfactorily with varying loads provided a minimum 5.In case of a pi -filter PIV is larger than that in case of an L -section filter. 1) A capacitor filter provides Vm volts at less load current."
  },
  {
    "subject": "books",
    "text": "But regulation is poor. 2) An Inductor filter gives high ripple voltage for low load currents. It is used for 3) L \u2013 Section filter gives a ripple factor independent of load current. Voltage Regulation can be improved by use of bleeder resistance 4) Multiple L \u2013 Section filter or \u03c0 filters give much less ripple than the single L \u2013 A bipolar junction transistor (BJT) is a three terminal device in which operation depends on the interaction of both majority and minority carriers and hence the name b ipolar."
  },
  {
    "subject": "books",
    "text": "The BJT is analogues to vacuum triode and is comparatively smaller in size. It is used as amplifier and oscillator circuits, and as a switch in digital circuits. It has wide applications in computers, satellites and other modern The Bipolar Transistor  basic construction consists of two PN -junctions producing three connecting terminals with each terminal being given a name to identify it from the other two."
  },
  {
    "subject": "books",
    "text": "These three terminals are know n and labelled as the Emitter  ( E ), the Base  ( B ) and the Collector  ( C ) respectively. There are two basic types of bipolar transistor construction, PNP and NPN , which basically describes the physical arrangement of the P -type and N -type semiconductor m aterials from which they are Transistors are three terminal active devices made from different semiconductor materials that can act as either an insulator or a conductor by the application of a small signal voltage."
  },
  {
    "subject": "books",
    "text": "Saturation  - the transistor is \"fully -ON\" operating as a switch and Ic = I(saturation) \uf0b7 3. Cut -off - the transistor is \"fully -OFF\" operating as a switch and Ic = 0 Bipolar Transistors are current regulating de vices that control the amount of current flowing through them in proportion to the amount of biasing voltage applied to their base terminal acting like a current -controlled switch."
  },
  {
    "subject": "books",
    "text": "The principle of operation of the two transistor types PNP and NPN , is exac tly the same the only difference being in their biasing and the polarity of the power supply for The construction and circuit symbols for both the PNP and NPN bipolar transistor are given above with the arrow in the circuit symbol always showing the direction of \"conventional current flow\" between the base terminal and its emitter terminal."
  },
  {
    "subject": "books",
    "text": "The direction of the arrow always points from the positive P -type regi on to the negative N -type region for both transistor types, exactly the same as for the standard diode symbol. junction and reverse - biased collector junction. The emitter current I E consists of hole current I PE (holes crossing from emitter into base) and electron current I nE (electrons crossing from base into emitter).The ratio of hole to electron currents, I pE / InE   , crossing the emitter junction is proportional to the  ratio of the conductivity of the p material to that of the n material."
  },
  {
    "subject": "books",
    "text": "In a transistor, the doping of that of the emitter is made much larg er than the doping of the base. This feature ensures (in p -n-p transistor) that the emitter current consists an almost entirely of holes. Such a situation is desired since the current which results from electrons crossing the emitter junction from base to emitter do not contribute carriers, which can reach the collector."
  },
  {
    "subject": "books",
    "text": "Not all the holes crossing the emitter junction J E reach the the collector junction J C Because some of them combine with the electrons in n -type base. If I pC   is hole current at junction  JC there must be a bulk recombination current ( I PE- IpC ) leaving the base."
  },
  {
    "subject": "books",
    "text": "Assumed referenced direction for I CO i.e. from right to left, then for a p -n-p transistor, I CO is negative. For an  n -p-n transistor, I CO  is positive.The basic operation will be described using the pnp transistor. The operation of the pnp transistor is exactly the same if the roles played by the electron and hole are interchanged."
  },
  {
    "subject": "books",
    "text": "One p-n junction of a transistor is reverse -biased, whereas the other is forward -biased. Majority carriers (+) will diffuse across the forward -biased p -n junction into the n -type material. A very small number of carriers (+) will through n -type material to the base terminal."
  },
  {
    "subject": "books",
    "text": "Resulti ng IB is The large number of majority carriers will diffuse across the reverse -biased junction into the p -type The comprises of t wo components \u2013 the majority and minority carriers ICO \u2013 IC current with emitter terminal open and is called leakage current Various parameters which relate the current components is given below ercurrent totalemittriersatJ njectedcar currentofiE\uf03d\uf067 IIentatJ rrierncurr injectedcaJ ntreaching rriercurre injectedca The ratio of the negative of collector current increment to the  emitter current change from zero (cut - off)to I E   the large signal current g ain of a common base transistor."
  },
  {
    "subject": "books",
    "text": "Since I C and IE have opposite signs, then  \u03b1, as defined, is always positive. Typically numerical values of The tran sistor alpha is the product of the transport factor and the emitter efficiency. This statement assumes that the collector multiplication ratio As the Bipolar Transistor  is a three terminal device, there are basically three possible ways to connect it within an electronic circuit with one terminal being common to both the input and output."
  },
  {
    "subject": "books",
    "text": "\uf0b7 3. Common Collector Configuration  - has Current Gain but no Voltage Gain. Common -base terminology is derived from the fact that the : base is common to both input and output of t configuration. base is usually the terminal closest to or at ground potential."
  },
  {
    "subject": "books",
    "text": "Note that the applied biasing (voltage sources) are such as to establish current in the direction To describe the behavior of common -base amplifiers requires two set of characteristics: \uf0b7 Active region \u2013defined by the biasing arrangements \uf0b7 Cutoff region \u2013 region where the collector current is 0A \uf0b7 Saturation region - region of the characteristics to the left of V CB = 0V The curves (output characteristics) clearly indicate t hat a first approximation to the relationship between IE and IC in the active region is given by In the dc mode the level of I C  and I E due to the maj ority carriers are related by a quantity called alpha It can then be summarize to I C = \uf061IE (ignore I CBO due to small value) For ac situations where the point of operation moves on the characteristics curve, an ac alpha defined Alpha a common base current gain factor that shows the efficiency by calculating the current percent Biasing: Proper biasing CB configuration in active region by  appr oximation I C \uf0bb IE (IB \uf0bb 0 uA) It is called common -emitter configuration since : emitter is common or reference to both inpu t and output terminals.emitter is usually the terminal closest to or at ground potential."
  },
  {
    "subject": "books",
    "text": "Almost amplifier design is using connection of CE due to the high gain for current and voltage. Two set of characteristics are necessary to describe the behavior for CE ;input (base terminal) and Proper Biasing common -emitter configuration in active region IB is microamperes compared to miliamperes of I C."
  },
  {
    "subject": "books",
    "text": "Base -emitter junction is forward bias  Increasing V CE will reduce I B for different values. For small V CE (VCE < V CESAT, IC increase linearly with increasing of V CE VCE > V CESAT  IC not totally depends on V CE \uf0e0 constant I C IB(uA) is very small compare to I C (mA)."
  },
  {
    "subject": "books",
    "text": "Small increase in I B cause big increas e in I C Noticing the value when I C=0A. There is still some value of current flows. The ratio of dc collector current (IC) to the dc base current (IB) is dc beta ( \uf062dc ) which is dc current gain wh ere IC and IB are determined at a particular operating point, Q -point (quiescent point)."
  },
  {
    "subject": "books",
    "text": "It\u2019s On data sheet, \uf062dc=hfe with h is derived from ac hybrid equivalent cct. FE are derived from forward - current amplification and common -emitter configuration respectively. For ac conditions, an ac beta has been defined as the changes of collector current (I C) compared to the changes of base current (I B) where I C and I B are determined at operating point."
  },
  {
    "subject": "books",
    "text": "On data sheet, \uf062ac=hfe  It can defined by the following equation: From output characteristics of commonemitter configuration, find \uf062ac and \uf062dc with an Also called emitter -follower (EF). It is called common -emitter configuration since both the signal source and the load share the collector terminal as a common connection point.The output voltage is obtained a t emitter terminal."
  },
  {
    "subject": "books",
    "text": "The input characteristic of common -collector configuration is similar with common -emitter. configuration.Common -collector circuit configuration is provided with the load resistor connected from emitter to ground. It is used primarily fo r impedance - matching purpose since it has high input impedance and low output impedance."
  },
  {
    "subject": "books",
    "text": "For the common -collector configuration, the output characteristics are a plot of I E vs V CE for a range Many BJT transistor used as an amplifier. Thus it is important to notice the limits of operations.At least 3 maximum values is mentioned in data sheet."
  },
  {
    "subject": "books",
    "text": "a) Maximum power d issipation at collector: P Cmax or P D b) Maximum collector -emitter voltage: V CEmax sometimes named as V BR(CEO ) or V CEO. There are few rules that need to be followed for BJT transistor used as an amplifier."
  },
  {
    "subject": "books",
    "text": "The rules are: Note:   VCE is at maximum and I C is at minimum (I CMAX=ICEO) in the  cutoff region. I C is at maximum and V CE is at minimum (V CE max = V cesat = V CEO) in the saturation region."
  },
  {
    "subject": "books",
    "text": "The tr ansistor operates in the active region between saturation and cutoff. Refer to the fig. Example; A derating factor of 2mW/\u00b0C indicates the power dissipation is reduced 2mW each degree centigrade increase of temperature. At any point on the characteristics the product of and must be equal to 360 mW."
  },
  {
    "subject": "books",
    "text": "Ex. 1. If choose I Cmax= 5 mA, substitute into the (1), we get Ex.2. If choose V CEmax =18 V, substitute into (1), we get Example;A derating factor of 2mW/\u00b0C indicates the power d issipation is reduced 2mW each degree All the transistor amplifiers are two port networks having two voltages and two currents."
  },
  {
    "subject": "books",
    "text": "The positive directions of v oltages and currents are shown in fig. 1 . A two -port network is represented by four external variables: voltage V1 and current  I1 at the input port, and voltage V2 and current  I2 at the output port, so that the two -port network can be treated a s a black box modeled by the relationships between the four variables,V 1,V2, I1,I2 ."
  },
  {
    "subject": "books",
    "text": "Out of four variables two can be selected as are independent variables and two are dependent variables.The dependent variables can be expressed interns of independent vari ables. This leads to various two port parameters out of which A two -port network can be described b y z-parameters as In matrix form, the above equation can be rewritten as Reverse transfer impedance with input por t open circuited Forward transfer impedance with output port open circuited A two -port network can be described by Y -parameters as In matrix form, the above equation can be rewritten as Reverse transfer admittance with input port short circuited Forward transfer admittance with output port short circuited If the input current I1 and output voltage V2 a re taken as independent variables, the dependent Where h 11, h12, h21, h22 are called as hybrid parameters."
  },
  {
    "subject": "books",
    "text": "Reverse voltage transfer ratio with i/p port open circuited Forward voltage transfer ratio with o/p port short circuited Based on the definition of hybrid parameters the mathematical model for two pert networks known as h-parameter model can be developed. The hybrid equations can be written as: (The following convenient alternative subscript not ation is recommended f =21 = forward transfer r = 12 = reverse transfer) We may now use the four h parameters to construct a mathematical model of the device of Fig.(1)."
  },
  {
    "subject": "books",
    "text": "The hybrid cir cuit for any device indicated in Fig.(2). We can verify that the model of Fig.(2) satisfies above equations by writing Kirchhoff'svoltage and current laws for input and output ports . If these parameters are specified for a particular con figuration, then suffixes e,b or c are also included, e.g."
  },
  {
    "subject": "books",
    "text": "h fe ,h ib are h parameters of common emitter and common collector amplifiers Using two equations the generalized model of the amplifier can be drawn as shown in fig. 2 . The hybrid model for a transistor amplifier can be derived as follow: Let us consider CE configuration as sho w in fig."
  },
  {
    "subject": "books",
    "text": "The partial derivatives are taken keeping the collector volta ge or base current constant. The \u0394 v B, \u0394 v C, \u0394 iB, \u0394 i C represent the small signal (incremental) base and collector current and voltage and can be The model for CE configuration is shown in fig."
  },
  {
    "subject": "books",
    "text": "4 . To determine the four h -parameters of transistor amplifier, input and output characteristic are used. Input characteristic depicts the r elationship between input voltage and input current with output voltage as parameter. The output characteristic depicts the relationship between output voltage and output current with input current as parameter."
  },
  {
    "subject": "books",
    "text": "Fig. 5 , shows the output characteristics of CE The current increments are taken around the quiescent point Q which corresponds to i B = IB and to the The value of h oe at the quiescent operating point is given by the slope of the output characteristic at hie is the slope of the appropriate input on fig."
  },
  {
    "subject": "books",
    "text": "Typical CE h -parametersof transistor 2N1573 are given below: ANALYSIS OF A TRANSISTOR AMPLIFIER USING H -PARAMETERS: To form a transistor amplifier it is only necessary to connect an external load and signal source as indicated in fig. 1  and to bias the transistor properly."
  },
  {
    "subject": "books",
    "text": "Consider the two -port network of CE amplifier. R S is the source resistance and Z L is the load impedence h-parameters are assumed to be consta nt over the operating range. The ac equivalent circuit is shown in fig. 2 ."
  },
  {
    "subject": "books",
    "text": "(Phasor notations are used assuming sinusoi dal voltage input). The quantities of interest are the current gain, input impedence, voltage gain, and output impedence. For the transistor amplifier stage, A i is defined as the ratio of output to input currents."
  },
  {
    "subject": "books",
    "text": "The impedence looking into the amplifier input terminals ( 1,1' ) is the input impedance Z i The ratio of output voltage to input voltage gives the gain of the transistors. Av is the voltage gain for an ideal voltage source (R v = 0)."
  },
  {
    "subject": "books",
    "text": "Consider input source to be a current source I S in parallel with a resistance R S as shown in fig. 3 . In this case, overall current gain A IS is defined as To analyze multistage amplifier the h -parameters of the transistor used are obtained from manufacture data sheet."
  },
  {
    "subject": "books",
    "text": "5 . hybrid model for transistor in three different configurations Analysis of a Transistor amplifier circuit using h -parameters A transistor amplifier can be constructed by connecting an external load and signal source and assumed that h -parameters remain constant over the operating range.The input is sinuso idal and I 1,V- For transistor amplifier the current gain A i is defined as the ratio of output current to input In the circuit of Fig     , R S is the signal source resistance .The impedence seen when looking into the amplifier terminals (1,1\u2019) is the amplifier input impedence  Z i, From the input circuit of Fig   V 1 = h i I1 + h rV2 Voltage Gain or Voltage Gain Amplification Factor(A v) The ratio of output voltage V 2 to input voltage V 1 give the voltage gain of the transistor i.e, Yo is obtained by setting V S to zero, Z L to infinity and by driving the output terminals from a generator V2."
  },
  {
    "subject": "books",
    "text": "If the current V 2 is I2 then Y o= I2/V2 with V S=0 and R L= \u221e. The output admittance is a function of source resistance. If the source impe dence is resistive then Y o is Voltage Amplification Factor(A vs) taking into account the resistance (R s) of the source Current Amplification (A is) taking into account the sourse Resistance(R S) Overall Current Gain, A is = -I2 / IS = - I2I1 /I1 IS = A i I1/IS The operating power gain A P of the transistor is defined as AP = P 2 / P 1 = -V2 I2 / V 1 I1 = A vAi = A i AiZL/ Zi Avs =  A v Zi / ( Z i + R S) =  A iZL / ( Z i + R S) If the o/p signal must be a faithful reproduction of the i/p signal, the transistor must be operated in active region."
  },
  {
    "subject": "books",
    "text": "This process of selecting proper supply voltages and resistance for obtaining desired operating point or Q point is called as biasing and the ckt used for transistor biasing is called as biasing c kt. There are four conditions to be met by a transistor so that it acts as a faithful ampr: junction must be reverse biased for all levels of i/p signal."
  },
  {
    "subject": "books",
    "text": "For VCE less than VCE (sat) the collector base junction is not probably reverse biased. 3) The value of the signal I c when no signal is applied should be at least  equal to the max. collector 4) Max. rating of the transistor I c(max) , VCE (max) and P D(max)  should not be exceeded at any value of Consider the fig shown in fig1."
  },
  {
    "subject": "books",
    "text": "If operating point is selected at A, A represents a condition when no bias is applied to the transistor i.e, I c=0, VCE =0. It does not satisfy the above said conditions necessary Point C is too close to P D(max)  curve of the transistor."
  },
  {
    "subject": "books",
    "text": "Therefore  the o/p voltage swing in the posi tive Point B is located in the middle of active region .It will allow both positive and negative  half cycles in the o/p signal. It also provides linear gain and larger possible o/p voltages and currents Hence operating point for a t ransistor amplifier is selected to be in the middle of active region."
  },
  {
    "subject": "books",
    "text": "point A are obtaine d by substituting V CE =0 in the above equation. Then The coordinates of B are obtained by substituting Ic=0 in the above equation. Then Vce = Vcc. Therefore the coordinates of B a re V CE =Vcc and Ic=0."
  },
  {
    "subject": "books",
    "text": "Thus the dc load line AB can be drawn if the BETWEEN a AND b. In order to get faithful amplification, the Q point mu st be well within the active Even though the Q point is fixed properly, it is very important to ensure that the operating point remains stable where it is originally fixed."
  },
  {
    "subject": "books",
    "text": "If the Q point shifts nearer to either A or B, the output voltage and current get clipped, thereby o/p signal is distorted. In practice, the Q -point tends to shift its position due to any or all of the following three main 1) Reverse saturation current, Ico, which doubles for every 10oC raise in temperatur e 3) Transistor current gain, h FE or \u03b2 which increases with temperature."
  },
  {
    "subject": "books",
    "text": "If base current I B is kept constant since I B is approximately equal to Vcc/RB. If the transistor is replaced by another one o f the same type, one cannot ensure that the new transistor will have identical parameters as that of the first one."
  },
  {
    "subject": "books",
    "text": "Parameters such as \u03b2 vary over a range. This results in the variation of collector current Ic for a given I B. Hence , in the o/p characteris tics, the spacing between the curves might increase or decrease which leads to the shifting of the Q -point to a location which After drawing the dc load line, the operating point Q is properly located a t the center of the dc load line."
  },
  {
    "subject": "books",
    "text": "This operating point is chosen under zero input signal condition of the circuit. Hence the ac load line should also pas through the operating point Q. The effective ac load resistance R ac, is a To draw the ac load line, two end points, I.e."
  },
  {
    "subject": "books",
    "text": "V CE(max) and I C(max)   when the signal is applied are required. By joining points c and D, ac load line CD is constructed. As R C > R ac, The dc load line is less steep than The rise of temperature results in incre ase in the value of transistor gain \u03b2 and the leakage current Ico."
  },
  {
    "subject": "books",
    "text": "So, I C also increases which results in a shift in operating point. Therefore, The biasing network should be provided with thermal stability. Maintenance of the operating point is specified by S, which indicates the degree of change in operating point due to change in temperature."
  },
  {
    "subject": "books",
    "text": "The extent to which I C is stabilized with varying I C is measured by a stability factor S Differentiate the above equation w.r.t IC , We get S should be small to have better thermal stability. S\u2019 is defined as the rate of change of    IC with V BE, keeping I C and V BE constant."
  },
  {
    "subject": "books",
    "text": "S\u2019\u2019 is defined as the  rate of change of    IC with \u03b2, keeping I CO and V BE constant. battery) is used for both collector and base of a transistor, although separate batteries can also be used. Since the equation is independent of current I CR, dI B//dI CR =0  and the stability factor is given by the Since \u03b2 is a large quantity, this is very poor biasing circuit."
  },
  {
    "subject": "books",
    "text": "Therefore in practice the circuit is not used for For a given transistor, V be does not vary significantly during use. As V cc is of fixed value, on selection of R B, the base current I B is fixed. Therefore this type is called fixed bias  type of circuit."
  },
  {
    "subject": "books",
    "text": "\uf0b7 It is simple to shift the operating point anywhere in the active region by merely changing \uf0b7 The collector current does not remain constant with variation in temperature or power supply voltage. Therefore the operating point is unstable. \uf0b7 Changes in V be will change I B and t hus cause R E to change."
  },
  {
    "subject": "books",
    "text": "This in turn will alter the gain \uf0b7 When the transistor is replaced with another one, considerable change in the value of \u03b2 can be expected. Due to this change the operating point will shift. attaching an external resistor to the emitter."
  },
  {
    "subject": "books",
    "text": "This resistor introduces negative feedback that stabilizes the Q -point. From Kirchhoff's voltage law, the voltage  across the base resistor is The way feedback controls the bias point is as follows. If V be is held constant and temperature increases, emitter curre nt increases."
  },
  {
    "subject": "books",
    "text": "Collector current and emitter current are related by I c = \u03b1 I e with \u03b1 \u2248 1, so increase in emitter current with temperature is opposed, Similarly, if the transistor is replaced by another, there may be a change in I C (corresponding to change in \u03b2 -value, for example)."
  },
  {
    "subject": "books",
    "text": "By simil ar process as above, the change is negated and operating The circuit has the tendency to stabilize operating point against changes in temperature and \u03b2 - \uf0b7 In this circuit, to keep I C independent of \u03b2 the following condition must be met: which is approximately the case if ( \u03b2 + 1 )R E >> R B."
  },
  {
    "subject": "books",
    "text": "\uf0b7 As \u03b2 -value is fixed for a given transistor, this relation can be satisfied either by keeping \uf0b7 If R E is of large value, high V CC is necessary. This increases cost as well as precautions \uf0b7 If R B is low, a separate low voltage supply should be used in the base circuit."
  },
  {
    "subject": "books",
    "text": "Using two \uf0b7 In addition to the above, R E causes ac feedback which reduces the voltage gain of 3)COLLECTOR TO BASE BIAS  OR COLLECTOR FEED -BACK BIAS: stabilize the operating point. In this form of biasing, the base resistor RB is connected to the collector instead of connecting it to the DC source Vcc."
  },
  {
    "subject": "books",
    "text": "So any thermal runaway will induce a voltage drop acros s the RC resistor that will throttle the transistor's base current. If Vbe is held constant and temperature increases, then the collector current Ic increases. However, a larger Ic causes the voltage drop across resistor Rc to inc rease, which in turn reduces the across the base resistor Rb."
  },
  {
    "subject": "books",
    "text": "A lower base -resistor voltage drop reduces the base current Ib, which results in less collector current Ic. Because an increase in collector current with temperature is \uf0b7 Circuit stabilizes the operating point against variations in temperature and \u03b2 (i.e. \uf0b7 In this circuit, to keep Ic independent of \u03b2, the following condition must be met: \uf0b7 As \u03b2-value is fixed (a nd generally unknown) for a given transistor, this relation can be satisfied either by keeping Rc fairly large or making Rb very low."
  },
  {
    "subject": "books",
    "text": "\uf0b7 If Rc is large, a high Vcc is necessary, which increases cost as well as precautions \uf0b7 If Rb is low, the reverse bias of the collector \u2013base region is small, which limits the range of collector voltage swing that leaves the transistor in active mode."
  },
  {
    "subject": "books",
    "text": "\uf0b7 The resistor Rb causes an AC feedback, reducing the voltage gain  of the amplifier. This undesirable e ffect is a trade -off for greater Q-point  stability. Usage:  The feedback also decreases the input impedance of the amplifier as seen from the base, which can be advantageous."
  },
  {
    "subject": "books",
    "text": "Due to the gain reduction from feedback, this biasing form is used only when the trade -off for stability is warranted. applying both the collector feedback an d emitter feedback. Here the collector feedback is provided by connecting a resistance RB from the collector to the base and emitter feedback is provided by connecting an emitter Re from emitter to ground."
  },
  {
    "subject": "books",
    "text": "Both feed backs are used  to control collector current  and base current IB in the opposite direction to increase the stability as compared to the 5)VOLTAGE DIVIDER BIAS OR SELF BIAS OR EMITTER BIAS voltage across R 2 forward biases the emitter junction."
  },
  {
    "subject": "books",
    "text": "By proper selection of resistors R 1 and R 2, the operating point of the transistor can be made independent of \u03b2. In this circuit, the voltage divider holds the base voltage fixed independ ent of base current provided the divider current is large compared to the base current."
  },
  {
    "subject": "books",
    "text": "However, even with a fixed base voltage, collector current varies with temperature (for example) so an emitter resistor is added to stabilize the Q -point, similar to th e above circuits with Let the current in resistor R1 is I1 and this is divided into two parts \u2013 current through base and resistor R2."
  },
  {
    "subject": "books",
    "text": "Since the base current is very small so for all practical purpose it is assumed that I1 also stability is excellent. In all practical cases the value of VBE is quite small in comparison to the V2, so it can be ignored in the above expression so the collector current is almost independent of the transistor parameters thus this arrangement provides excellent stability."
  },
  {
    "subject": "books",
    "text": "The resistor RE provides stability to the circuit. If the current through the collector rises, the voltage across the resistor RE also rises. This will cause VCE to increase as the voltage V2 is independent of collector current. This decreases the base current, thus collector current increases to Stability factor for such circuit arrangement is given by If Req/RE is very small compared to 1, it can be ignored in the above expression thus we have Which is excellent since it is the smallest possible value for the stability."
  },
  {
    "subject": "books",
    "text": "In actual practice the value of stability factor is around 8 -10, since Req/R E cannot be ignored as compared to 1. \uf0b7 Unlike above circuits, only one dc supply is necessary. \uf0b7 Operating point is almost independent of \u03b2 variation."
  },
  {
    "subject": "books",
    "text": "\uf0b7 As \u03b2 -value is fixed for a given transistor, this relation can be satisfied either by keeping \uf0b7 If R E is of large value, high V CC is necessa ry. This increases cost as well as precautions \uf0b7 If R 1 || R 2 is low, either R 1 is low, or R 2 is low, or both are low."
  },
  {
    "subject": "books",
    "text": "Lowering both resistor values draws more current from the power supply and lowers the input resistance of the amplifier as seen from th e base. \uf0b7 AC as well as DC feedback is caused by R E, which reduces the AC voltage gain of the amplifier."
  },
  {
    "subject": "books",
    "text": "A method to avoid AC feedback while retaining DC feedback is discussed below. Usage: The circuit's stability and merits as above make it widely used fo r linear circuits. The various biasing circuits considered use some type of negative feedback to stabilize the operation point."
  },
  {
    "subject": "books",
    "text": "Also, diodes, thermistors and sensistors can be used to compensate for variatio ns in emitter junction for compensation of change in collector saturation current I CO. The diode is of the same material as the transi stor and it is reverse biased by e the emitter -base junction voltage V BE, allowing the diode reverse saturation current I O to flow through diode D."
  },
  {
    "subject": "books",
    "text": "The base current I B=I-IO. As long as temperature is constant, diode D operates as a resistor. As the tempera ture increases, I CO of the transistor increases. Hence, to compensate for this, the base current I B should be The increase in temperature will also cause the leakage current I O through D to increase and thereby decrease the base current I B."
  },
  {
    "subject": "books",
    "text": "This  is the required action to keep Ic constant. This type of bias compensation does not need a change in Ic to effect the change in I C, as both IO and I CO can track almost equally according to the change in temperature."
  },
  {
    "subject": "books",
    "text": "As the temperature increases, the equi valent resistance of the parallel combination of R1 and Rs also increases and hence V BE decreases, reducing I B and Ic. This reduced Ic compensates for increased Ic caused by the increase in V BE, ICO and \u03b2 The collector current for the CE circuit is given by increases with rise in temperature."
  },
  {
    "subject": "books",
    "text": "This process will beco me cumulative leading to \u201cthermal runaway\u201d . Consequently, the ratings of the transistor are exceeded which may destroy the transistor itself. The collector is made larger in size than the emitter in order to help the heat developed at the collector junct ion."
  },
  {
    "subject": "books",
    "text": "However if the circuit is designed such that the base current automatically with rise in temperature, then the decrease in Consider transistor used in a circuit where the ambient temperature of the air around the transistor is T AoC and the temperature of the collector -base junction of the transistor is T JoC."
  },
  {
    "subject": "books",
    "text": "Due to heating within the transisto r TJ is higher than T A. As the temperature difference T J- TA is greater, the power dissipated in the transistor, P D will be greater, i.e, T J- TA called the Thermal resistance."
  },
  {
    "subject": "books",
    "text": "Rearranging the above equation up to 1000oC/W for small signal, low power transistor which have no cooling provision. As \u0398 represents total thermal resistance from a transistor junction to the ambient temperature, it is referred to as \u0398 J-A.  However, for power transistors, thermal resistance is given form junction to The amount resistance from junction to am bience is considered to consist of 2 parts."
  },
  {
    "subject": "books",
    "text": "Which indicates the heat dissipated in the junction must make its way to the surrounding air through two series paths from junction to case and from case to air. Hence the power dissipated. \u0398J-C is determined by the type of manufacture of the transistor and how it is located I the case, but \u0398 C-A is determined by the surface area of the case or flange and its contac t with air."
  },
  {
    "subject": "books",
    "text": "If the effective surface area of the transistor case could be increased, the resistance to heat flows, or could be increased \u0398 C-A, could be decreased. This can be achieved by the use of a heat sink. The heat sink is a relatively large, finned,  usually black metallic heat conducting device in close contact with transistor case or flange."
  },
  {
    "subject": "books",
    "text": "Many versions of heat sink exist depending upon the shape and size of the transistor. Larger the heat sink smaller is the thermal resistance \u0398 HS-A. This thermal  resistance is not added to \u0398 C-A in series, but is instead in parallel with it and if \u0398HS-A is much less than \u0398 C-A, then \u0398 C-A will be reduced significantly, thereby improving the dissipation For preventing thermal runaway, the required condition I the rate at which the heat is released at the collector junction should not exceed the rate at which the heat can be dissipated under steady state c ondition."
  },
  {
    "subject": "books",
    "text": "Hence the condition to be satisfied to avoid thermal runaway is given by If the circuit is properly designed, then the transistor cannot runaway below a specified ambient In the self bias ed circuit the transistor is biased in the active region."
  },
  {
    "subject": "books",
    "text": "The power generated at the Let us assume that the quiescent collector and the emitter currents are equal. Then The condition to prevent the rmal runaway can be written as should be negative in order to satisfy the above condition. Hence to avoid thermal runaway it is necessary that SinceVCE=VCC -IC(RE+RC) then eq(4) implies that VCE<VCC/2."
  },
  {
    "subject": "books",
    "text": "IF the inequality of eq(4) is not satisfied is positive., and the corresponding eq(2) should be satisfied. 1. The Field effect transistor is abbreviated as FET , it is an another semiconductor device like a BJT  which can be used as an amplifier or  switch."
  },
  {
    "subject": "books",
    "text": "2. The Field effect transistor is a voltage o perated device. Whereas Bipolar junction transistor is a current controlled device. Unlike BJT a FET requires virtually no input current. 3. This gives it an extremely high input resistance , which is its most important advantage over a 4."
  },
  {
    "subject": "books",
    "text": "FET is also a three terminal device, labeled  as source, drain and gate. 5. The source can be viewed as BJT\u2019s emitter, the drain as collector, and the gate as the counter 6. The material that connects the source to drain is referred to as the cha nnel."
  },
  {
    "subject": "books",
    "text": "7. FET operation depends only on the flow of majority carriers ,therefore they are called uni polar devices. BJT operation depends on both minority and majority carriers. 8. As FET has conduction through only majority carriers it is less noisy than BJT."
  },
  {
    "subject": "books",
    "text": "9. FETs are much easier to fabricate and are particularly suitable for ICs because they occupy less 10. FET amplifiers have low gain bandwidth product due to the junction capacitive effects and produce more signal distortion except for small sig nal operation."
  },
  {
    "subject": "books",
    "text": "11. The performance of FET is relatively unaffected by ambient temperature changes. As it has  a negative temperature coefficient at high current levels, it prevents the FET from thermal breakdown. The BJT has a positive temperature coefficient at high current levels which leads to There are two major categories of field effect transistors: These are further sub divided in to P - channel and N -channel de vices."
  },
  {
    "subject": "books",
    "text": "MOSFETs are further classified  in to two types Depletion MOSFETs  and Enhancement . MOSFETs When the channel is of N -type the JFET is referred to as an N -channel JFET ,when the channel is of P-type the JFET is referred to as P -channel JFET."
  },
  {
    "subject": "books",
    "text": "The schematic symbols for the P -channel and N -channel JFETs are shown in the figure. If the gate is an N -type material, the channel must be a P -type material. A piece of N - type material, referred to as channel has two smaller pieces of P -type material attached to its sides, forming PN jun ctions."
  },
  {
    "subject": "books",
    "text": "The channel ends are designated as the drain and source. And the two pieces of P -type material are connected together and their terminal is called the gate. Since this channel is in the N -type bar, the FET is known as N -channel JFET."
  },
  {
    "subject": "books",
    "text": "The overall operation of the JFET is based on varying the width of the channel to control the drain A piece of N type material referred to as the channel, has two smaller pieces of P type material attached to its sites, far ming PN \u2013Junctions."
  },
  {
    "subject": "books",
    "text": "The channel\u2019s ends are designated the drain and the source. And the two pieces of P type material are connected together and their terminal is called the gate. With the gate terminal not connected and the potential applied positive at t he drain negative at the source a drain current Id flows."
  },
  {
    "subject": "books",
    "text": "When the gate is biased negative with respective to the source the PN junctions are reverse biased and depletion regions are formed. The channel is more lightly doped than the P type gate blocks, so  the depletion regions penetrate deeply into the channel."
  },
  {
    "subject": "books",
    "text": "Since depletion region is a region depleted of charge carriers it behaves as an Insulator. The result is that the channel is narrowed. Its resistance is increased and Id is reduced. When the negativ e gate bias voltage is further increased, the depletion regions meet at the center and Id is cut off completely."
  },
  {
    "subject": "books",
    "text": "2. And by Varying the value of Vds  holding Vgs constant We can vary the width of the channel and in turn vary the amount of drain current. This can be done by varying the value of Vgs. This point is illustrated in the fig  below."
  },
  {
    "subject": "books",
    "text": "Here we are dealing with N channel FET. So channel is o f N type and gate is of P type that constitutes a PN junction. This PN junction is always reverse biased in JFET operation .The reverse bias is applied by a battery voltage Vgs connected between the gate and the source terminal i.e positive terminal of the  battery is connected to the source and negative terminal to gate."
  },
  {
    "subject": "books",
    "text": "1) When a PN junction is reverse biased the electrons and holes diffuse across junction by leaving immobile ions on the N and P sides , the region containing these immobile ions  is known as 2) If both P and N regions are heavily doped then the depletion region extends symmetrically on 3) But in N channel FET P region is heavily doped than N type thus depletion region extends more 4) So when n o Vds is applied the depletion region is symmetrical and the conductivity becomes Zero."
  },
  {
    "subject": "books",
    "text": "Since there are no mobile carriers in the junction. 5) As the reverse bias voltage is increases the thickness of the depletion region also increases.  i.e. 6) By varying the value of Vgs we can vary the width of the channel."
  },
  {
    "subject": "books",
    "text": "2 Varying the value of Vds  holding Vgs constant : - 1) When no voltage is applied to the gate i.e. Vgs=0 , Vds is applied between source and drain the electrons will f low from source to drain through the channel constituting drain current Id ."
  },
  {
    "subject": "books",
    "text": "2) With Vgs= 0 for Id= 0 the channel between the gate junctions is entirely open .In response to a small applied voltage Vds , the entire bar acts as a simple semi conductor resistor  and the 3) The channel resistances are represented as rd and rs as shown in the fig."
  },
  {
    "subject": "books",
    "text": "4) This increasing drain current Id produces a voltage drop across rd which reverse biases the gate to source junction,(rd> rs) .Thus the depletion region is formed which is not symmetrical . 5) The depletion region i.e. developed penetrates deeper in to the channel near drain and less towards source because Vrd >> Vrs."
  },
  {
    "subject": "books",
    "text": "So reverse bias is higher near drain than at source. 6) As a result growing depletion region reduces the effective width of the channel. Eventually a voltage Vds is reached at which the channel is pinched off. This is the voltage where the current Id begins to level off and approach a constant value."
  },
  {
    "subject": "books",
    "text": "7)  So, by varying the va lue of Vds we can vary the width of the channel holding Vgs constant. It is of course in principle not possible for the channel to close Completely and there by reduce the current Id to Zero for,  if such ind eed, could be the case the gate voltage Vgs is applied in the 1) When voltage is applied between the drain and source with a battery Vdd, the electrons flow from source to drain through the narrow channel existing  between the depletion regions."
  },
  {
    "subject": "books",
    "text": "This constitutes the drain current Id, its conventional direction is from drain to source. 2) The value of drain current is maximum  when no external voltage is applied between gate and 3) When Vgs is increased beyond Zero the depletion regions are widened."
  },
  {
    "subject": "books",
    "text": "This reduces the effective width of the channel and therefore controls the flow of drain current through the 4) When Vgs is further increased a stage is reached at which to deplet ion regions touch each other that means the entire channel is closed with depletion region."
  },
  {
    "subject": "books",
    "text": "This reduces the drain The family of curves that shows the relation between current and voltage are known as There are two important characteristics of a JFET. 2.     Drain characteristics shows the relation between the drain to source voltage Vds and drain curre nt Id."
  },
  {
    "subject": "books",
    "text": "In order to explain typical drain characteristics let us  consider the curve 1) When Vds is applied and it is increasing the drain current ID also increases linearly up to knee 2) This shows that FET behaves like an ordinary resistor .This region is called as ohmic region."
  },
  {
    "subject": "books",
    "text": "3) ID increases with increase in drain to source voltage. Here the drain current is increased 4) It is because of the fact that there is an increase in VDS .This in tu rn increases the reverse bias voltage across the gate source junction .As a result of this depletion region grows in size thereby 5) All the drain to source voltage corresponding to point the channel width is r educed to a 5) The drain to source voltage at which channel pinch off occurs is called pinch off voltage(Vp)."
  },
  {
    "subject": "books",
    "text": "1) This is the region shown by the curve  as saturation region. 2) It is also called as sa turation region or constant current region. Because of the channel is occupied with depletion region , the depletion region is more towards the drain and less towards the source, so the channel is limited, with this only limited number of carriers are only  allowed to cross this channel from source drain causing a current that is constant in this region."
  },
  {
    "subject": "books",
    "text": "To use FET as an amplifier it is operated in this saturation region. 3) In this drain current remains constant at its maximum value IDSS. 4) The drain current in  the pinch off region depends upon the gate to source voltage and is 1) The region is shown by the curve .In this region, the  drain current increases rapidly as the 2) It is because of the gate to source junction due to avalanche effect."
  },
  {
    "subject": "books",
    "text": "3) The avalanche break down occurs at progressively lower value of VDS because the reverse bias gate voltage ad ds to the drain voltage thereby increasing effective voltage across the 1. The maximum saturation drain current is smaller 4) It is important to note that the maximum voltage VDS which can be  applied to FET is the These curves shows the relationship between drain current ID  and gate to source voltage 1) First ad just the drain to source voltage to some suitable value , then increase the gate to 2) Plot the graph between gate to source voltage along the horizontal axis and current ID on the vertical axis."
  },
  {
    "subject": "books",
    "text": "We shall obtain a curve  like this. 3) As we know that if V gs  is more negative curves drain current to reduce . where V gs is made sufficiently negative, I d is reduced to zero. This is caused by the widening of the depletion region to a point where it is completely closes the c hannel."
  },
  {
    "subject": "books",
    "text": "The value of V gs at the cutoff 4) The upper end of the curve as shown by the drain current value is equal to I dss that is when 5) While the lower end is indicated by a voltage equal to V gsoff 6) If Vg s continuously increasing , the channel width is reduced , then I d =0 7) It may be noted that curve is part of the parabola; it may be expressed as Vp is the value of V gs that causes the  JFET to become constant current component, It is measured at V gs =0V and has a constant drain current of I d =Idss .Where V gsoff is the value of V gs that The gate to source junction of a JFET is never allowed to become forward biased because the gate material is not designed to handle any significant amount of current."
  },
  {
    "subject": "books",
    "text": "If the junction is allowed to become forward biased, current is g enerated through the gate material. This current may destroy There is one more important characteristic of JFET reverse biasing i.e. J FET \u2018s have extremely high characteristic gate input impedance."
  },
  {
    "subject": "books",
    "text": "This impedance is typically in the  high mega ohm range. With the advantage of extremely high input impedance it draws no current from the source. The high input impedance of the JFET has led to its extensive use in integrated circuits."
  },
  {
    "subject": "books",
    "text": "The electrical behavior of JFET may be described in terms of certain parameters. Such parameters are It is also called dynamic drain resistance and is the a.c.resistance between the drain a nd source termina l,when the JFET is operating in the pinch off or saturation region.It is given by the ratio of small change in drain to source voltage  \u2206V ds to  the  corresponding change in drain current   \u2206I d for a Mathematically it i s expressed as r d=\u2206V ds/ \u2206Id where V gs is held constant."
  },
  {
    "subject": "books",
    "text": "It is also called forward transconductance  . It is given by the ratio of small change in drain current (\u2206I d) to the corresponding change in gate to source voltage (\u2206V ds) Math ematically  the transconductance can be written as It is given by the ratio of small change in drain to source voltage (\u2206V ds) to the corresponding change in gate to source voltage (\u2206V gs)for a cons tant drain current (I d)."
  },
  {
    "subject": "books",
    "text": "We can express the drain current iD as a function f of the gate voltage and drain voltage V ds. The transconductance g m and drain resistance r d:- If both gate voltage and drain voltage are varied, the change in the drain current is approximated by using taylors series considering only the first two terms in the expansion Is the mutual  conductance or tra nsconductance .It is also called as gfs or yfs common source forward The second parameter r d  is the drain resistance or output resistance is defined as The re ciprocal of the rd is the drain conductance gd .It is also designated by Yos and Gos and called the common source output conductance ."
  },
  {
    "subject": "books",
    "text": "So the small signal equivalent circuit for FET  can be A small signal current \u2013source model for FET in common  source configuration can be drawn This low frequency model for FET has a Norton\u2019s output circuit with a dependent cur rent generator whose magnitude is proportional to the gate -to \u2013source voltage."
  },
  {
    "subject": "books",
    "text": "The proportionality factor is the transconductance \u2018g m\u2019. The output resistance is \u2018r d\u2019. The input resistance between the gate and source is infinite, since it is assumed that th e reverse biased gate draws no current. For the same reason the resistance between gate and drain is assumed to be infinite."
  },
  {
    "subject": "books",
    "text": "These small signal models for FET can be used for analyzing the three basic FET amplifier 1.common source (CS)  2.common drain (CD) or source follower Here the input circuit is kept open because of having high input impedance and the output We now turn our attention to the insulated gate FET or metal oxide semi conductor FET which is having the greater commercial importance than the junction FET."
  },
  {
    "subject": "books",
    "text": "Most MOSFETS however are triodes, with the substrate  internally connected to the source. The circuit symbols used by several manufacturers are indic ated in the Fig below. (1) Deplet ion type           (2) Enhancement type MOSFET. D-MOSFETS can be operated in both the depletion mode and the enhancement mode."
  },
  {
    "subject": "books",
    "text": "E MOSFETS are restricted to operate in enhancement mode. The primary difference between them is their physical The construction difference between the two is shown in the fig given below. As we can see the D MOSFET have physical channel between the source and drain The E MOSFET on the other hand has no such channel p hysically."
  },
  {
    "subject": "books",
    "text": "It depends on the gate voltage to form a channel between the source and the drain terminals. Both MOSFETS have an insulating layer between the gate and the rest of the component. This insulating layer is made up of SIO 2 a glass like insulating material."
  },
  {
    "subject": "books",
    "text": "The gate material is made up of metal conductor .Thus going from gate to substrate, we can have metal oxide semi conductor which is Since the gate is insulated from the rest of the component, the MOSFET is some times The foundation of the MOSFET is called the substrate."
  },
  {
    "subject": "books",
    "text": "This material is represented in the schematic symbol by the center line that is connected to the source. In the symbol for the MOSFET, the arrow is p laced on the substrate. As with JFET an arrow pointing in represents an N -channel device, while an arrow pointing out represents p -channel device."
  },
  {
    "subject": "books",
    "text": "The N - channel MOSFET consists of a lightly doped p type subst ance into which two heavily doped n+ regions are diffused as shown in the Fig. These n+ sections , which will act as source and drain. A thin layer of insulation silicon dioxide (SIO 2) is grown over the surface of the structure, and holes are cut into oxid e layer, allowing contact with the source and drain."
  },
  {
    "subject": "books",
    "text": "Then the gate metal area is overlaid on the oxide, covering the entire channel region.Metal contacts are made to drain and source and the contact to the metal over the channel area is the gate terminal.T he metal area of the gate, in conjunction with the insulating dielectric oxide layer and the semiconductor channel, forms a parallel Is the reason why this device is called the insulated gate field effect trans istor."
  },
  {
    "subject": "books",
    "text": "This layer results in an extremely high input resistance (10 10 to 10power 15ohms) for MOSFET. The basic structure of D \u2013MOSFET is shown in the fig. An N -channel is diffused between source and drain with the device an ap preciable drain current IDSS flows foe zero gate to source voltage, Vgs=0."
  },
  {
    "subject": "books",
    "text": "1) The above fig shows the D -MOSFET operating conditions with gate and source terminals shorted 2) At this stage ID= IDSS where VGS=0V, wit h this voltage VDS, an appreciable drain current IDSS 3) If the gate to source voltage is made negative  i.e."
  },
  {
    "subject": "books",
    "text": "VGs is negative .Positive charges are induced in the channel through the SIO2 of the gate capacitor. 4) Since the current in a FET is due to ma jority carriers(electrons for an N -type material) , the induced positive charges make the channel less conductive and the drain current drops as Vgs is 5) The re distribution of charge in the channel causes an effective depletion of major ity carriers , which accounts for the designation depletion MOSFET."
  },
  {
    "subject": "books",
    "text": "As a result ,Id<Idss.T he actual value of ID depends on the value of Idss,Vgs(off) and Vgs. 1) This operating mode is a result of applying a positive gate to source voltage Vgs to the device. 2) When Vgs is positive the channel is effectiv ely widened."
  },
  {
    "subject": "books",
    "text": "This reduces the resistance of the 3) When Vgs is given positive the majority carriers in the p -type are holes. The holes in the p type 4) At the same t ime, the conduction band electrons (minority carriers) in the p type material are attracted towards the channel by the +gate voltage."
  },
  {
    "subject": "books",
    "text": "5) With the build up of electrons near the channel , the area to the right of the physical channel 6) The extended n type channel now allows more current, Id> Idss The fig. shows the drain characteristics for the N channel depletion type MOSFET 1) The curves are plotted for both Vgs positive and Vgs negative voltages 2) When Vgs=0 and negative the MOSFET operates in depletion mode when Vgs is positive ,the 3) The difference between JFET and D MOSFET is that JFET does not operate for positive values of 4) When Vd s=0, there is no conduction takes place between source to drain, if Vgs<0 and Vds>0 5) But as Vgs,0 induces positive charges holes in the channel, and controls the channel width."
  },
  {
    "subject": "books",
    "text": "Thus the conduction between source to drain is main tained as constant, i.e. Id is constant. 6) If Vgs>0 the gate induces more electrons in channel side, it is added with the free electrons generated by source. again the potential applied to gate determines the channel width and maintains constant current flo w through it as shown in Fig The combination of 3 operating states i.e."
  },
  {
    "subject": "books",
    "text": "Vgs=0V, VGs<0V, Vgs>0V is represented by the D 1) Here in this curve it may be noted that the region AB of the characteristics similar to that of 2) This curve extends for the positive values of Vgs 3) Note that Id=Idss for Vgs=0V when Vgs is negative,Id< Idss when Vgs= Vgs(off) ,Id is reduced to approximately omA.Where Vgs is positive Id>Idss.So obviou sly Idss is not the maximum possible 4) The curves are similar to JFET so thet the D MOSFET have the same transconductance equation."
  },
  {
    "subject": "books",
    "text": "The E MOSFET is capable of operating only in the enhancement mode.The gate potenti al must be 1) when the value of Vgs=0V, there is no channel connecting the source and drain materials. 2) As aresult , there can be no significant amount of drain current."
  },
  {
    "subject": "books",
    "text": "3) When Vgs=0, the Vdd supply tries to force free electrons fr om source to drain but the presence of p-region does not permit the electrons to pass through it. Thus there is no drain current at 4) If Vgs is  positive, it induces a negative charge in the p type substrate just adjacent to the SIO2 5) As the h oles are repelled by the positive gate voltage, the minority carrier electrons attracted toward this voltage."
  },
  {
    "subject": "books",
    "text": "This forms an effective N type bridge between source and drain providing a 6) This +ve gate voltage forma a channel between the source and drain. 7) This produces a thin layer of N type channel in the P type substarate.This layer of free electrons 8)  The minimum Vgs which produces this inversion layer is called threshold voltage and is desig nated by Vgs(th).This is the point at which the device turns on is called the threshold 9)  When the voltage Vgs is <Vgs (th) no current flows from drain to source."
  },
  {
    "subject": "books",
    "text": "10) How ever when the voltage Vgs > Vgs (th) the inversion layer connects the dra in to source and The volt ampere drain characteristics of an N -channel enhancement mode MOSFET are given in the 1) The current Id ss at Vgs\u2264 0 is very small beinf of the order of a few nano amps."
  },
  {
    "subject": "books",
    "text": "2) As Vgs is made +ve , the current Id increases slowly at forst, and then much more rapidly with 3) The standard transconductance formula will not work for the E MOSFET. 4) To de termine the value of ID at a given value of VGs we must use the following relation From the data specification sheets, the 2N7000 has the followin g ratings."
  },
  {
    "subject": "books",
    "text": "One of the primary contributions to electronics made by  MOSFETs  can be found in the area of digital (computer electronics). The signals in digital circuits are mad e up of rapidly switching dc levels. This signal is called as a rectangular wave ,made up of two dc levels (or logic levels)."
  },
  {
    "subject": "books",
    "text": "These A group of circuits with similar circuitry and operating characteristics is referred to as a  logic family. All the circuits in a given logic family respond to the same logic levels, have similar speed and power -handling capabilities  , and can be directly connected together."
  },
  {
    "subject": "books",
    "text": "One such logic family is complementary MOS (or CMOS)  logic. This logic family is made up entirely of  MOSFETs. For the proper functioning of a linear FET amplifier, it is necessary to maintain the operating point Q stable in the central portion of the pinch off region The Q point sh ould be independent of device parameter variations and ambient temperature variations This can be achieved by suitably selecting the gate to source voltage VGS and drain current ID JFET biasing circuits are very similar to  BJT biasing circuitsThe main difference between JFET circuits and BJT circuits is the operation of the active components themselves Self bias is a JFET bias ing circuit that uses a source resistor to help reverse bias the JFET gate."
  },
  {
    "subject": "books",
    "text": "A  self bias circuit is shown in the fig. Self bias is the most common type of JFET bias. This JFET must be operated such that gate source junction is always reverse biased. This c ondition requires a negative VGS for an N channel JFET and a positive VGS for P channel JFET."
  },
  {
    "subject": "books",
    "text": "This can be achieved using the self bias arrangement as shown in Fig. The gate resistor RG doesn\u2019t affect the bias because it has essentially no voltage drop acro ss it, and : the gate remains at 0V .RG is necessary only to isolate an ac signal from ground in amplifier applications."
  },
  {
    "subject": "books",
    "text": "The voltage drop across resistor RS makes gate source junction For the dc analysis coupling capacitors are open circu its. IS produces a voltage drop across RS and makes the source positive  w.r.t ground. In any JFET circuit all the source current passes through the device to the drain circuit .This is due to the fact that there is no (VG =0 because there is no gate current flowing in RG So VG across RG is zero) In the following DC analysis, t he N channel J FET shown in the fig."
  },
  {
    "subject": "books",
    "text": "is used for illustration. For DC analysis we can replace coupling capacitors by open circuits and we can also replace the resistor RG by a short circuit equivalent.:. IG = 0.The relation between ID and VGS is given by Is produces a voltage drop across Rs and makes the source positive w.r.t ground in any JFET circuit all the source current passes through the device to drain circuit this is due to the fact that there is no significant gate current."
  },
  {
    "subject": "books",
    "text": "Therefore we  can define source current as Is=Id and Vg=0 then Typical transfer characteristics for a self biased JFET are shown in the fig. The maximum drain current is 5mA and the gate source cut of f voltage is -3V. This means the gate Now using the equation VGS = -IDRS and assuming RS of any suitable value we can draw the self bias With this Rs , we can plot two points correspon ding to ID = 0 and Id = IDSS By plotting these two points, we can draw the straight line through the points."
  },
  {
    "subject": "books",
    "text": "This line will intersect the transconductance curve and it is known as self bias line.The intersection point gives the operating point of the self bias JFET for the circuit. At Q point , the ID is slightly  > than 2mA and VGS is slightly > -1V."
  },
  {
    "subject": "books",
    "text": "The Q point for the self bias JFET depends on the value of Rs.If Rs is large, Q point far down on the transconductance curve ,ID is small, when Rs is small Q point is far up on the curve , ID is large."
  },
  {
    "subject": "books",
    "text": "The fig. shows N channel JFET with voltage divider bias. The voltage at the source of JFET must be more positive than the voltage at the gate in order to keep the gate to source junction reverse The gate voltage is  set by resistors R1 and R2 as expressed by the following equation using the The Q point of a JFET amplifier , using the voltage divider bias is a."
  },
  {
    "subject": "books",
    "text": "The gate leakage current in a MOSFET is of the order of 10-12A. Hence the input resistance of a MOSFET is very high in the order of 1010  to  1015 \u2126.  The gate leakage current of a JFET is of the order of 10-9A., and its input resistance is of the order of 108\u2126."
  },
  {
    "subject": "books",
    "text": "d. The output characteristics of the JFET are flatter than those of the MOSFET, and hence the e. JFETs are opera ted only in the depletion mode. The depletion type MOSFET may be f. Comparing to JFET, MOSFETs  are easier to fabricate."
  },
  {
    "subject": "books",
    "text": "g. Special digital CMOS circuits are available which involve near zero power dissipation an d very low voltage and current requirements. This makes them suitable for portable Field Effect Transistor (FET) amplifiers provide an excellent voltage gain and high input impedence."
  },
  {
    "subject": "books",
    "text": "Because of high input impede nce and other characteristics of JFETs they are preferred over Similar to BJT CE,CC and CB circuits, only difference is  in BJT large output collector current is controlled by small input base current whereas FET controls output current by means of small input voltage."
  },
  {
    "subject": "books",
    "text": "In both the cases output current is controlled variable. FET amplifier circuits use voltage controlled na ture of the JFET. In Pinch off region, I D depends Source resistance (R S) is used to set the Q -Point but is bypassed by C S for mid -frequency operation."
  },
  {
    "subject": "books",
    "text": "From the small signal equivalent circ uit ,the output voltage For voltage divider bias as in CE Amplifiers of BJT Output impedance is the impedance measured at the output  terminals with the input voltage V I = 0 Normally r d will be far greater than R D ."
  },
  {
    "subject": "books",
    "text": "Hence Z o \u2248 R D determined than V gs, the voltage source in the output circuit is expressed in terms of V gs and Thevenin\u2019s For the proper functioning of a linear FET amplifier, it is necessary to maintain the operating point Q stable in the central portion of the pinch o ff region The Q point should be independent of device parameter variations and ambient temperature variations This can be achieved by suitably selecting the gate to source voltage VGS and drain current ID which is JFET biasing circu its are very similar to BJT biasing circuitsThe main difference between JFET circuits and BJT circuits is the operation of the active components themselves Self bias is a JFET biasing circuit that uses a source resistor to help reverse bias the JFET gate."
  },
  {
    "subject": "books",
    "text": "Self bias is the most common type of JFET bias. This JFET must be operated such that gate source junct ion is always reverse biased. This condition requires a negative VGS for an N channel JFET and a positive VGS for P channel JFET."
  },
  {
    "subject": "books",
    "text": "This can be achieved using the self bias arrangement as shown in and : the gate remains at 0V .RG is necessary only to isolate an ac signal from ground in amplifier applications. The voltage drop across resistor RS makes gate source junction reverse biased."
  },
  {
    "subject": "books",
    "text": "For DC analysis we can replace coupling capacitors by open circuits and   we can also replace       the Is produces a voltage drop across Rs and makes the source positive w.r.t ground in any JFET circuit all the source current passes through the device to drain circuit this is due to the fact therefore we can define source current as Is=Id and Vg=0 then The maxim um drain current is 6mA and the gate source cut off voltage is -3V."
  },
  {
    "subject": "books",
    "text": "This line will intersect the transconductance curve and it is known as self bias line. The intersection point gives the operating point of the self bias JFET for the circui t. At Q point , the ID is slightly  > than 2mA and VGS is slightly > -1V."
  },
  {
    "subject": "books",
    "text": "The Q point for the self bias JFET depends on the value of Rs.If Rs is large, Q point far down on the transconductance curve ,ID is small, when Rs is small Q point is far up on the c urve , ID is large."
  },
  {
    "subject": "books",
    "text": "must be more positive than the voltage at the gate in order to keep the gate to source junction reverse The gate voltage is set by resistors R1 and R2 as expressed by the following equation using the The Q point of a JFET amplifier , using the voltage divider bias is Let us consider the drain characteristics of FET as shown in the fig."
  },
  {
    "subject": "books",
    "text": "In this characteristics we can see that in the region before pinch off voltage, drain characteristics are linear, i.e. FET operation is linear. In this region the FET is useful as a voltage controlled resistor,i.e. the drain to source resistance is controlled by the bias voltage VGS.( In this region only FET behaves like an ordinary resistor This resistances can be varied by VGS ) .The ope ration of FET in the region is useful in most linear applications of FET.In such an application the FET is also referred to as a voltage variable resistor (VVR) or voltage dependent resistor (VDR)."
  },
  {
    "subject": "books",
    "text": "for small values of VDS which may also be expressed as When  the variation of the rd with VGS can be closely approximated by the express ion )  Where ro = drain resistance at zero gate bias.K = a constant, dependent upon FET The VVR property of FET can be used to vary the voltage gain of a multistage amplifier A, as the signal level is incre ased."
  },
  {
    "subject": "books",
    "text": "This action is called AGC automatic gain control. A typical arrangement is Here maximum value of signal is taken rectified; filter to produce a DC voltage proportional to the output signal level. This voltage is applied to the gat e of JFET, this causing the resistance between drain and source to change."
  },
  {
    "subject": "books",
    "text": "As this resistance is connected across RE, so effective RE also changes according to change in the drain to source resistance. When output signal level increases, the drain to sourc e resistance rd increases, increasing effective RE. Increase in RE causes the gain of transistor Q1 to decrease, reducing the output signal."
  },
  {
    "subject": "books",
    "text": "Exactly reverse process takes place when output signal level :: The output signal level is maintained c onstant. It is to be noted that the DC bias conditions of Q1 are not affected by JFET since FET is isolated from Q1 by capacitor C2 MALLAREDDY COLLEGE OF ENGINEERING AND TECHNOLOGY , HYDERABAD B.Tech II Year I Semester Exam inatio ns, Model Paper I -2014 (Common to EEE, ECE, CSE, EIE, BME, IT, MCT, ETM, ECOMPE) i} an  intrinsic  ii}n -type  iii} a p -type semiconductor Indicates the positions of the fermi, the donor &the acceptor levels."
  },
  {
    "subject": "books",
    "text": "(i) Explain when a FET acts as a voltage variable resistor.       (2M) (j) Explain the drain and transfer characteristics of a JFET in details     (3M) Answer all the following questions                                         10x5=50 2.a) Derive an expression for total diode current starting from Boltzmann relationship in terms of the b) The reverse saturation current of a silico n p \u2013 n function diode at an operating temperature of 270C is 3.a) Explain the operation of silicon p \u2013 n junction diode and obtain the forward bias and reverse bias b) Obtain the transition capacitance C T of a junction diode at a reverse bias voltage of 12 V if C T of the diode is given as 15 PF at a reverse bias of 8 V."
  },
  {
    "subject": "books",
    "text": "Differentiate between tran sition and diffusion 4.a) Define the following terms of a rectifier and filter: b) What is the ripple factor if a power supply of 220 V, 50 Hz is to be Full Wa ve rectified and filtered 5.a) Derive expressions for ripple factor of a Full Wave Rectifier with and wi thout a capacitive filter."
  },
  {
    "subject": "books",
    "text": "7.a) Compare the characteristics of a BJT in CB, CE and CC configurations. b) A Silicon BJT is connected in common Emitter configuration with collector \u2013 to \u2013Base bias. Calculate the base resistance R b for the quiescent collector \u2013 to \u2013 Emitter voltag e, V CE has to be 4 V."
  },
  {
    "subject": "books",
    "text": "VCC and R C are given as 2 V and 1 K\u2126 respectively. Assume \u03b2= 100, V BE to be zero volts. Also find the 8.a) Explain how self biasing can be done in a BJT with relevant sketches and waveforms."
  },
  {
    "subject": "books",
    "text": "b) Design a self bias circuit for the fol lowing specifications: V CC = 12 V; V CE = 2V; I C = 4mA; h fe = 80. Assume any other design parameters required. Draw the designed circuit. 9.a) Explain how biasing is provided to a transistor through potential divider bias."
  },
  {
    "subject": "books",
    "text": "List the assumptions made. Lis t the need of bias compensation methods. K\u2126. Biasing is done through a 100 K\u2126 resistance from collector \u2013 to \u2013 Base. Assuming V BE to be zero volts, Find i) The quiescent point ii) The stability factor, \u201eS\u201f."
  },
  {
    "subject": "books",
    "text": "The supply voltage is 12 V. Determine the values of RD and RS so  that ID = 5 mA and VDS = 6V. 11.a) Explain the significance of threshold voltage of a MOSFET. Discuss the methods to reduce MALLAREDDY COLLEGE OF ENGINEERING AND TECHNOLOGY , HYDERABAD B.Tech II Year I Semester Exam inations, Model Paper II -2014 (Common to EEE, ECE, CSE, EIE, BME, IT, MC T, ETM, ECOMPE) (j) Derive Expression for saturation drain current        (3M) Answer all the following questions:       5x10= 50 marks i) Static and dynamic resistances of a p \u2013 n diode."
  },
  {
    "subject": "books",
    "text": "ii) Transition and Diffusion capacitances of a p \u2013 n diode. iii)Volt \u2013 Ampere characteristics of a single silicon p \u2013 n diode and two identical silicon p - n diodes b) A reverse bias voltage of 90V is applied to a Germanium diode through a resistance R."
  },
  {
    "subject": "books",
    "text": "The reverse saturation current of the diode is 50 \u03bcA at an operating temperature of  250C. Compute the diode current 4.a) Define Ripple factor and form factor . Establish a relation between them. b) Explain the necessity of a bleeder resistor in an L \u2013 section filter used with a Full Wave filter."
  },
  {
    "subject": "books",
    "text": "c) Compute ripple factor of an L \u2013 section choke input filter used at the output of a Full wave rectifier 5.a) List out the merits and demerits of Bridge type Full Wave rectifiers over centre tapped type Full b) The secondary voltages of a centre tapped transformer are given as 60V -0V-60V the total resista nce of secondary coil and forward diode resistance of each section of transformer secondary is 62 \u2126."
  },
  {
    "subject": "books",
    "text": "Compute the following for a load resistance of 1 K\u2126. iv) Ripple fact or for 240 V/50Hz supply to primary of transformer. 6.a) Describe the significance of the terms, \u201e\u03b1\u201f and \u201e\u03b2\u201f. Establish a relation between them. b) A transistor is operated at a forward emitter curre nt of 2 mA and with the collector open \u2013 circuited."
  },
  {
    "subject": "books",
    "text": "iii) The region of transistor operation (Saturation/Active/Cut -off). 7.a) Describe the functioning of a BJT in common base configuration. b) Determine the collector current of a BJT with both of its junctions reverse biased. Assume I CO = 5\u03bcA, c) How do you identify the region of operation of a BJT to be saturation region from the values of 8.a) Justify statement \u201cPotential divider bias is the most commonly used biasing method\u201d for BJT circuits."
  },
  {
    "subject": "books",
    "text": "Explain how bias compensation can be done in such biasing through diodes. b) An NPN transistor with \u03b2= 100 is used in common Emitter configuration with Collector \u2013 to \u2013 Base bias. If VCC = 10 V, RC = 1 K and VBE = 0 V, determine i)Rb such that quiescent Collector \u2013 to \u2013 9.a) Define all the four hybrid parameters of a BJT in CE configuration."
  },
  {
    "subject": "books",
    "text": "Draw the circuit and its b) The source and load resistances connected to a BJT amplifier in CE configuration are 680\u2126 and 1 K\u2126 respectively. Calculate the voltage gain AV and the input Compute A V and R i using both approximate and exact analysis."
  },
  {
    "subject": "books",
    "text": "JFET if the thickness of its gate region is c) Establish a relation between the three JFET parameters, \u03bc, r d and g m. MALLAREDDY COLLEGE OF ENGINEERING AND TECHNOLOGY , HYDERABAD B.Tech II Year I Semester Exam inations, Model Paper III -2014 (Common to EEE, ECE, CSE, EIE, BME, IT, MCT, ETM, ECOMPE) Answer all the following questions:       5x10= 50 marks b) Find the value of D.C."
  },
  {
    "subject": "books",
    "text": "Explain its operation with necessary b) A full wave rectifier circuit uses two  silicon diodes with a forward resistance of 20 \u2126 each. A DC iii) ripple factor iv) Transformer secondary voltage rating. 5.a) Draw the circuit of full -wave rectifier with L -sectio n filter and derive  expression b) A 230 V, 60Hz voltage is applied to the primary of a 5:1 step down, center tapped transformer used in a full wave rectifier having a load of 900\u2126."
  },
  {
    "subject": "books",
    "text": "b) The reverse leakage current of the transistor when connected in CB configuration 7.a) With the help of a neat diagram explain different current components in an NPN b) With reference to bipolar junction transistors, define the following term s and 8.a) Explain how ICO  variations are compensated with the help of diode and thermistor in transistor b) Design a collector to base bias circuit us ing silicon transistor to achieve a stability 9.a) Explain the basic requirements of transistor biasing."
  },
  {
    "subject": "books",
    "text": "Verify these requirements in Emitter feedback b) An NPN Silicon transistor with \u03b2=50 is used in a common emitter circuit with VCC=10V, RC=2K. The bias is obtained by connec ting a 100K resistance from collector to base. Find i) Q -Point ii) Stability 10.a) Explain the construction & operation of  an P-channel enhancement and depletion MOSFET with the help of static drain characteristics and transfer characteristics."
  },
  {
    "subject": "books",
    "text": "b) Explain why field effect transistor is called as unipolar and voltage controlled de vice 11.a) With neat sketches, necessary equations explain the drain & transfer MALLAREDDY COLLEGE OF ENGINEERING AND TECHNOLOGY , HYDERABAD B.Tech II Year I Semester Exam inations, Model Paper V -2014 (Common to EEE, ECE, CSE, EIE, BME, IT, MCT, ETM, ECOMPE) 1.Answer all the following questions:               5x2= 10 marks b) Which type of diode c apacitance is used in the varactor diode, explain."
  },
  {
    "subject": "books",
    "text": "Explain its ope ration with necessary is 18 m A when the same transistor is connected in CE configuration. a) Compar e the three transistor amplifier configurations with related to A 4. Draw a fixed bias circuit and explain its operation."
  },
  {
    "subject": "books",
    "text": "Kirchhoff's circuit laws  are two  equalities  that deal with the current  and potential difference  (commonly known as voltage) in the  lumped element model  of electrical circuits . They were  first described  in 1845 by German physicist  Gustav Kirchhoff .[1] This generalized the work of  Georg Ohm  and preceded the work of James Clerk Maxwell ."
  },
  {
    "subject": "books",
    "text": "Widely used in  electrical engineering , they are also called  Kirchhoff's rules  or simply  Kirchhoff's laws. These laws can be applied in time and frequency domains and form Both of Kirchhoff's laws can be understood as corollaries of Maxwell's equations  in the low -frequency limit."
  },
  {
    "subject": "books",
    "text": "They are accurate for DC circuits, and for AC circuits at frequencies where the wavelengths of electromagnetic radiation are very large This law, also called  Kirchhoff's first law, or  Kirchhoff's junction rule, states that, \u201c for any node (junction) in an electrical circuit , the sum of  currents  flowing into that node is equal to the sum of currents flowing out of that Recalling that current is a signed (positive or negative) quantity reflecting direction towards or away from a node, where  n is the total number of branches with currents The current entering the junction is equal to the current \u201cThe directed sum of the  potential differences  (voltages) Similarly to Kirchhoff's current law, the voltage law can be Here,  n is the total number of voltages measured."
  },
  {
    "subject": "books",
    "text": "The sum of all voltages around a loop is zero: v1 + v 2 + v 3 + b) Procedures employed when analysing electrical circuits The following are the step -by-step analysis of electric circuits \u2022 Identify Nodes/Junctions : Mark and label all nodes \u2022 Identify Loops/Meshes : Identify all independent \u2022 Assign Current Directions : Arbitrarily assign a unique current and direction to each independent branch."
  },
  {
    "subject": "books",
    "text": "If the calculated current is negative, its actual direction resistors, assign voltage polarity signs such that the current flows into the positive terminal and out of the negative terminal (passive sign convention). Voltage 2. Apply Kirchhoff's Current Law (KCL) at the Nodes: \u2022 Apply KCL to all but one of the essential nodes to 3."
  },
  {
    "subject": "books",
    "text": "Apply Kirchhoff's Voltage Law (KVL) to the Loops: \u2022 For each independent loop, write an equation based algebraic sum of all voltage changes (rises and drops) \u2022 Choose a direction to traverse the loop (clockwise or conventions: voltage rises (moving from - to + across a source or against current through a resistor) are positive, and voltage drops (moving from + to - across \u2022 You will have a system of linear equations from KCL \u2022 Use standard algebraic techniques (substitution, \u2022 Check your answers to ensure they satisfy all the \u2022 Use circuit simulation software or alternative analysis methods (like Thevenin's or Nodal analysis) to cross - In the circuit shown in figure, find the value of current through 100 Find the voltage across the resistor 'R' in figure."
  },
  {
    "subject": "books",
    "text": "For the circuit shown in figure, determine the unknown voltage drop  V1 Kirchhoff's Laws are fundamental to modern electrical engineering and are applied daily in countless devices and Kirchhoff's Current Law (KCL): The \"Junction Rule\" KCL is based on the  conservation of charge, stating that the total current entering any junction (node) in a circuit must equal the total current leaving it."
  },
  {
    "subject": "books",
    "text": "This is like water flow in pipes; the amount of water flowing in must equal the amount home, multiple lights and outlets are connected in parallel to the main power line. The current from the main line splits at various junctions to power each appliance."
  },
  {
    "subject": "books",
    "text": "KCL ensures the system is balanced, so the total current drawn by all connected devices equals the multiple devices (phone, laptop, watch) into a single power strip or a multi -port USB charger, the main current from the wall outlet splits into different paths for each device."
  },
  {
    "subject": "books",
    "text": "KCL is applied in the charger's design to guarantee that the sum of currents going to all devices matches the total input current, preventing iii. Printed Circuit Boards (PCBs):  Inside electronic distributed among microchips, transistors, and other components. KCL is crucial during the design phase to ensure every component receives the correct current iv."
  },
  {
    "subject": "books",
    "text": "Electrical Grid Management:  On a large scale, power engineers use KCL to manage the distribution of electricity across complex power grids. It helps balance the load, ensuring that power supplied from KVL is based on the  conservation of energy, stating that the sum of all voltage changes (rises and drops) around any closed loop in a circuit must equal zero."
  },
  {
    "subject": "books",
    "text": "This is analogous to a hike on a mountain; if you start and end at the same elevation, your total change in v. Battery -Powered Devices (Series Circuits):  In a TV remote or a flashlight that uses multiple batteries in available to power the device."
  },
  {
    "subject": "books",
    "text": "The sum of voltages from each battery equals the total voltage drop across vi. Automotive Electrical Systems:  In a car, KVL is used to analyze the complex wiring for the headlights, radio, and engine control units. When troubleshooting measure voltage drops across different sections of the circuit (wiring, fuse, swit ch) to pinpoint a poor connection or degraded wiring causing an unexpected vii."
  },
  {
    "subject": "books",
    "text": "Dimmer Switches and Voltage Dividers:  Dimmer variable resistance in the circuit, changing the voltage drop across the switch itself. The remaining voltage across the light bulb is reduced, making it dimmer. This controlled voltage distribution ensures the bulb battery cells within a large battery pack, ensuring overcharging/discharging, and enhancing  the battery's."
  },
  {
    "subject": "books",
    "text": "Measure and record the peak -to-peak output voltage VO and th e phase relationship between V in and VO. The open -circuit voltage gain A V is V O/Vin. 4. To measure the voltage gain from source -to-load, V L/VS of the common emitter 5."
  },
  {
    "subject": "books",
    "text": "With the signal generator's frequency se t to 10 kHz, and V S = 50mVp -p. Measure and record the peak -to-peak output voltage VL and the phase relationship between V in and VL. The voltage gain from source to load is V L /VS.."
  },
  {
    "subject": "books",
    "text": "\u2022Data visualization is the graphical representation of information and data. \u2022By using visual elements like charts , graphs , and maps , data visualization tools provide an accessible way to see and understand trends, outliers, and \u2022Additionally , it provides an excellent way to present data to non -technical \u2022The term is often used interchangeably with others, including information graphics , information visualization and statistical graphics ."
  },
  {
    "subject": "books",
    "text": "\u2022Data visualization provides a quick and effective way to communicate information in a universal manner using visual information . \u2022It is the practice of translating information into a visual context, such as a map or graph, to make data easier for the human brain to understand and pull \u2022The main goal of data visualization is to make it easier to identify patterns , \u2022Data visualization is an element of the broader Data Presentation Architecture (DPA) discipline, which aims to identify , locate , manipulate , format and deliver \u2022Data visualization is important for almost every career."
  },
  {
    "subject": "books",
    "text": "\u2022It can be used by teachers to display student test results, by computer scientists exploring advancements in artificial intelligence (AI) or by executives \u2022It also plays an important role in big data projects. \u2022As businesses accumulated massive collections of data during the early years of the big data trend , they needed a way to get an overview of their data \u2022The most common visualization technique used including the following: \u2022An infographic is defined as a visualization of data that tries to convey complex information to an audience in a manner than can be quickly \u2022An infographic is a collection of imagery , data visualizations like pie charts and bar graphs , and minimal text that gives an easy -to-understand overview of a \u2022Bubble cloud charts are useful for illustrating the relationship between \u2022For example, you can visualize data collected from different cities , and represent each city as a bubble whose size is proportional to the value for \u2022A bullet graph , or a bullet chart , is a variation of a bar chart, typically consisting of a primary bar layered on top of a secondary stack of less -prominent bars."
  },
  {
    "subject": "books",
    "text": "\u2022Bullet graphs are best used for making comparisons , such as showing progress \u2022Line charts. Line charts display how variables can change over time. \u2022Area charts. This displays multiple values in a time series or a sequence of data collected at consecutive, equally spaced points in time."
  },
  {
    "subject": "books",
    "text": "\u2022Scatter plots. This technique displays the relationship between two variables. \u2022Treemaps . This method shows hierarchical data in a nested format. The size of the rectangles used for each category is proportional to its percentage of the whole. Treemaps are best used when multiple categories are present , and the \u2022System visualization is the process of mapping the flow and/or function of a \u2022Visualizations are beneficial to help a team more quickly diagnose issues, communicate across departments, and efficiently build or update a system."
  },
  {
    "subject": "books",
    "text": "\u2022A display is a core ingredient in a human -machine interface (HMI), the dynamic device through which information is entered and presented, as text \u2022Not too many years ago, the CRT (cathode ray tube) monitor large , heavy, \u2022Two main technologies, liquid crystals and organic light -emitting diodes , currently dominate the market for visual displays."
  },
  {
    "subject": "books",
    "text": "\u2022An older technology, the cathode ray tube, has all but vanished from the scene, and plasma monitors also see use in some applications . 17\u2022A display is an electronic device whose main purpose is an interface to show the reading (information) as the result of a certain process of a \u2022The information (data types) could be a text, picture (images) , or video \u2022In simple terms, pixel response provides flexibility the amount depending on display type to create graphics and text in combination, in monochrome \u2022This type of display has a big size, heavy, and bulky \u20227-Segment LED display can be used for displaying digits and \u2022A seven segment display consists of 7 LEDs arranged in the form of Square \u20188\u2019 and a single LED as dot character."
  },
  {
    "subject": "books",
    "text": "\u2022Different characters can be displayed by selecting the very good, their working lifetime is currently not display, you normally never see it directly , only \u2022The LCD is much more informative output device than \u2022The LCD is a display that can easily show characters applications to display graphic images such as 16\u00d72 \u2022The most common add -on to an LCD is a touch -panel ."
  },
  {
    "subject": "books",
    "text": "\u2022In this four-wire resistive technology example, a glass panel is uniformly coated with electrically conductive and resistive layers . \u2022A polyester cover sheet is suspended over the top of the glass and separated from it by small, transparent insulating separators ."
  },
  {
    "subject": "books",
    "text": "\u2022During operation, an electrical current moves through the touchscreen . \u2022When activated by a touch, the conductive coating makes contact with the coating on the glass and a touch point is registered. \u2022Images are brought to the display surface by a backlight , typically CCFL (cold cathode fluorescent lamps) powered by a high-voltage power supply called an \u2022As light -emitting diode (LED) and organic light -emitting diode (OLED) technologies advance in power consumption and lumen output, they are \u2022A logic -powered light source, the LED requires no inverter ."
  },
  {
    "subject": "books",
    "text": "\u2022While CCFL is still the backlight of choice in large displays and laptops, LEDs are found in smaller displays (5-in. diagonal and less), cellphones, and a variety of other devices, such as intelligent thermostats. \u2022OLED displays embody low voltage, 3x self -illumination, and high brightness."
  },
  {
    "subject": "books",
    "text": "\u2022With improving life, future OLED use will escalate. \u2022A plasma display panel (PDP) is a type of flat panel display that uses small cells containing plasma: ionized gas that responds to \u2022Plasma televisions were the first large (over 32 inches diagonal) \u2022A plasma display screen consists of tiny gas capsules arranged in a grid; when stimulated by electricity, the gas glows much in the \u2022Instead of having a beam that scans, a plasma produces light from its pixels when an electric charge is applied to a cell containing a noble gas , \u2022These plasma chambers are sealed units, the gas will never escape."
  },
  {
    "subject": "books",
    "text": "\u2022However , LCDs are more energy -efficient than plasmas ; due to battery life concerns, virtually all laptop computers have LCD screens and not plasma \u2022Most plasma screens currently sold tend to be in the 40 -inch to 60 -inch size range where image quality helps justify the greater energy consumption."
  },
  {
    "subject": "books",
    "text": "\u2022It determines the total number of pixels on the screen . \u2022The most common is 1920 \u00d71080 that is Full-HD or 1080p. \u2022On its development, more resolution is introduced such as 2K, \u2022This is often explained in inch size , e.g."
  },
  {
    "subject": "books",
    "text": "22\u201d, 55\u201d etc. \u2022The size is measured diagonally just for your information. \u2022To keep the image quality sharp and clear , a bigger size display CGA Color Graphics Adapter 640 x 200  ( monochrome ) EGA Enhanced Graphics Adapter 640 x 350 (4 -color) \u2022It represents how often a display can update per second (Hertz or Hz)."
  },
  {
    "subject": "books",
    "text": "\u2022The common refresh rates are 60Hz, 75Hz, 90Hz, 120Hz -Gaming, and 144Hz - \u2022It is measured by two numbers such as 160/120 where 160 is the horizontal viewing angle and 120 is the vertical viewing angle . \u2022As long as you are in 160 out of 180 degrees horizontally and 120 out 180."
  },
  {
    "subject": "books",
    "text": "Microprocessor an integrated circuit that contains all the functions of a central processing unit of a Microprocessor is any of a type of miniature electronic device that contains the arithmetic, logic and control circuitry necessary to perform the functions of a digital computer\u2019s central processing unit."
  },
  {
    "subject": "books",
    "text": "In effect, this kind of integrated circuit can interpret and execute program instructions as well Computer architecture  is a set of rules and methods that describe the functionality, organization, and implementation of computer systems. The architecture of a system refers to its structure in terms of separately specified components of that system and their interrelationships."
  },
  {
    "subject": "books",
    "text": "The  IAS computer,although not completed until 1952,is the prototype of all subsequent general-purpose Figure 1 shows the general structure of the IAS computer). 1.A main memory, which stores both data and instruction 2.An arithmetic and logic unit (ALU) capable of operating on binary data 3.A control unit, which interprets the instructions in memory and causes them to be executed 4.Input and output (I/O) equipment operated by the control unit This structure was outlined in von Neumann\u2019s earlier proposal, which is worth quoting at this 1.Because the device is primarily a computer, it will have to perform the elementary operations of arithmetic most frequently."
  },
  {
    "subject": "books",
    "text": "By the central control and the organs which perform it form the second specific part: CC 3.Any device which is to carry out long and complicated sequences of operations (specifically of calculations) must have a considerable memory . . . At any rate, the total memory constitutes the third specific part of the device: M."
  },
  {
    "subject": "books",
    "text": "These organs form its output, the fifth specific part: O. The control unit operates the IAS by fetching instructions from memory and executing them one at a time. A more detailed structure diagram is shown in Figure 2. This figure reveals that both the control unit and the ALU contain storage locations, called registers, defined as follows: 1.Memory buffer register (MBR): Contains a word to be stored in memory or sent to the I/O unit, or is used to receive a word from memory or from the I/O unit."
  },
  {
    "subject": "books",
    "text": "The transistor is smaller, cheaper, and dissipates less heat than a vacuum tube but can be used in the same way as a vacuum tube to construct computers. Unlike the vacuum tube, which requires wires, metal plates, a glass capsule, and a vacuum, the transistor is a solid- state device, The transistor was invented at Bell Labs in 1947 and by the 1950s had launched an electronic revolution."
  },
  {
    "subject": "books",
    "text": "It was  not  until  the  late  1950s,  however,  that  fully  transistorized  computers  were The use of the transistor defines the second generation of computers. It has become widely accepted to classify computers into generations based on the fundamental hardware technology employed THE IBM 7094 From the introduction of the 700 series in 1952 to the introduction of the last member of the 7000 series in 1964, this IBM product line underwent an evolution that is typical of computer products."
  },
  {
    "subject": "books",
    "text": "Successive members of the product line show increased performance, increased In  1958  came  the  achievement  that  revolutionized  electronics  and  started  the  era  of microelectronics: the invention of the integrated circuit. It is the integrated circuit that defines the MICROELECTRONICS:  Microelectronics  means,  literally,  \u201csmall  electronics.\u201d  Since  the beginnings  of  digital  electronics  and  the  computer  industry,  there  has  been  a  persistent  and consistent trend toward the reduction in size of digital electronic circuits."
  },
  {
    "subject": "books",
    "text": "An alternative approach to processor design in the reduced instruction set computer (RISC). The ARM architecture is used in a wide variety of embedded systems and is one of the most powerful and best-designed RISC-based In terms of market share, Intel has ranked as the number one maker of microprocessors for non- embedded  systems  for  decades,  a  position  it  seems  unlikely  to  yield."
  },
  {
    "subject": "books",
    "text": "Interestingly,  as microprocessors have grown faster and much more complex, Intel has actually picked up the pace. Intel used to develop microprocessors one after another, every four years. It is worthwhile to list some of the highlights of the evolution of the Intel product line: 8-bit data path to memory."
  },
  {
    "subject": "books",
    "text": "The 8080 was used in the first personal computer, the Altair. registers, the 8086 sported an instruction cache, or queue, that prefetches a few instructions before they are executed. A variant of this processor, the 8088, was used in IBM\u2019s first personal computer, securing the success of Intel."
  },
  {
    "subject": "books",
    "text": "The 8086 is the first appearance of the x86 architecture, the 80386 rivaled the complexity and power of minicomputers and mainframes introduced just a few years earlier. This was the first Intel processor to support multitasking, meaning it could run multiple programs at the same time."
  },
  {
    "subject": "books",
    "text": "technology and sophisticated instruction pipelining. The 80486 also offered a built-in math coprocessor, offloading complex math operations from the main CPU. 6.Pentium: With the Pentium, Intel introduced the use of superscalar techniques, which allow 7.Pentium Pro: The Pentium Pro continued the move into superscalar organization begun with the Pentium, with aggressive use of register renaming, branch prediction, data flow analysis, 8.Pentium II: The Pentium II incorporated Intel MMX technology, which is designed specifically to process video, audio, and graphics data efficiently."
  },
  {
    "subject": "books",
    "text": "9.Pentium III: The Pentium III incorporates additional floating-point instructions to support 10.Pentium 4: The Pentium 4 includes additional floating-point and other enhancements for 11.Core:  This  is  the  first  Intel  x86  microprocessor  with  a  dual  core,  referring  to  the implementation of two processors on a single chip."
  },
  {
    "subject": "books",
    "text": "so  that  there  are  now  over  500 13.The x86 provides an excellent illustration of the advances in computer hardware over the past 30 years. The 1978 8086 was introduced with a clock speed of 5 MHz and had 29,000 transistors. A quad-core Intel Core 2 introduced in 2008 operates at 3 GHz, a speedup of a factor of 600, and has 820 million transistors, about 28,000 times as many as the 8086."
  },
  {
    "subject": "books",
    "text": "Yet the Core 2 is in only a slightly larger package than the 8086 and has a comparable cost. Year by year, the cost of computer systems continues to drop dramatically, while the performance and capacity of those systems continue to rise equally dramatically."
  },
  {
    "subject": "books",
    "text": "In microprocessors, the addition of new circuits, and the speed boost that comes from reducing the distances between them, has improved performance four- or fivefold every three years or so since Intel launched its x86 family in 1978. The more elaborate techniques for feeding the monster into contemporary processors are the following: 1.Branch prediction: The processor looks ahead in the instruction code fetched from memory and predicts which branches, or groups of instructions, are likely to be processed next 2.Data flow analysis: The processor analyzes which instructions are dependent on each other\u2019s results, or data, to create an optimized schedule of instructions 3.Speculative execution: Using branch prediction and data flow analysis, some processors speculatively execute instructions ahead of their actual appearance in the program execution, While processor power has  raced ahead at breakneck speed, other critical components of the computer have not kept up.The result is a need to look for performance balance: an adjusting of the organization and architecture to compensate for the mismatch among the capabilities of the various The interface between processor and main memory is  the most crucial pathway in the entire computer because it is responsible for carrying a constant flow of program instructions and data There are a number of ways that a system architect can attack this problem, all of which are reflected in contemporary computer designs."
  },
  {
    "subject": "books",
    "text": "Consider the following examples: 1.Increase the number of bits that are retrieved at one time by making DRAMs \u201cwider\u201d rather 2.Change the DRAM interface to make it more efficient by including a cache7 or other 3.Reduce  the  frequency  of  memory  access  by  incorporating  increasingly  complex  and efficient cache structures between the processor and main memory."
  },
  {
    "subject": "books",
    "text": "4.Increase the interconnect bandwidth between processors and memory by using higher- speed buses and by using a hierarchy of buses to buffer and structure data flow. Improvements in Chip Organization and Architecture There are three approaches to achieving increased processor speed: 2.Increase the size and speed of caches that are interposed between the processor and main memory."
  },
  {
    "subject": "books",
    "text": "In particular, by dedicating a portion of the processor chip itself to the cache, cache 3.Make changes to the processor organization and architecture that increase the effective However, as clock speed and logic density increase, a number of obstacles become more 1.Power: As the density of logic and the clock speed on a chip increase, so does the power 2.RC delay: The speed at which electrons can flow on a chip between transistors is limited by the  resistance  and  capacitance  of  the  metal  wires  connecting  them;  specifically,  delay increases as the RC product increases."
  },
  {
    "subject": "books",
    "text": "As components on the chip decrease in size, the wire interconnects become thinner, increasing resistance. Also, the wires are closer together, 3.Memory latency: Memory speeds lag processor speeds. Beginning in the late 1980s, and continuing for about 15 years, two main strategies have been used to increase performance beyond what can be achieved simply by increasing clock speed."
  },
  {
    "subject": "books",
    "text": "A superscalar approach in essence allows multiple pipelines within a single processor so that instructions that do not depend on one another can be executed in parallel. Virtually  all  contemporary  computer  designs  are  based  on  concepts  developed  by  John  von Neumann at the Institute for Advanced Studies, Princeton."
  },
  {
    "subject": "books",
    "text": "Such a design is referred to as the von Neumann architecture and is based on three key concepts: 1.Data and instructions are stored in a single read\u2013write memory. 2.The contents of this memory are addressable by location, without regard to the type of data 3.Execution occurs in a sequential fashion (unless explicitly modified) from one instruction to If there is a particular computation to be performed, a configuration of logic components designed specifically for that computation could be constructed."
  },
  {
    "subject": "books",
    "text": "The resulting \u201cprogram\u201d is in the form of Now consider this alternative. Suppose we construct a general-purpose configuration of arithmetic and logic functions. This set of hardware will perform various functions on data depending on control signals applied to the hardware."
  },
  {
    "subject": "books",
    "text": "For this we need some sort of input module. A means of reporting results is needed, and this is in the form of an output module. Taken together, these are referred to as There must be a place to store temporarily both instructions and data."
  },
  {
    "subject": "books",
    "text": "That module is called memory,  or  main  memory  to  distinguish  it  from  external  storage  or  peripheral  devices.  V on Neumann pointed out that the same memory could be used to store both instructions and data. Figure 4 illustrates these top-level components and suggests the interactions among them."
  },
  {
    "subject": "books",
    "text": "Similarly, an I/O address register (I/OAR) specifies a particular I/O device. An I/O buffer (I/OBR) register is used for the exchange of data between an A memory module consists of a set of locations, defined by sequentially numbered addresses. Each location contains a binary number that can be interpreted as either an instruction or data."
  },
  {
    "subject": "books",
    "text": "An I/O module transfers data from external devices to CPU and memory, and vice versa. It contains internal buffers for temporarily holding these data until they can be sent on. The basic function performed by a computer is execution of a program, which consists of a set of instructions stored in memory."
  },
  {
    "subject": "books",
    "text": "Instruction processing consists of two steps: The processor reads (fetches) instructions from memory one at a time and executes each instruction. Program execution consists of repeating the process of instruction fetch and instruction execution. The processing required for a single instruction is called an instruction cycle."
  },
  {
    "subject": "books",
    "text": "Using the simplified two-step description given previously, the instruction cycle is depicted in Figure 5. The two steps are referred to as the fetch cycle and the execute cycle. Program execution halts only if the machine is turned off, some sort of unrecoverable error occurs, or a program instruction that halts the At the beginning of each instruction cycle, the processor fetches an instruction from memory."
  },
  {
    "subject": "books",
    "text": "If the program counter is set to location 300. The processor will next fetch the instruction at location 300. On next instruction cycles, it will fetch instructions from locations 301,302,303,and so on. The fetched instruction is loaded into a register in the processor known as the instruction register (IR)."
  },
  {
    "subject": "books",
    "text": "Consider a simple example using a hypothetical machine that includes the characteristics listed in Figure 6. The processor contains a single data register, called an accumulator (AC). Both instructions and data are 16 bits long. Thus, it is convenient to organize memory using 16-bit words."
  },
  {
    "subject": "books",
    "text": "This instruction (the value 1940 in hexadecimal) is loaded into the instruction register IR and the PC is incremented. 2.The first 4 bits (first hexadecimal digit) in the IR indicate that the AC is to be loaded. The remaining 12 bits (three hexadecimal digits) specify the address (940) from which data are 3.The next instruction (5941) is fetched from location 301 and the PC is incremented."
  },
  {
    "subject": "books",
    "text": "4.The old contents of the AC and the contents of location 941 are added and the result is 5.The next instruction (2941) is fetched from location 302 and the PC is incremented. 6.The contents of the AC are stored in location 941."
  },
  {
    "subject": "books",
    "text": "3.Read the contents of memory location B into the processor. In order that the contents of A are not lost, the processor must have at least two registers for storing memory values, rather 5.Write the result from the processor to memory location A."
  },
  {
    "subject": "books",
    "text": "Interrupts are provided primarily as a way to improve interleaved with processing. Code segments 1, 2, and 3 refer to sequences of instructions that do not involve I/O. The WRITE calls are to an I/O program that is a system utility and that will perform the actual I/O operation."
  },
  {
    "subject": "books",
    "text": "Without the use of interrupts, once this command is issued, the program must wait for the I/O device to perform the requested function (or periodically poll the device). The program might wait by simply repeatedly performing a test operation to 3.A sequence of instructions, labeled 5 in the figure, to complete the operation."
  },
  {
    "subject": "books",
    "text": "This may include setting a flag indicating the success or failure of the operation. Figure 9 Program Flow of Control Without and With Interrupts INTERRUPTS AND THE INSTRUCTION CYCLE With interrupts, the processor can be engaged in executing other instructions while an I/O operation is in progress."
  },
  {
    "subject": "books",
    "text": "Meanwhile, the external device is busy accepting data from computer memory and printing it. This I/O operation is conducted concurrently with the execution When the external device becomes ready to accept more data from the processor,\u2014the I/O module for that external device sends an interrupt request signal to the processor."
  },
  {
    "subject": "books",
    "text": "The processor responds by suspending operation of the current program, branching off to a program to service that particular I/O device, known as an interrupt handler, and resuming the original execution after the device is serviced. The points at which such interrupts occur are indicated by an asterisk in Figure 9b."
  },
  {
    "subject": "books",
    "text": "From the point of view of the user program, an interrupt is just that: an interruption of the normal sequence of execution. When the interrupt processing is completed, execution resumes (Figure To accommodate interrupts, an interrupt cycle is added to the instruction cycle, as shown in In the interrupt cycle, the processor checks to see if any interrupts have occurred."
  },
  {
    "subject": "books",
    "text": "If no interrupts are pending, the processor proceeds to the fetch cycle and fetches the next instruction of the current program. If an interrupt is pending, the processor does the following: 1.It suspends execution of the current program being executed and saves its context 2.It sets the program counter to the starting address of an interrupt handler routine."
  },
  {
    "subject": "books",
    "text": "The processor now proceeds to the fetch cycle and fetches the first instruction in the interrupt handler program, which will service the interrupt. When the interrupt handler routine is completed, the processor can resume execution of the user program at the point of interruption."
  },
  {
    "subject": "books",
    "text": "Consider Figure 12, which is a timing diagram based on the flow of control in Figures 9a and 9b. Figure 9c indicates this state of affairs. In this case, the user program reaches the second WRITE call before the I/O operation spawned by the first call is complete."
  },
  {
    "subject": "books",
    "text": "The result is that the user program is hung up at that point. When the preceding I/O operation is completed, this new timing for this situation with and without the use of interrupts. We can see that there is still a gain in efficiency because part of the time during which the I/O operation is underway overlaps with the Figure 14 shows a revised instruction cycle state diagram that includes interrupt cycle MULTIPLE INTERRUPTS Multiple interrupts can occur."
  },
  {
    "subject": "books",
    "text": "Two approaches can be taken to dealing The first is to disable interrupts while an interrupt is being processed. A disabled interrupt simply means that the processor can and will ignore that interrupt request signal. Thus, when a user program  is  executing  and  an  interrupt  occurs,  interrupts  are  disabled  immediately."
  },
  {
    "subject": "books",
    "text": "After  the interrupt handler routine completes, interrupts are enabled before resuming the user program and the processor checks to see if additional interrupts have occurred. This approach is nice and simple, as interrupts are handled in strict sequential order (Figure 15a)."
  },
  {
    "subject": "books",
    "text": "The drawback to the preceding approach is that it does not take into account relative priority or A second approach is to define priorities for interrupts and to allow an interrupt of higher priority to cause a lower-priority interrupt handler to be itself interrupted (Figure 15b)."
  },
  {
    "subject": "books",
    "text": "At t = 10, a printer interrupt occurs; user information is placed on the system stack and execution continues at the printer interrupt service routine (ISR). While this routine is still executing, at t = 15, a communications interrupt occurs. Because the communications line has higher priority than the printer, the interrupt is honored."
  },
  {
    "subject": "books",
    "text": "The printer ISR is interrupted, its state is pushed onto the stack,and execution continues at the communications ISR.While this routine is executing, a disk interrupt occurs (t = 20). Because this interrupt is of lower priority, it is simply held, and the communications ISR runs to completion."
  },
  {
    "subject": "books",
    "text": "When the communications ISR is complete (t = 25), the previous processor state is restored, which is the execution of the printer ISR. However, before even a single instruction in that routine can be executed, the processor honors the higher-priority disk interrupt and control transfers to the disk ISR."
  },
  {
    "subject": "books",
    "text": "Only when that routine is complete (t = 35) is the printer ISR resumed. When that routine completes (t = 40), control finally returns to the user program. An I/O module (e.g., a disk controller) can exchange data directly with the processor."
  },
  {
    "subject": "books",
    "text": "Just as the processor can initiate a read or write with memory, designating the address of a specific location, the processor can also read data from or write data to an I/O module In some cases, it is desirable to allow I/O exchanges to occur directly with memory."
  },
  {
    "subject": "books",
    "text": "This operation is known as direct memory access (DMA). A bus is a communication pathway connecting two or more devices. A key characteristic of a bus is that  it  is  a  shared  transmission  medium.  Multiple  devices  connect  to  the  bus,  and  a  signal transmitted by any one device is available for reception by all other devices attached to the bus."
  },
  {
    "subject": "books",
    "text": "If two devices transmit during the same time period, their signals will overlap and become garbled. Thus, only one device at a time can successfully transmit. Typically, a bus consists of multiple communication pathways, or lines. Each line is capable of transmitting signals representing binary 1 and binary 0."
  },
  {
    "subject": "books",
    "text": "An 8-bit unit of data can be transmitted over eight bus lines. A bus that connects major computer components (processor, memory, I/O) is called control lines. In addition, there may be power distribution lines that supply power to the attached The data lines provide a path for moving data among system modules."
  },
  {
    "subject": "books",
    "text": "These lines, collectively, are The address lines are used to designate the source or destination of the data on the data bus. For example, on an 8-bit address bus, address 01111111 and below might reference locations in a memory module (module 0) with 128 words of memory, and address 10000000 and above refer to The control lines are used to control the access to and the use of the data and address lines."
  },
  {
    "subject": "books",
    "text": "Control signals transmit both command and timing information among system modules. Timing signals indicate the validity of data and address information. Command signals specify operations 1.Memory write: Causes data on the bus to be written into the addressed location 2.Memory read: Causes data from the addressed location to be placed on the bus 3.I/O write: Causes data on the bus to be output to the addressed I/O port 4.I/O read: Causes data from the addressed I/O port to be placed on the bus 5.Transfer ACK: Indicates that data have been accepted from or placed on the bus 6.Bus request: Indicates that a module needs to gain control of the bus 7.Bus grant: Indicates that a requesting module has been granted control of the bus 8.Interrupt request: Indicates that an interrupt is pending 9.Interrupt ACK: Acknowledges that the pending interrupt has been recognized The operation of the bus is as follows."
  },
  {
    "subject": "books",
    "text": "It must then wait for that second The classic physical arrangement of a bus is depicted in Figure 18. Figure 18 Typical Physical Realization of a Bus Architecture In this example, the bus consists of two vertical columns of conductors. Each of the major system components occupies one or more boards and plugs into the bus at these slots."
  },
  {
    "subject": "books",
    "text": "Thus, an on-chip bus may connect the processor and cache memory, whereas an on-board bus may connect the processor This arrangement is most convenient. A small computer system may be acquired and then expanded later (more memory, more I/O) by adding more boards."
  },
  {
    "subject": "books",
    "text": "If a component on a board fails, that board If a great number of devices are connected to the bus, performance will suffer. There are two main 1.In general, the more devices attached to the bus, the greater the bus length and hence the 2.The bus may become a bottleneck as the aggregate data transfer demand approaches the Most computer systems use multiple buses, generally laid out in a hierarchy."
  },
  {
    "subject": "books",
    "text": "A typical traditional structure is shown in Figure 19a. There is a local bus that connects the processor to a cache memory and that may support one or more local devices The cache memory is connected to a system bus to which all of the main memory modules are attached."
  },
  {
    "subject": "books",
    "text": "It is possible to connect I/O controllers directly onto the system bus. A more efficient solution is to make use of one or more expansion buses for this purpose. This arrangement allows the system to support a wide variety of I/O devices and at the same time insulate memory-to-processor traffic from I/O traffic."
  },
  {
    "subject": "books",
    "text": "Figure 19a shows some typical examples of I/O devices that might be attached to the expansion bus. Network connections include local area networks (LANs), wide area networks (WANs), SCSI (small  computer  system  interface),  serial  port..  This  traditional  bus  architecture  is  reasonably efficient but begins to break down as higher and higher performance is seen in the I/O devices."
  },
  {
    "subject": "books",
    "text": "In response to these growing demands, a common approach taken by industry is to build a high-speed bus that is closely integrated with the rest of the system, requiring only a bridge between the processor\u2019s bus and the high-speed bus. This arrangement is sometimes known as a mezzanine Figure 19b shows a typical realization of this approach."
  },
  {
    "subject": "books",
    "text": "Again,there is a local bus that connects the processor to a cache controller, which is in turn connected to a system bus that supports main memory. The cache controller is integrated into a bridge, or buffering device, that connects to the high-speed bus."
  },
  {
    "subject": "books",
    "text": "This bus supports connections to high-speed LANs, video and graphics workstation controllers, SCSI and FireWireLower-speed devices are still supported off an expansion bus, with an interface buffering traffic between the expansion bus and the high-speed bus. The advantage of this arrangement is that the high-speed bus brings high-demand devices into closer integration with the processor and at the same time is independent of the processor."
  },
  {
    "subject": "books",
    "text": "1.BUS TYPES Bus lines can be separated into two generic types: dedicated and multi- plexed. A dedicated bus line is permanently assigned either to one function or to a physical subset of computer components. Physical dedication refers to the use of multiple buses, each of which connects only a subset of modules."
  },
  {
    "subject": "books",
    "text": "The potential advantage of physical dedication is high throughput, because there is less bus contention.A disadvantage is the increased size and Address  and data information may be transmitted over the same set of lines  using an Address Valid control line. At the beginning of a data transfer, the address is placed on the bus and the Address Valid line is activated."
  },
  {
    "subject": "books",
    "text": "The address is then removed from the bus, and the same bus connections are used for the subsequent read or write data transfer. This method of using the same lines for multiple purposes is known as time multiplexing.The advantage of time multiplexing is the use of fewer lines, which saves space and, usually, cost."
  },
  {
    "subject": "books",
    "text": "The disadvantage is that more complex circuitry is needed within each module. 2.METHOD OF ABITRATION. The various methods can be roughly classified as being either centralized or distributed. In a centralized scheme, a single hardware device, referred to as a bus controller or arbiter, is responsible for allocating time on the bus."
  },
  {
    "subject": "books",
    "text": "In a distributed scheme, there is no central controller. Rather, each module contains access control logic and the modules act together to share the bus. With both methods of arbitration, the purpose is to designate either the processor or an I/O module, as master."
  },
  {
    "subject": "books",
    "text": "The master may then initiate a data transfer (e.g., read or write) with some other device, which acts as slave for this 3.TIMING Buses use either synchronous timing or asynchronous timing. With synchronous timing,  the  occurrence  of  events  on  the  bus  is  determined  by  a  clock."
  },
  {
    "subject": "books",
    "text": "A single  1\u20130 transmission is referred to as a clock cycle or bus cycle and defines a time slot. Figure 19 shows a typical, but simplified, timing diagram for synchronous read and write. In this simple example, the processor places a memory address on the address lines during the first clock cycle and may assert various status lines."
  },
  {
    "subject": "books",
    "text": "After pausing for these signals to stabilize, it issues a read command, indicating the presence of valid address and control signals. The appropriate memory decodes the address and responds by placing the data on the data line. Once the data lines have stabilized, the memory module asserts the acknowledged line to signal the processor that the data are available."
  },
  {
    "subject": "books",
    "text": "Once the master has read the data from the data lines, it deasserts the read signal. This causes the memory module to drop the data and acknowledge lines. Finally, once the acknowledge line is dropped, the master removes the Figure 21b shows a simple asynchronous write operation."
  },
  {
    "subject": "books",
    "text": "In this case, the master places the data on the data line at the same time that is puts signals on the status and address lines. The memory module responds to the write command by copying the data from the data lines and then asserting the acknowledge line."
  },
  {
    "subject": "books",
    "text": "The master then drops the write signal and the memory module drops the Synchronous timing is simpler to implement and test. However, it is less flexible than asynchronous timing. With asynchronous timing, a mixture of slow and fast devices, using older \uf0b7BUS WIDTH The width of the data bus has an impact on system performance: The wider the data bus, the greater the number of bits transferred at one time."
  },
  {
    "subject": "books",
    "text": "The width of the address bus has an impact on system capacity: the wider the address bus, the greater the range of \uf0b7DATA TRANSFER TYPE Finally, a bus supports various data transfer types, as illustrated In the case of a multiplexed address/data bus, the bus is first used for specifying the address and then for transferring the data."
  },
  {
    "subject": "books",
    "text": "For a read operation, there is typically a wait while the data are being fetched from the slave to be put on the bus. For either a read or a write, there may also be a delay if it is necessary to go through arbitration to gain control of the bus for the remainder of the operation."
  },
  {
    "subject": "books",
    "text": "In the case of dedicated address and data buses, the address is put on the address bus and remains there while the data are put on the data bus. For a write operation, the master puts the data onto the data bus as soon as the address has stabilized and the slave has had the opportunity to recognize its address."
  },
  {
    "subject": "books",
    "text": "For a read operation, the slave puts the data onto the data bus as soon as it has recognized A read\u2013modify\u2013write operation is simply a read followed immediately by a write to the same Read-after-write is an indivisible operation consisting of a write followed immediately by a read Some bus systems also support a block data transfer."
  },
  {
    "subject": "books",
    "text": "The first data item is transferred to or from the specified address; the remaining data items are transferred to or from subsequent addresses The peripheral component interconnect (PCI) is a popular high-bandwidth, processor-independent bus that can function as a peripheral bus."
  },
  {
    "subject": "books",
    "text": "PCI  is  designed  to  support  a  variety  of  microprocessor-based  configurations, including both single- and multiple-processor systems. It makes use of synchronous timing and a Figure 23a shows a typical use of PCI in a single-processor system. The bridge acts as a data buffer so that the speed of the PCI bus may differ from that of the processor\u2019s I/O capability."
  },
  {
    "subject": "books",
    "text": "In a to the processor\u2019s system bus. Again, the use of bridges keeps the PCI independent of the processor speed yet provides the ability to receive and deliver data rapidly. PCI may be configured as a 32- or 64-bit bus. There are 49 mandatory signal lines for PCI which \u2022 Address and data pins: Include 32 lines that are time multiplexed for addresses and data."
  },
  {
    "subject": "books",
    "text": "The other lines in this group are used to interpret and validate the signal lines that carry the \u2022 Interface control pins: Control the timing of transactions and provide coordination among \u2022 Arbitration pins: Unlike the other PCI signal lines, these are not shared lines."
  },
  {
    "subject": "books",
    "text": "Rather, each PCI master has its own pair of arbitration lines that connect it directly to the PCI bus arbiter. \u2022 Error reporting pins: Used to report parity and other errors. In addition, the PCI specification defines 51 optional signal lines, divided into the following \u2022 Interrupt pins: These are provided for PCI devices that must generate requests for service."
  },
  {
    "subject": "books",
    "text": "As with the arbitration pins, these are not shared lines. Rather, each PCI device has its own interrupt line or lines to an interrupt controller. \u2022 Cache support pins: These pins are needed to support a memory on PCI that can be cached \u2022 64-bit bus extension pins: Include 32 lines that are time multiplexed for ad dresses and data and that are combined with the mandatory address/data lines to form a 64-bit address/data \u2022 JTAG/boundary scan pins: These signal lines support testing procedures."
  },
  {
    "subject": "books",
    "text": "Bus activity occurs in the form of transactions between an initiator, or master, and a target. When a bus master acquires control of the bus, it determines the type of transaction that will occur 1. Interrupt Acknowledge is a read command intended for the device that functions as an interrupt 2."
  },
  {
    "subject": "books",
    "text": "The Special Cycle command is used by the initiator to broadcast a message to one or more 3. The I/O Read and Write commands are used to transfer data between the initiator and an I/O 4. The memory read and write commands are used to specify the transfer of a burst of data, occupying one or more clock cycles."
  },
  {
    "subject": "books",
    "text": "The three memory read commands have the uses outlined in 5. The Memory Write command is used to transfer data in one or more data cycles to memory. 6. The Memory Write and Invalidate command transfers data in one or more cycles to memory."
  },
  {
    "subject": "books",
    "text": "In addition, it guarantees that at least one cache line is written. The two configuration commands enable a master to read and update configuration parameters in a The  Dual  Address  Cycle  command  is  used  by  an  initiator  to  indicate  that  it  is  using  64-bit Every data transfer on the PCI bus is a single transaction consisting of one address phase and one or Figure 24 shows the timing of the read transaction."
  },
  {
    "subject": "books",
    "text": "All events are synchronized to the falling transitions of the clock, which occur in the middle of each clock cycle. Bus devices sample the bus lines on the rising edge at the beginning of a bus cycle. The following are the significant events, a)Once a bus master has gained control of the bus, it may begin the transaction by asserting FRAME."
  },
  {
    "subject": "books",
    "text": "This line remains asserted until the initiator is ready to complete the last data phase. The initiator also puts the start address on the address bus, and the read command on b)At the start of clock 2, the target device will recognize its address on the AD lines."
  },
  {
    "subject": "books",
    "text": "c)The initiator ceases driving the AD bus. A turnaround cycle (indicated by the two circular arrows) is required on all signal lines that may be driven by more than one device, so that the dropping of the address signal will prepare the bus for use by the target device."
  },
  {
    "subject": "books",
    "text": "The initiator changes the information on the C/BE lines to designate which AD lines are to be used for transfer for the currently addressed data (from 1 to 4 bytes). The initiator also asserts IRDY to indicate that it is ready for the first data item."
  },
  {
    "subject": "books",
    "text": "The g)During clock 6, the target places the third data item on the bus. However, in this example, the initiator is not yet ready to read the data item (e.g., it has a temporary buffer full condition). It therefore deasserts IRDY ."
  },
  {
    "subject": "books",
    "text": "This will cause the target to maintain the third data h)The initiator knows that the third data transfer is the last, and so it deasserts FRAME to signal the target that this is the last data transfer. It also asserts IRDY to signal that it is ready i)The initiator deasserts IRDY , returning the bus to the idle state, and the target deasserts PCI makes use of a centralized, synchronous arbitration scheme in which each master has a unique request (REQ) and grant (GNT) signal."
  },
  {
    "subject": "books",
    "text": "These signal lines are attached to a central arbiter (Figure 25) and a simple request\u2013grant handshake is used to grant access to the bus. Figure 26 is an example in which devices A and B are arbitrating for the bus. The following a."
  },
  {
    "subject": "books",
    "text": "d. Bus master A samples GNT-A at the beginning of clock 2 and learns that it has been granted bus access. It also finds IRDY and TRDY deasserted, which indicates that the bus is idle. It also continues to assert REQ-A, because it has a second transaction to perform after this one."
  },
  {
    "subject": "books",
    "text": "f. A deasserts FRAME to indicate that the last data transfer is in progress.It puts the data on the data bus and signals the target with IRDY .The target reads the data at the beginning of the next clock g. At the beginning of clock 5, B finds IRDY and FRAME deasserted and so is able to take control of the bus by asserting FRAME."
  },
  {
    "subject": "books",
    "text": "It also deasserts its REQ line, because it only wants to perform one transaction.Subsequently, master A is granted access to the bus for its next transaction.."
  },
  {
    "subject": "books",
    "text": "ALU is responsible to perform the operation in the computer. The basic operations are implemented in hardware level. ALU is having collection of two types of operations: Consider an ALU having 4 arithmetic operations and 4 logical operation. To identify any one of these four logical operations or four arithmetic operations, two control lines are needed."
  },
  {
    "subject": "books",
    "text": "Also to identify the any one of these two groups- arithmetic or logical, another control line is needed. So, with the help  of three control lines, any one of these  eight  operations  can  be  identified.  Consider  an  ALU  is  having  four  arithmetic  operations."
  },
  {
    "subject": "books",
    "text": "Addition, subtraction, multiplication and division. Also  consider that the ALU  is having four logical operations: OR, AND, We need three control lines to identify any one of these operations. The input combination of these control lines Control line C2 is used to identify the group: logical or arithmetic, ie C2 = 0: arithmetic operation C2 = 1 logical operation Control lines C0 and C1 are used to identify any one of the four operations in a group."
  },
  {
    "subject": "books",
    "text": "One possible combination A 3 x 8 decoder is used to decode the instruction. The block diagram of the ALU is shown in the The ALU has got two input registers named as A and B and one output storage register, named as C."
  },
  {
    "subject": "books",
    "text": "The input data are stored in A and B, and according to the operation specified in the control lines, the ALU perform the operation and put the result in register C. As for example, if the contents of controls lines are, 000, then the decoder enables the addition operation and it activates the adder circuit and the addition operation is performed on the data that are available in storage register A and B ."
  },
  {
    "subject": "books",
    "text": "After the completion of the operation, the result is stored We should have some hardware implementations for basic operations. These basic operations can be used to implement some complicated operations which are not feasible to implement directly in There are several logic gates  exists  in digital logic circuit."
  },
  {
    "subject": "books",
    "text": "These logic gates  can be used to implement the logical operation. Some of the common logic gates are mentioned here. AND gate: OR gate: The output is high if any one of the input is high. EX-OR gate: The output is high if either of the input is high."
  },
  {
    "subject": "books",
    "text": "If we want to construct a circuit which will perform the AND operation on two 4-bit number, the implementation of the 4-bit AND operation is shown in the figure. Binary Adder : Binary adder is used to add two binary numbers."
  },
  {
    "subject": "books",
    "text": "In general, the adder circuit needs two binary inputs and two binary outputs. The input variables designate the augends and addend bits; The output variables produce the sum and carry. The binary addition operation of single bit is shown in the truth table This circuit can not handle the carry input, so it is termed as half adder."
  },
  {
    "subject": "books",
    "text": "A full adder is a combinational circuit that forms the arithmetic sum of three bits. It consists of three Two of the input variables, denoted by x and y, represent the two bits to be added. The third input Z, represents the carry from the previous lower position."
  },
  {
    "subject": "books",
    "text": "The two outputs are designated by the The circuit diagram full adder is shown in the figure. n -such single bit full adder blocks are used to make n -bit full adder. To demonstrate the binary addition of four bit numbers, let us consider a specific example."
  },
  {
    "subject": "books",
    "text": "To get the four bit adder, we have to use 4 full adder block. The carry output the lower bit is used as Binary subtractor :  The subtraction operation can be implemented with the help of binary adder We know that 2's complement representation of a number is treated as a negative number of the We can get the 2's complements of a given number by complementing each bit and adding 1 to it."
  },
  {
    "subject": "books",
    "text": "This is equal to A With this principle, a single circuit can be used for both addition and subtraction. The 4 bit adder subtractor circuit is shown in the figure. It has got one mode ( M ) selection input line, which will Multiplication of two numbers in binary representation can be performed by a process of SHIFT and ADD operations."
  },
  {
    "subject": "books",
    "text": "Since the binary number system allows only 0 and 1's, the digit multiplication can be replaced by SHIFT and ADD operation only, because multiplying by 1 gives the number The multiplication process is illustrated with a numerical example. The process consists of looking at successive bits of the multiplier, least significant bit first."
  },
  {
    "subject": "books",
    "text": "If the multiplier bit is a 1, the multiplicand is copied down, otherwise, zeros are copied down. The numbers copied down in successive lines are shifted one position to the left from the previous number. Finally, the numbers are added and their sum forms the product."
  },
  {
    "subject": "books",
    "text": "When multiplication is implemented in a digital computer, the process is changed slightly. Instead of providing registers to store and add simultaneously as many binary numbers as there are bits in the multiplier, it is convenient to provide an adder for the summation of only two binary numbers  and  successively  accumulate  the  partial  products  in  a  register."
  },
  {
    "subject": "books",
    "text": "It  will  reduce  the requirements of registers. Instead of sifting the multiplicand to the left, the partial product is shifted When the corresponding bit of the multiplier is 0, there is no need to add all zeros to the partial product."
  },
  {
    "subject": "books",
    "text": "An algorithm to multiply two binary numbers. Consider that the ALU does not provide the multiplication operation, but it is having the addition operation and shifting operation. Then we can write a micro program for multiplication operation and provide the micro program code in memory."
  },
  {
    "subject": "books",
    "text": "When a multiplication operation is encountered, it will execute this micro code to perform the The micro code is nothing but the collection of some instructions. ALU must have those operation; otherwise we must have micro code again for those operations which are not supported in ALU."
  },
  {
    "subject": "books",
    "text": "Consider a situation such that we do not have the multiplication operation in a primitive computer. Is it possible to perform the multiplication. Of course, yes, provided the addition operation is available.  We  can  perform  the  multiplication  with  the  help  of  repeated  addition  method;  for example, if we want to multiply 4 by 5 ( 4 5), then simply add 4 five times to get the result."
  },
  {
    "subject": "books",
    "text": "If it is possible by addition operation, then why we need a multiplication operation. Consider a machine, which can handle 8 bit numbers, then we can represent number from 0 to 255. If we want to multiply 175 225, then there will be at least 175 addition operation."
  },
  {
    "subject": "books",
    "text": "But if we use the multiplication algorithm that involves shifting and addition, it can be done in 8 Again, the micro program execution is slightly slower, because we have to access the code from micro controller memory, and memory is a slower device than CPU."
  },
  {
    "subject": "books",
    "text": "It is possible to implement the The block diagram of binary multiplier is shown in the figure. The multiplicand is stored in register B and the multiplier is stored in register Q. The partial product is formed in register A and stored in A and Q The counter P is initially set to a number equal to the number of bits in the multiplier."
  },
  {
    "subject": "books",
    "text": "The counter is decremented by 1 after forming each partial product. When the content of the counter reaches zero, Initially, the multiplicand is in register B and the multiplier in Q. The register A is reset to 0. The sum of A and B forms a partial product- which is transferred to the EA register."
  },
  {
    "subject": "books",
    "text": "Both partial product and multiplier are shifted to the right. The least significant bit of A is shifted into the most significant position of Q; and 0 is shifted into E. After the shift, one bit of the partial product is shifted into Q, pushing the multiplier bits one The right most flip flop in register Q, designated by Q 0 will hold the bit of the multiplier which must be inspected next."
  },
  {
    "subject": "books",
    "text": "If the content of this bit is 0, then it is not required to add the multiplicand, only shifting is needed. If the content of this bit is 1, then both addition and shifting are needed. After each shifter, value of counter P is decremented and the process continues till the counter value becomes 0."
  },
  {
    "subject": "books",
    "text": "The final result is available in ( EAQ ) registers combination. To control the operation, it is required to design the appropriate control logic that is shown in the block diagram. The flow chart of the multiplication operation is given in the figure."
  },
  {
    "subject": "books",
    "text": "We have already mentioned that digital computer works on stored programmed concept introduced by V on Neumann. We use memory to store the information, which includes both program and data. Due to several reasons, we have different kind of memories. We use different kind of memory at The memory of computer is broadly categories into two categories: Internal memory is used by CPU to perform task and external memory is used to store bulk information, which includes large software and data."
  },
  {
    "subject": "books",
    "text": "The memory unit is an essential component in any digital computer since it is needed for storing programs and data. A very small computer with a limited application may be able to fulfill its intended task without the need of additional storage capacity."
  },
  {
    "subject": "books",
    "text": "Most general-purpose computers would run more efficiently if they were equipped with additional storage beyond the capacity of the main memory. There is just not enough space in one memory unit to accommodate all the programs used in a typical computer."
  },
  {
    "subject": "books",
    "text": "Moreover, most computer users accumulate and continue to accumulate large amounts  of data-processing software. Not all accumulated information  is  needed  by the processor at the same time. Therefore, it is more economical to use low-cost storage devices to serve as a backup for storing the information that is not currently used by the CPU."
  },
  {
    "subject": "books",
    "text": "Memory is used to store the information in digital form. The memory hierarchy is given by: This is a part of Central Processor Unit, so they reside inside the CPU. The information from main memory is brought to CPU and keep the information in register."
  },
  {
    "subject": "books",
    "text": "Due to space and cost constraints, we have got a limited number of registers in a CPU. These are basically faster devices. Cache  memory  is  a  storage  device  placed  in  between  CPU  and  main  memory.  These  are semiconductor memories. These are basically fast memory device, faster than main memory."
  },
  {
    "subject": "books",
    "text": "We can not have a big volume of cache memory due to its higher cost and some constraints of the CPU. Due to higher cost we can not replace the whole main memory by faster memory. Generally, the most recently used information is kept in the cache memory."
  },
  {
    "subject": "books",
    "text": "It is brought from the main memory and placed in the cache memory. Now a days, we get CPU with internal cache. Like  cache  memory,  main  memory  is  also  semiconductor  memory.  But  the  main  memory  is relatively slower memory. We have to first bring the information (whether it is data or program), to main memory."
  },
  {
    "subject": "books",
    "text": "CPU can work with the information available in main memory only. This is bulk storage device. We have to deal with huge amount of data in many application. But we don't have so much semiconductor memory to keep these information in our computer."
  },
  {
    "subject": "books",
    "text": "On the other hand, semiconductor memories are volatile in nature. It loses its content once we switch off the computer. For permanent storage, we use magnetic disk. The storage capacity of magnetic disk is For different application, we use different data."
  },
  {
    "subject": "books",
    "text": "It may not be possible to keep all the information in magnetic disk. So, which ever data we are not using currently, can be kept in removable media. Magnetic tape is one kind of removable medium. CD is also a removable media, which is an optical Register, cache memory and main memory are internal memory."
  },
  {
    "subject": "books",
    "text": "Magnetic Disk, removable media are external memory. Internal memories are semiconductor memory. Semiconductor memories are categoried as volatile memory and non-volatile memory. RAM: Random Access Memories are volatile in nature. As soon as the computer is switched off, the ROM: Read only memories are non volatile in nature."
  },
  {
    "subject": "books",
    "text": "The storage is permanent, but it is read only \u2022PROM:  Programmable  Read  Only  Memory;  it  can  be  programmed  once  as  per  user \u2022EPROM: Erasable Programmable Read Only Memory; the contents of the memory can be erased and store new data into the memory."
  },
  {
    "subject": "books",
    "text": "In this case, we have to erase whole information. \u2022EEPROM: Electrically Erasable Programmable Read Only Memory; in this type of memory the contents of a particular location can be changed without effecting the contents of other The main memory of a computer is semiconductor memory."
  },
  {
    "subject": "books",
    "text": "The main memory unit of computer is \u2022RAM : Random access memory; which is volatile in nature. The permanent information are kept in ROM and the user space is basically in RAM. The smallest unit of information is known as bit (binary digit), and in one memory cell we can store one bit of information."
  },
  {
    "subject": "books",
    "text": "8 bit together is termed as a byte. The maximum size of main memory that can be used in any computer is determined by the A computer that generates 16-bit address is capable of addressing upto 2^16 which is equal to 64K memory location."
  },
  {
    "subject": "books",
    "text": "Similarly, for 32 bit addresses, the total capacity will be 2^32 which is equal to In some computer, the smallest addressable unit of information is a memory word and the machine In some computer, individual address is assigned for each byte of information, and it is called byte- addressable computer ."
  },
  {
    "subject": "books",
    "text": "In this computer, one memory word contains one or more memory bytes A byte addressable 32-bit computer, each memory word contains 4 bytes. A possible way of address assignment is shown in figure. The address of a word is always integer multiple of 4."
  },
  {
    "subject": "books",
    "text": "The main memory is usually designed to store and retrieve data in word length quantities. The word length of a computer is generally defined by the number of bits actually stored or retrieved in one Consider a machine with 32 bit address bus."
  },
  {
    "subject": "books",
    "text": "If the word size is 32 bit, then the high order 30 bit will specify the address of a word. If we want to access any byte of the word, then it can be specified by The data transfer between main memory and the CPU takes place through two CPU registers."
  },
  {
    "subject": "books",
    "text": "If the MAR is k-bit long, then the total addressable memory location will be 2^k . If the MDR is n-bit long, then the n bit of data is transferred in one memory cycle. The transfer of data takes place through memory bus, which consist of address bus and data bus."
  },
  {
    "subject": "books",
    "text": "In the above example, size of data bus is n-bit and size of address bus is k bit. It  also  includes  control  lines  like  Read,  Write  and  Memory  Function  Complete  (MFC)  for coordinating data transfer. In the case of byte addressable computer, another control line to be added to indicate the byte transfer instead of the whole word."
  },
  {
    "subject": "books",
    "text": "For memory operation, the CPU initiates a memory operation by loading the appropriate data i.e., If it is a memory read operation, then it sets the read memory control line to 1. Then the contents of the memory location is brought to MDR and the memory control circuitry indicates this to the CPU by setting MFC to 1."
  },
  {
    "subject": "books",
    "text": "If the operation is a memory write operation, then the CPU places the data into MDR and sets the write memory control line to 1. Once the contents of MDR are stored in specified memory location, then the memory control circuitry indicates the end of operation by setting MFC A useful measure of the speed of memory unit is the time that elapses between the initiation of an operation and the completion of the operation (for example, the time between Read and MFC)."
  },
  {
    "subject": "books",
    "text": "This is referred to as Memory Access Time . Another measure is memory cycle time. This is the minimum time delay between the initiation two independent memory operations (for example, two successive memory read operation). Memory cycle time is slightly larger than memory access time."
  },
  {
    "subject": "books",
    "text": "The binary storage cell is the basic building block of a memory unit. The binary storage cell that stores one bit of information can be modelled by an SR latch with associated gates. This model of binary storage cell is shown in the figure."
  },
  {
    "subject": "books",
    "text": "The binary cell sotres one bit of information in its internal latch. The storage part is modelled here with SR-latch, but in reality it is an electronics circuit made up of The memory constructed with the help of transistors is known as semiconductor memory."
  },
  {
    "subject": "books",
    "text": "The semiconductor memories are termed as Random Access Memory(RAM), because it is possible to Depending on the technology used to construct a RAM, there are two types of RAM - A DRAM is made with cells that store data as charge on capacitors."
  },
  {
    "subject": "books",
    "text": "The presence or absence of charge in a capacitor is interpreted as binary 1 or 0. Because capacitors have a natural tendency to discharge due to leakage current, dynamic RAM require  periodic  charge  refreshing  to  maintain  data  storage.  The  term  dynamic  refers  to  this tendency of the stored charge to leak away, even with power continuously applied."
  },
  {
    "subject": "books",
    "text": "A typical DRAM structure for an individual cell that stores one bit information is shown in the For the write operation, a voltage signal is applied to the bit line B, a high voltage represents 1 and a low voltage represents 0."
  },
  {
    "subject": "books",
    "text": "A signal is then applied to the address line, which will turn on the transistor T, allowing a charge to be transferred to the capacitor. For the read operation, when a signal is applied to the address line, the transistor T turns on and the charge stored on the capacitor is fed out onto the bit line B."
  },
  {
    "subject": "books",
    "text": "In an SRAM, binary values are stored using traditional flip-flop constructed with the help of transistors. A static RAM will hold its data as long as power is supplied to it. A typical SRAM constructed with transistors is shown in the figure."
  },
  {
    "subject": "books",
    "text": "Four transistors (T1 , T2 , T3 , T4 ) are cross connected in an arrangement that produces a stable In logic state 1, point A 1 is high and point A 2 is low; in this state T 1 and T 4 are off, and T2 and In logic state 0, point A 1 is low and point A 2 is high; in this state T 1 and T 4 are on, and T 2 and T Both states are stable as long as the dc supply voltage is applied."
  },
  {
    "subject": "books",
    "text": "The address line is used to open or close a switch which is nothing but another transistor. The address line controls two transistors(T 5 and T 6 ). When a signal is applied to this line, the two transistors are switched on, allowing a read or write operation."
  },
  {
    "subject": "books",
    "text": "For a write operation, the desired bit value is applied to line B, and its complement is applied to line B\u2019. This forces the four transistors(T1 , T2 , T3 , T4 ) into the proper state. For a read operation, the bit value is read from the line B."
  },
  {
    "subject": "books",
    "text": "When a signal is applied to the address line, the signal of point A1 is available in the bit line B. \u2022Both static and dynamic RAMs are volatile, that is, it will retain the information as long as \u2022A dynamic memory cell is simpler and smaller than a static memory cell."
  },
  {
    "subject": "books",
    "text": "Thus a DRAM is more dense, i.e., packing density is high(more cell per unit area). DRAM is less expensive \u2022DRAM requires the supporting refresh circuitry. For larger memories, the fixed cost of the refresh circuitry is more than compensated for by the less cost of DRAM cells \u2022SRAM  cells  are  generally  faster  than  the  DRAM  cells."
  },
  {
    "subject": "books",
    "text": "Therefore,  to  construct  faster A memory cell is capable of storing 1-bit of information. A number of memory cells are organized in the form of a matrix to form the memory chip. One such organization is shown in the Figure Each row of cells constitutes a memory word, and all cell of a row are connected to a common line which is referred as word line."
  },
  {
    "subject": "books",
    "text": "An address decoder is used to drive the word line. At a particular instant, one word line is enabled depending on the address present in the address bus. The cells in each column are connected by two lines. These are known as bit lines."
  },
  {
    "subject": "books",
    "text": "These bit lines are connected to data input line and data output line through a Sense/ Write circuit. During a Read operation, the Sense/Write circuit sense, or read the information stored in the cells selected by a word line and transmit this information to the output data line."
  },
  {
    "subject": "books",
    "text": "During a write operation, the sense/write circuit receive information and store it in the cells of the selected word. A memory chip consisting of 16 words of 8 bits each, usually referred to as 16 x 8 organization. The data input and data output line of each Sense/Write circuit are connected to a single bidirectional data line in order to reduce the pin required."
  },
  {
    "subject": "books",
    "text": "For 16 words, we need an address bus of size 4. In addition to address and data lines, two control lines, RW\u2019 and CS, are provided. The R/W\u2019 line is to used to specify the required operation about read or write."
  },
  {
    "subject": "books",
    "text": "The CS (Chip Select) line is required to select a given chip in a multi chip memory system. If it is organised as a 128 x 8 memory chips, then it has got 128 memory words of size 8 bits. So the size of data bus is 8 bits and the size of address bus is 7 bits (2^7 = 128)."
  },
  {
    "subject": "books",
    "text": "If it is organized as a 1024 x 1 memory chips, then it has got 1024 memory words of size 1 bit only. Therefore, the size of data bus is 1 bit and the size of address bus is 10 bits (2^10 = 1024)."
  },
  {
    "subject": "books",
    "text": "A particular memory location is identified by the contents of memory address bus. A decoder is used  to  decode  the  memory  address. There  are  two  ways  of decoding  of a  memory  address depending upon the organization of the memory module. In one case, each memory word is organized in a row."
  },
  {
    "subject": "books",
    "text": "In this case whole memory address bus is used together to decode the address of the specified location. In second case, several memory words are organized in one row. In this case, address bus One group is used to form the row address and the second group is used to form the column address."
  },
  {
    "subject": "books",
    "text": "Consider the memory organization of 1024 x 1 memory chip. The required 10-bit address is divided into two groups of 5 bits each to form the row and column address of the cell array. A row address selects a row of 32 cells, all of which are accessed in parallel."
  },
  {
    "subject": "books",
    "text": "However, according to the column address, only one of these cells is connected to the external data line via the input output The commercially available memory chips contain a much larger number of cells. As for example, a memory unit of 1MB (mega byte) size, organised as 1M x 8, contains 2^20 x 8 memory cells."
  },
  {
    "subject": "books",
    "text": "The cells are organized in the form of a square array. The address bus is divided into two groups, one for column address and other one is for row address. In this case, high- and low- order 10 bits of 20-bit address constitute of row and column address of a given cell, respectively."
  },
  {
    "subject": "books",
    "text": "In order to reduce the number of pin needed for external connections, the row and column addresses are multiplexed on ten pins. During a Read or a Write operation, the row address is applied first. In response to a signal pulse on the Row Address Strobe (RAS)  input of the chip, this part of the address is loaded into the row address latch."
  },
  {
    "subject": "books",
    "text": "All cell of this particular row is selected. Shortly after the row address is latched, the column address is applied to the address pins. It is loaded into the column address latch with the help of Column Address Strobe (CAS) signal, similar to RAS."
  },
  {
    "subject": "books",
    "text": "The information in this latch is decoded and For a Write operation, the information at the input lines are transferred to the selected circuits. Now we discuss the design of memory subsystem using memory chips. Consider a memory chips of capacity 16K x 8."
  },
  {
    "subject": "books",
    "text": "The requirement is to design a memory subsystem of capacity 64K x 16. Each memory chip has got eight lines for data bus, but the data bus size of memory subsytem is 16 bits. The total requiremet is for 64K memory location, so four such units are required to get the 64K memory location."
  },
  {
    "subject": "books",
    "text": "For 64K memory location, the size of address bus is 16. On the other hand, for 16K memory location, size of address bus is 14 bits. Each chip has a control input line called Chip Select (CS). A chip can be enabled to accept data input or to place the data on the output bus by setting its Chip Select input to 1."
  },
  {
    "subject": "books",
    "text": "The address bus for the 64K memory is 16 bits wide. The high order two bits of the address are decoded to obtain the four chip select control signals. The remaining 14 address bits are connected to the address lines of all the chips."
  },
  {
    "subject": "books",
    "text": "They are used to access a specific location inside each chip of the selected row. The R/W\u2019 inputs of all chips are tied together to provide a common READ/WRITE control. Analysis of large number of programs has  shown that a number of instructions  are executed repeatedly."
  },
  {
    "subject": "books",
    "text": "This may be in the form of a simple loops, nested loops, or a few procedures that repeatedly call each other. It is observed that many instructions in each of a few localized areas of the program are repeatedly executed, while the remainder of the program is accessed relatively less."
  },
  {
    "subject": "books",
    "text": "This phenomenon is referred to as locality of reference. Now, if it can be arranged to have the active segments of a program in a fast memory, then the tolal execution time can be significantly reduced. It is the fact that CPU is a faster device and memory is Memory access is the main bottleneck for the performance efficiency."
  },
  {
    "subject": "books",
    "text": "If a faster memory device can be inserted between main memory and CPU, the efficiency can be increased. The faster memory that  is  inserted  between  CPU  and Main  Memory  is  termed  as  Cache  memory.  To  make  this arrangement effective, the cache must be considerably faster than the main memory, and typically it is 5 to 10 time faster than the main memory."
  },
  {
    "subject": "books",
    "text": "This approach is more economical than the use of fast memory device to implement the entire main memory. This is also a feasible due to the locality of reference that is present in most of the program, which reduces the frequent data transfer between The memory control circuitry is designed to take advantage of the property of locality of reference."
  },
  {
    "subject": "books",
    "text": "Some assumptions are made while designing the memory control circuitry: 1.The CPU does not need to know explicitly about the existence of the cache. 2.The CPU simply makes Read and Write request. The nature of these two operations are 3.The address generated by the CPU always refer to location of main memory."
  },
  {
    "subject": "books",
    "text": "4.The memory access control circuitry determines whether or not the requested word currently When  a  Read  request  is  received  from  the  CPU,  the  contents  of  a  block  of  memory  words containing the location specified are transferred into the cache. When any of the locations in this block is referenced by the program, its contents are read directly from the cache."
  },
  {
    "subject": "books",
    "text": "The cache memory can store a number of such blocks at any given time. The correspondence between the Main Memory Blocks and those in the cache is specified by means When the cache is full and a memory word is referenced that is not in the cache, a decision must be made as to which block should be removed from the cache to create space to bring the new block to the cache that contains the referenced word."
  },
  {
    "subject": "books",
    "text": "Replacement algorithms are used to make the proper selection of block that must be replaced by the new one. When a write request is received from the CPU, there are two ways that the system can proceed. In the first case, the cache location and the main memory location are updated simultaneously."
  },
  {
    "subject": "books",
    "text": "This is called the store through method or write through method . The alternative is to update the cache location only. During replacement time, the cache block will be written back to the main memory. If there is no new write operation in the cache block, it is not required to write back the cache block in the main memory."
  },
  {
    "subject": "books",
    "text": "This information can be kept with the help of an associated bit. This bit it set while there is a write operation in the cache block. During replacement, it checks this bit, if it is set, then write back the cache block in main memory otherwise not."
  },
  {
    "subject": "books",
    "text": "This bit is known as dirty bit . If the bit gets dirty (set to one), writing to main This write through method is simpler, but it results in unnecessary write operations in the main memory when a given cache word is updated a number of times during its cache residency period."
  },
  {
    "subject": "books",
    "text": "Consider the case where the addressed word is not in the cache and the operation is a read. First the block of the words is brought to the cache and then the requested word is forwarded to the CPU. But it can be forwarded to the CPU as soon as it is available to the cache, instead of whole block to be loaded into the cache."
  },
  {
    "subject": "books",
    "text": "This is called load through, and there is some scope to save time while During a write operation, if the address word is not in the cache, the information is written directly into the main memory. A write operation normally refers to the location of data areas and the property of locality of reference is not as pronounced in accessing data when write operation is involved."
  },
  {
    "subject": "books",
    "text": "Therefore, it is not advantageous to bring the data block to the cache when there a write operation, and the addressed word is not present in cache. The mapping functions are used to map a particular block of main memory to a particular block of cache."
  },
  {
    "subject": "books",
    "text": "This mapping function is used to transfer the block from main memory to cache memory. A particular block of main memory can be brought to a particular block of cache memory. So, it is In this mapping function, any block of Main memory can potentially reside in any cache block position."
  },
  {
    "subject": "books",
    "text": "This is much more flexible mapping method. In this method, blocks of cache are grouped into sets, and the mapping allows a block of main memory to reside in any block of a specific set. From the flexibility point of view, it is in between to Consider a cache of 4096 (4K) words with a block size of 32 words."
  },
  {
    "subject": "books",
    "text": "Therefore, the cache is organized as 128 blocks. For 4K words, required address lines are 12 bits. To select one of the block out of 128 blocks, we need 7 bits of address lines and to select one word out of 32 words, we need 5 bits of address lines."
  },
  {
    "subject": "books",
    "text": "So the total 12 bits of address is divided for two groups, lower 5 bits are used to select a word within a block, and higher 7 bits of address are used to select any block of cache Let us consider a main memory system consisting 64K words."
  },
  {
    "subject": "books",
    "text": "The size of address bus is 16 bits. Since the block size of cache is 32 words, so the main memory is also organized as block size of 32 words. Therefore, the total number of blocks in main memory is 2048 (2K x 32 words = 64K words)."
  },
  {
    "subject": "books",
    "text": "To identify any one block of 2K blocks, we need 11 address lines. Out of 16 address lines of main memory, lower 5 bits are used to select a word within a block and higher 11 bits are used to Number of blocks in cache memory is 128 and number of blocks in main memory is 2048, so at any instant of time only 128 blocks out of 2048 blocks can reside in cache menory."
  },
  {
    "subject": "books",
    "text": "Therefore, we need mapping  function  to put  a  particular  block  of  main  memory  into  appropriate  block  of cache The simplest way of associating main memory blocks with cache block is the direct mapping technique. In this technique, block k of main memory maps into block k modulo m of the cache, where m is the total number of blocks in cache."
  },
  {
    "subject": "books",
    "text": "In this example, the value of m is 128. In direct mapping technique, one particular block of main memory can be transfered to a particular block of Since more than one main memory block is mapped onto a given cache block position, contention may arise for that position."
  },
  {
    "subject": "books",
    "text": "This situation may occurs even when the cache is not full. Contention is resolved by allowing the new block to overwrite the currently resident block. So the replacement algorithm is trivial. The detail operation of direct mapping technique is as follows: The main memory address is divided into three fields."
  },
  {
    "subject": "books",
    "text": "The field size depends on the memory capacity and the block size of cache. In this example, the lower 5 bits of address is used to identify a word within a block. Next 7 bits are used to select a block out of 128 blocks (which is the capacity of the cache)."
  },
  {
    "subject": "books",
    "text": "The remaining 4 bits are used as a TAG to identify the proper block of main memory When a new block is first brought into the cache, the high order 4 bits of the main memory address are stored in four TAG bits associated with its location in the cache."
  },
  {
    "subject": "books",
    "text": "When the CPU generates a memory request, the 7-bit block address determines the corresponding cache block. The TAG field of that block is compared to the TAG field of the address. If they match, the desired word specified by the low-order 5 bits of the address is in that block of the cache."
  },
  {
    "subject": "books",
    "text": "If there is no match, the required word must be accessed from the main memory, that is, the contents of that block of the cache is replaced by the new block that is specified by the new address generated by the CPU and correspondingly the TAG bit will also be changed by the high order 4 bits of the address."
  },
  {
    "subject": "books",
    "text": "The whole arrangement for direct mapping technique is shown in the figure. In the associative mapping technique, a main memory block can potentially reside in any cache block position. In this case, the main memory address is divided into two groups, low-order bits identifies the location of a word within a block and high-order bits identifies the block."
  },
  {
    "subject": "books",
    "text": "In the example here, 11 bits are required to identify a main memory block when it is resident in the cache , high-order 11 bits are used as TAG bits and low-order 5 bits are used to identify a word within a block."
  },
  {
    "subject": "books",
    "text": "The TAG bits of an address received from the CPU must be compared to the TAG bits of each block of the cache to see if the desired block is present. In the associative mapping, any block of main memory can go to any block of cache, so it has got the complete flexibility and we have to use proper replacement policy to replace a block from cache if the currently accessed block of main memory is not present in cache."
  },
  {
    "subject": "books",
    "text": "It might not be practical to use this complete flexibility of associative mapping technique due to searching overhead, because the TAG field of main memory address has to be compared with the TAG field of all the cache block. In this example, there are 128 blocks in cache and the size of TAG is 11 bits."
  },
  {
    "subject": "books",
    "text": "The whole arrangement of Associative Mapping Technique is shown in the figure This mapping technique is intermediate to the above two techniques. Blocks of the cache are grouped into sets, and the mapping allows a block of main memory to reside in any block of a specific set."
  },
  {
    "subject": "books",
    "text": "Therefore, the flexibity of associative mapping is reduced from full freedom to a set of specific blocks. This also reduces the searching overhead, because the search is restricted to number of sets, instead of number of blocks. Also the contention problem of the direct mapping is eased by Consider  the  same  cache  memory  and  main  memory  organization  of  the  previous  example."
  },
  {
    "subject": "books",
    "text": "Organize the cache with 4 blocks in each set. The TAG field of associative mapping technique is divided into two groups, one is termed as SET bit and the second one is termed as TAG bit. Since each set contains 4 blocks, total number of set is 32."
  },
  {
    "subject": "books",
    "text": "The main memory address is grouped into three parts: low-order 5 bits are used to identifies a word within a block. Since there are total 32 sets present, next 5 bits are used to identify the set. High-order 6 bits are used as TAG bits."
  },
  {
    "subject": "books",
    "text": "The 5-bit set field of the address determines which set of the cache might contain the desired block. This is similar to direct mapping technique, in case of direct mapping, it looks for block, but in case of block-set-associative mapping, it looks for set."
  },
  {
    "subject": "books",
    "text": "The TAG field of the address must then be compared with the TAGs of the four blocks of that set. If a match occurs, then the block is present in the cache; otherwise the block containing the addressed word must be brought to the cache."
  },
  {
    "subject": "books",
    "text": "This block will potentially come to the corresponding set only. Since, there are four blocks in the set, we have to choose appropriately which block to be replaced if all the blocks are occupied. Since the search  is  restricted  to  four  block  only,  so  the  searching  complexity  is  reduced."
  },
  {
    "subject": "books",
    "text": "The  whole arrangement of block-set-associative mapping technique is shown in the figure. It is clear that if we increase the number of blocks per set, then the number of bits in SET field is reduced. Due to the increase of blocks per set, complexity of search is also increased."
  },
  {
    "subject": "books",
    "text": "The extreme condition of 128 blocks per set requires no set bits and corresponds to the fully associative mapping technique with 11 TAG bits. The other extreme of one block per set is the direct mapping method. When a new block must be brought into the cache and all the positions that it may occupy are full, a decision must be made as to which of the old blocks is to be overwritten."
  },
  {
    "subject": "books",
    "text": "In general, a policy is required to keep the block in cache when they are likely to be referenced in near future. However, it is not easy to determine directly which of the block in the cache are about to be referenced."
  },
  {
    "subject": "books",
    "text": "The property of locality of reference gives some clue to design good replacement policy. Since program usually stay in localized areas for reasonable periods of time, it can be assumed that there is a high probability that blocks which have been referenced recently will also be referenced in the near future."
  },
  {
    "subject": "books",
    "text": "Therefore, when a block is to be overwritten, it is a good decision to overwrite the one that has gone for longest time without being referenced. This is defined as the least recently used (LRU) block. Keeping track of LRU block must be done as computation proceeds."
  },
  {
    "subject": "books",
    "text": "Consider a specific example of a four-block set. It is required to track the LRU block of this four- block set. A 2-bit counter may be used for each block. When a hit occurs, that is, when a read request is received for a word that is in the cache, the counter of the block that is referenced is set to 0."
  },
  {
    "subject": "books",
    "text": "All counters which values originally lower than the referenced one are incremented by 1 and all other counters remain unchanged. When a miss occurs, that is, when a read request is received for a word and the word is not present in the cache, we have to bring the block to cache."
  },
  {
    "subject": "books",
    "text": "If the set is not full, the counter associated with the new block loaded from the main memory is set to 0, and the values of all other counters are incremented by 1. If the set is full and a miss occurs, the block with the counter value 3 is removed , and the new block is put in its palce."
  },
  {
    "subject": "books",
    "text": "The counter value is set to zero. The other three block counters are It is easy to verify that the counter values of occupied blocks are always distinct. Also it is trivial that highest counter value indicates least recently used block."
  },
  {
    "subject": "books",
    "text": "A reasonable rule may be to remove the oldest from a full set when a new block must be brought in. While using this technique, no updation is required when a hit occurs. When a miss occurs and the set is not full, the new block is put into an empty block and the counter values of the occupied block will be increment by one."
  },
  {
    "subject": "books",
    "text": "When a miss occurs and the set is full, the block with highest counter value is replaced by new block and counter is set to 0, counter value of all other blocks of that set is incremented by 1. The overhead of the policy is less, since no updation is required during hit."
  },
  {
    "subject": "books",
    "text": "The simplest algorithm is to choose the block to be overwritten at random. Interestingly enough, this simple algorithm has been found to be very effective in practice. Both unequal fixed size and variable size partitions are inefficient in the use of memory."
  },
  {
    "subject": "books",
    "text": "It has been observed that both schemes lead to memory wastage. Therefore we are not using the memory efficiently. There is another scheme for use of memory which is known as paging. In this scheme, The memory is partitioned into equal fixed size chunks that are relatively small."
  },
  {
    "subject": "books",
    "text": "This chunk of memory is known as frames or page frames. Each process is also divided into small fixed chunks of same size. The chunks of a program is known as pages. A page of a program could be assigned to available page frame."
  },
  {
    "subject": "books",
    "text": "In this scheme, the wastage space in memory for a process is a fraction of a page frame which corresponds to the last page of the program. At a given point of time some of the frames in memory are in use and some are free."
  },
  {
    "subject": "books",
    "text": "The list of free frame is maintained by the operating system. Process A , stored in disk , consists of pages . At the time of execution of the process A, the operating system finds six free frames and loads the six pages of the process A into six frames."
  },
  {
    "subject": "books",
    "text": "These six frames need not be contiguous frames in main memory. The operating system maintains a page table for each process. Within the program, each logical address consists of page number and a In case of simple partitioning, a logical address is the location of a word relative to the beginning of the program; the processor translates that into a physical address."
  },
  {
    "subject": "books",
    "text": "With paging, a logical address is a location of the word relative to the beginning of the page of the program, because the whole program is divided into several pages of equal length and the length of a page is same with the A logical address consists of page number and relative address within the page, the process uses the page table to produce the physical address which consists of frame number and relative address The figure on next page shows the allocation of frames to a new process in the main memory."
  },
  {
    "subject": "books",
    "text": "A page table is maintained for each process. This page table helps us to find the physical address in a frame which corresponds to a logical address within a process. The conversion of logical address to physical address is shown in the figure for the Process A."
  },
  {
    "subject": "books",
    "text": "This approach solves the problems. Main memory is divided into many small equal size frames. Each process is divided into frame size pages. Smaller process requires fewer pages, larger process requires more. When a process is brought in, its pages are loaded into available frames and a page The concept of paging helps us to develop truly effective multi-programming systems."
  },
  {
    "subject": "books",
    "text": "Since a process need not be loaded into contiguous memory locations, it helps us to put a page of a process in any free page frame. On the other hand, it is not required to load the whole process to the main memory,  because  the  execution  may  be  confined  to  a  small  section  of  the  program."
  },
  {
    "subject": "books",
    "text": "(eg.  a It would clearly be wasteful to load in many pages for a process when only a few pages will be used before the program is suspended. Instead of loading all the pages of a process, each page of process is brought in only when it is needed, i.e on demand."
  },
  {
    "subject": "books",
    "text": "This scheme is known as demand paging . Demand paging also allows us to accommodate more process in the main memory, since we are not going to load the whole process in the main memory, pages will be brought into the main memory With demand paging, it is not necessary to load an entire process into main memory."
  },
  {
    "subject": "books",
    "text": "This concept leads us to an important consequence \u2013 It is possible for a process to be larger than the size of main memory. So, while developing a new process, it is not required to look for the main memory available in the machine."
  },
  {
    "subject": "books",
    "text": "Because, the process will be divided into pages and pages will be Because a process executes only in main memory, so the main memory is referred to as real memory or physical memory. A programmer or user perceives a much larger memory that is allocated on the disk."
  },
  {
    "subject": "books",
    "text": "This memory is referred to as virtual memory. The program enjoys a huge virtual memory space to develop his or her program or software. The execution of a program is the job of operating system and the underlying hardware. To improve the performance some special hardware is added to the system."
  },
  {
    "subject": "books",
    "text": "This hardware unit is known as In paging system, we make a page table for the process. Page table helps us to find the physical address from virtual address. The virtual address space is used to develop a process. The special hardware unit , called Memory Management Unit (MMU) translates virtual address to physical address."
  },
  {
    "subject": "books",
    "text": "When the desired data is in the main memory, the CPU can work with these data. If the data are not in the main memory, the MMU causes the operating system to bring into the memory The basic mechanism for reading a word from memory involves the translation of a virtual or logical address, consisting of page number and offset, into a physical address, consisting of frame There is one page table for each process."
  },
  {
    "subject": "books",
    "text": "But each process can occupy huge amount of virtual memory. But the virtual memory of a process cannot go beyond a certain limit which is restricted by the underlying hardware of the MMU. One of such component may be the size of the virtual The sizes of pages are relatively small and so the size of page table increases as the size of process increases."
  },
  {
    "subject": "books",
    "text": "Therefore, size of page table could be unacceptably high. To overcome this problem, most virtual memory scheme store page table in virtual memory rather than in real memory. This means that the page table is subject to paging just as other pages are."
  },
  {
    "subject": "books",
    "text": "When a process is running, at least a part of its page table must be in main memory, including the page table entry of the currently Each virtual address generated by the processor is interpreted as virtual page number (high order list) followed by an offset (lower order bits) that specifies the location of a particular word within a page."
  },
  {
    "subject": "books",
    "text": "Information about the main memory location of each page kept in a page table. Some processors make use of a two level scheme to organize large page tables. In this scheme, there is a page directory, in which each entry points to a page table."
  },
  {
    "subject": "books",
    "text": "Thus, if the length of the page directory is X, and if the maximum length of a page table is Y , then the process can consist of up to X x Y pages. Typically, the maximum length of page table is restricted to the."
  },
  {
    "subject": "books",
    "text": "We  have  examined  the  types  of  operands  and  operations  that  may  be  specified  by  machine instructions . Now we have to see how is the address of an operand specified, and how are the bits of an instruction organized to define the operand addresses and operation of that instruction."
  },
  {
    "subject": "books",
    "text": "All computer architectures provide more than one of these addressing modes . The question arises as to how the control unit can determine which addressing mode is being used in a particular instruction. Several approaches are used. Often, different opcodes will use different addressing modes."
  },
  {
    "subject": "books",
    "text": "Also, one or more bits in the instruction format can be used as a mode field . The value of the mode field determines which addressing mode is to be used. What is the interpretation of effective address . In a system without virtual memory, the effective address will be either a main memory address or a register."
  },
  {
    "subject": "books",
    "text": "In a virtual memory system, the effective address is a virtual address or a register. The actual mapping to a physical address is a function of the paging mechanism and is invisible to the programmer. To explain the addressing modes, we use the following notation: A = contents of an address field in the instruction that refers to a memory R = contents of an address field in the instruction that refers to a register EA = actual (effective) address of the location containing the referenced operand The simplest form of addressing is immediate addressing, in which the operand is actually present This mode can be used to define and use constants or set initial values of variables."
  },
  {
    "subject": "books",
    "text": "The advantage of immediate addressing is that no memory reference other than the instruction fetch is required to obtain the operand. The disadvantage is that the size of the number is restricted to the size of the address field, which, in most instruction sets, is small compared with the world length."
  },
  {
    "subject": "books",
    "text": "A very simple form of addressing is direct addressing, in which the address field contains the It requires only one memory reference and no special calculation. With direct addressing, the length of the address field is usually less than the word length, thus limiting the address range."
  },
  {
    "subject": "books",
    "text": "One solution is to have the address field refer to the address of a word in memory, which in turn contains a full-length address of the operand. This is know as indirect Register addressing is similar to direct addressing. The only difference is that the address field refers to a register rather than a main memory address: The advantages of register addressing are that only a small address field is needed in the instruction and no memory reference is required."
  },
  {
    "subject": "books",
    "text": "The disadvantage of register addressing is that the address Register indirect addressing is similar to indirect addressing, except that the address field refers to a It requires only one memory reference and no special calculation. Register indirect addressing uses one less memory reference than indirect addressing."
  },
  {
    "subject": "books",
    "text": "Because, the first information is available in a register which is nothing but a memory address. From that memory location, we use to get the data or information. In general, register access is much more A very powerful mode of addressing combines the capabilities of direct addressing and register indirect addressing, which is broadly categorized as displacement addressing: Displacement addressing requires that the instruction have two address fields, at least one of which is explicit."
  },
  {
    "subject": "books",
    "text": "The value contained in one address field (value = A) is used directly. The other address field, or an implicit reference based on opcode, refers to a register whose contents are added to A to Three of the most common use of displacement addressing are: For relative addressing, the implicitly referenced register is the program counter (PC)."
  },
  {
    "subject": "books",
    "text": "That is, the current instruction address is added to the address field to produce the EA. Thus, the effective address is a displacement relative to the address of the instruction. The reference register contains a memory address, and the address field contains a displacement from that address."
  },
  {
    "subject": "books",
    "text": "The register reference may be explicit or implicit . In some implimentation, a single segment/base register is employed and is used implicitly. In others, the programmer may choose a register to hold the base address of a segment, and the The address field references a main memory address, and the reference register contains a positive displacement from that address."
  },
  {
    "subject": "books",
    "text": "In this case also the register reference is sometimes explicit and Generally index register are used for iterative tasks, it is typical that there is a need to increment or decrement the index register after each reference to it. Because this is such a common operation, some system will automatically do this as part of the same instruction cycle."
  },
  {
    "subject": "books",
    "text": "This is known as auto-indexing. We may get two types of auto-indexing: If  certain  registers  are  devoted  exclusively  to  indexing,  then  auto-indexing  can  be  invoked implicitly and automatically. If general purpose register are used, the autoindex operation may need Auto-indexing using increment can be depicted as follows: Auto-indexing using decrement can be depicted as follows: In some machines, both indirect addressing and indexing are provided, and it is possible to employ both in the same instruction."
  },
  {
    "subject": "books",
    "text": "There are two possibilities: The indexing is performed either before or If indexing is performed after the indirection, it is termed postindexing First, the contents of the address field are used to access a memory location containing an address. This address is then indexed by the register value."
  },
  {
    "subject": "books",
    "text": "With preindexing, the indexing is performed before the indirection: An address is calculated, the calculated address contains not the operand, but the address of the A stack is a linear array or list of locations. It is sometimes referred to as a pushdown list or last-in- first-out queue ."
  },
  {
    "subject": "books",
    "text": "A stack is a reserved block of locations. Items are appended to the top of the stack so that, at any given time, the block is partially filled. Associated with the stack is a pointer whose value is the address of the top of the stack."
  },
  {
    "subject": "books",
    "text": "The stack pointer is maintained in a register. Thus, references to stack locations in memory are in fact register indirect addresses. The stack mode of addressing is a form of implied addressing. The machine instructions need not include a memory reference but implicitly operate on the top of the stack."
  },
  {
    "subject": "books",
    "text": "The  operation  of  a  CPU  is  determine  by  the  instruction  it  executes,  referred  to  as  machine instructions or computer instructions. The collection of different instructions is referred as the Each instruction must contain the information required by the CPU for execution."
  },
  {
    "subject": "books",
    "text": "The elements of \uf0b7Operation  Code:  Specifies  the  operation  to  be  performed  (e.g.,  add,  move  etc.).  The operation is specified by a binary code, know as the operation code or opcode. \uf0b7Source operand reference: The operation may involve one or more source operands; that is, \uf0b7Result operand reference: The operation may produce a result."
  },
  {
    "subject": "books",
    "text": "\uf0b7Next instruction reference: This tells the CPU where to fetch the next instruction after the The next instruction to be fetched is located in main memory. But in case of virtual memory system, it may be either in main memory or secondary memory (disk)."
  },
  {
    "subject": "books",
    "text": "In most cases, the next instruction to be fetched immediately follow the current instruction. In those cases, there is no explicit reference to the next instruction. When an explicit reference is needed, then the main memory or virtual Source and result operands can be in one of the three areas: The steps involved in instruction execution is shown in the figure- Within the computer, each instruction is represented by a sequence of bits."
  },
  {
    "subject": "books",
    "text": "The instruction is divided into fields, corresponding to the constituent elements of the instruction. The instruction format is highly machine specific and it mainly depends on the machine architecture. A simple example of an instruction format is shown in the figure."
  },
  {
    "subject": "books",
    "text": "It is assume that it is a 16-bit CPU. 4 bits are  used  to  provide  the  operation  code.  So,  we  may  have  to  16  (2  4  =  16)  different  set  of instructions. With each instruction, there are two operands. To specify each operands, 6 bits are used."
  },
  {
    "subject": "books",
    "text": "It is possible to provide 64 ( 2 6 = 64 ) different operands for each operand reference. It is difficult to deal with binary representation of machine instructions. Thus, it has become common practice to use a symbolic representation of machine instructions."
  },
  {
    "subject": "books",
    "text": "Opcodes are represented by abbreviations, called mnemonics , that indicate the operations. Common examples include: Operands are also represented symbolically. For example, the instruction may mean multiply the value contained in the data location X by the contents of register R and put In this example, X refers to the address of a location in memory and R refers to a particular register."
  },
  {
    "subject": "books",
    "text": "Thus, it is possible to write a machine language program in symbolic form. Each symbolic opcode has a fixed binary representation, and the programmer specifies the location of each symbolic The instruction set of a CPU can be categorized as follows: \uf0b7Data  Processing:  Arithmatic  and  Logic  instructions  Arithmatic  instructions  provide computational capabilities for processing numeric data."
  },
  {
    "subject": "books",
    "text": "Logic (Boolean) instructions operate on the  bits  of a word as  bits  rather  than  as  numbers. Logic instructions  thus  provide capabilities for processing any other type of data. There operations are performed primarily \uf0b7Data Storage: Memory instructions Memory instructions are used for moving data between \uf0b7Data Movement: I/O instructions I/O instructions are needed to transfer program and data into memory from storage device or input device and the results of computation back to the Test instructions are used to test the value of a data word or the status of a computation."
  },
  {
    "subject": "books",
    "text": "Branch instructions are then used to branch to a different set of instructions depending on the decision arithmantic and logic operations are either unary (one operand) or binary (two operands). Thus we need a maximum of two addresses to reference operands."
  },
  {
    "subject": "books",
    "text": "In practice, four address instructions are rare. Most instructions have one, two or three operands addresses, with the address of the next instruction being implicit (obtained from the program counter). One of the most interesting, and most analyzed, aspects of computer design is instruction set design."
  },
  {
    "subject": "books",
    "text": "The  instruction  set  defines  the  functions  performed  by  the  CPU.  The  instruction  set  is  the programmer's means of controlling the CPU. Thus programmer requirements must be considered in Operation repertoire : How many and which operations to provide, and how complex operations Data Types                : The various type of data upon which operations are performed."
  },
  {
    "subject": "books",
    "text": "Instruction format     : Instruction length (in bits), number of addresses, size of various fields and so Registers                   : Number of CPU registers that can be referenced by instructions and their use. Addressing                : The mode or modes by which the address of an operand is specified."
  },
  {
    "subject": "books",
    "text": "Machine instructions operate on data. Data can be categorised as follows : Addresses: It basically indicates the address of a memory location. Addresses are nothing but the unsigned integer, but treated in a special way to indicate the address of a memory location."
  },
  {
    "subject": "books",
    "text": "Address arithmatic is somewhat different from normal arithmatic and it is related to machine architecture. Numbers: All machine languages include numeric data types. Numeric data are classified into two broad categories: integer or fixed point and floating point. Characters: A common form of data is text or character strings."
  },
  {
    "subject": "books",
    "text": "Since computer works with bits, so characters are represented by a sequence of bits. The most commonly used coding scheme is ASCII (American Standard Code for Information Interchange) code. Logical Data: Normally each word or other addressable unit (byte, halfword, and so on) is treated as a single unit of data."
  },
  {
    "subject": "books",
    "text": "It is sometime useful to consider an n-bit unit as consisting of n 1-bit items of data, each item having the value 0 or 1. When data are viewed this way, they are considered to be logical data. Generally 1 is treated as true and 0 is treated as false."
  },
  {
    "subject": "books",
    "text": "The number of different opcodes and their types varies widely from machine to machine. However, some general type of operations are found in most of the machine architecture. Those operations The most fundamental type of machine instruction is the data transfer instruction."
  },
  {
    "subject": "books",
    "text": "Third, as with all instructions with operands, the mode of addressing for each operand must be specified. The CPU has to perform several task to accomplish a data transfer operation. If both source and destination are registers, then the CPU simply causes data to be transferred from one register to another; this is an operation internal to the CPU."
  },
  {
    "subject": "books",
    "text": "If one or both operands are in memory, then the CPU must perform some or all of the following a) Calculate the memory address, based on the addressing mode. b) If the address refers to virtual memory, translate from virtual to actual memory address."
  },
  {
    "subject": "books",
    "text": "c) Determine whether the addressed item is in cache. Operation Name                                 Description Move (Transfer)               Transfer word or block from source to destination Store                                 Transfer word or block from source to destination Load (fetch)                      Transfer word from memory to processor Exchange                          Transfer word from memory to processor Clear (reset)                      Transfer word of 0s to destination Set                                     Transfer word of 0s to destination Push                                  Transfer word from source to top of stack Pop                                    Transfer word from top of stack to destination Most machines provide the basic arithmatic operations like add, subtract, multiply, divide etc."
  },
  {
    "subject": "books",
    "text": "These are  invariably  provided  for  signed  integer  (fixed-point)  numbers.  They  are  also  available  for floating point number. The execution of an arithmatic operation may involve data transfer operation to provide the operands to the ALU input and to deliver the result of the ALU operation."
  },
  {
    "subject": "books",
    "text": "Add                      Compute sum of two operands Subtract               Compute sum of two operands Multiply               Compute product of two operands Divide                  Compute quotient of two operands Absolute              Compute quotient of two operands Most machines also provide a variety of operations for manipulating individual bits of a word or AND                              Performs the logical operation AND bitwise OR                                 Performs the logical operation AND bitwise NOT                              Performs the logical operation NOT bitwise Exclusive OR                Performs the logical operation NOT bitwise Test                                Test specified condition; set flag(s) based on outcome Compare                        Make logical or arithmatic comparison Set flag(s) based on outcome Set  Control  Variables  Class  of  instructions  to  set  controls  for  protection  purposes,  interrupt Shift                              Left (right) shift operand, introducing constant at end Rotate                           Left (right) shift operation, with wraparound end Conversion instructions are those that change the format or operate on the format of data."
  },
  {
    "subject": "books",
    "text": "An Input/Output instructions are used to transfer data between input/output devices and memory/CPU Input (Read)        Transfer data from specified I/O port or device to destination (e.g., main memory Output (Write)      Transfer data from specified source to I/O port or device. Start I/O                Transfer instructions to I/O processor to initiate I/O operation."
  },
  {
    "subject": "books",
    "text": "Test I/O                 Transfer status information from I/O system to specified destination System control instructions are those which are used for system setting and it can be used only in privileged state. Typically, these instructions are reserved for the use of operating systems."
  },
  {
    "subject": "books",
    "text": "For example, a system control instruction may read or alter the content of a control register. Another instruction may be to read or modify a storage protection key. In most of the cases, the next instruction to be performed is the one that immediately follows the current instruction in memory."
  },
  {
    "subject": "books",
    "text": "Therefore, program counter helps us to get the next instruction. But sometimes it is required to change the sequence of instruction execution and for that instruction set should  provide  instructions  to  accomplish  these  tasks.  For  these  instructions,  the  operation performed by the CPU is to upload the program counter to contain the address of some instruction in memory."
  },
  {
    "subject": "books",
    "text": "The most common transfer-of-control operations found in instruction set are: branch, A branch instruction, also called a jump instruction, has one of its operands as the address of the next instruction to be executed. Basically there are two types of branch instructions: Conditional Branch  instruction  and  unconditionla  branch  instruction."
  },
  {
    "subject": "books",
    "text": "In  case  of  unconditional  branch instruction, the branch is made by updating the program counter to address specified in operand. In case of conditional branch instruction, the branch is made only if a certain condition is met. Otherwise, the next instruction in sequence is executed."
  },
  {
    "subject": "books",
    "text": "There are two common ways of generating the condition to be tested in a conditional branch instruction First most machines provide a 1-bit or multiple-bit condition code that is set as the result of some operations. As an example, an arithmetic operation could set a 2-bit condition code with one of the following four values: zero, positive, negative and overflow."
  },
  {
    "subject": "books",
    "text": "On such a machine, there could be four different conditional branch instructions: BRP X Branch to location X   if result is positive In all of these cases, the result referred to is the result of the most recent operation that set the Another approach that can be used with three address instruction format is to perform a comparison BRE R1, R2, X Branch to X if contents of R1 = Contents of R2."
  },
  {
    "subject": "books",
    "text": "Another common form of transfer-of-control instruction is the skip instruction. Generally, the skip imples that one instruction to be skipped; thus the implied address equals the address of the next instruction plus one instruction length. A typical example is the increment-and-skip-if-zero (ISZ) This instruction will increment the value of the register R1."
  },
  {
    "subject": "books",
    "text": "If the result of the increment is zero, A procedure is a self contained computer program that is incorporated into a large program. At any point in the program the procedure may be invoked, or called. The processor is instructed to go and execute the entire procedure and then return to the point from which the call took place."
  },
  {
    "subject": "books",
    "text": "The procedure mechanism involves two basic instructions: a call instruction that branches from the present location to the procedure, and a return instruction that returns from the procedure to the place from which it was called. Both of these are forms of branching instructions."
  },
  {
    "subject": "books",
    "text": "\uf0b7A procedure can be called from more than one location. \uf0b7A procedure call can appear in a procedure. This allows the nesting of procedures to an \uf0b7Each procedure call is matched by a return in the called program. Since we can call a procedure from a variety of points, the CPU must somehow save the return return can take place appropriately."
  },
  {
    "subject": "books",
    "text": "There are three common places for storing the return address: Consider a machine language instruction CALL X, which stands for call procedure at location X. If the register apprach is used, CALL X causes the following actions: where RN is a register that is always used for this purpose, PC is the program counter and IL is the The called procedure can now save the contents of RN to be used for the later return."
  },
  {
    "subject": "books",
    "text": "A second possibilities is to store the return address at the start of the procedure. In this case, CALL X causes Both of these approaches have been used. The only limitation of these approaches is that they prevent the use of reentrant procedures."
  },
  {
    "subject": "books",
    "text": "A reentrant procedure is one in which it is possible to have A more general approach is to use stack. When the CPU executes a call, it places the return address on the stack. When it executes a return, it uses the address on the stack."
  },
  {
    "subject": "books",
    "text": "It may happen that, the called procedure might have to use the processor registers. This will overwrite the contents of the registers and the calling environment will lose the information. So, it is necessary to preserve the contents of processor register too along with the return address."
  },
  {
    "subject": "books",
    "text": "The stack is used to store the contents of processor register. On return from the procedure call, the contents of the stack will be popped out to appropriate registers. In addition to provide a return address, it is also often necessary to pass parameters with a procedure call."
  },
  {
    "subject": "books",
    "text": "The most general approach to parameter passing is the stack. When the processor executes a call, it not only stacks the return address, it stacks parameters to be passed to the called procedures. The called procedure can access the parameters from the stack.Upon return, return parameters can also be placed on the stack."
  },
  {
    "subject": "books",
    "text": "The entire set of parameters, including return address, that is stored for a procedure invocation is referred to as stack frame. Jump (branch)           Unconditional transfer, load PC with specific address Jump conditional    Test specific condition; either load PC with specific address or do nothing, Jump to subroutine   Place current program control information in known location; jump to specific Return                       Replace contents of PC and other register from known location Skip                          Increment PC to skip next instruction Skip Conditional      Test specified condition; either skip or do nothing based on condition Halt                           Stop program execution An instruction format defines the layout of the bits of an instruction, in terms of its constituents parts."
  },
  {
    "subject": "books",
    "text": "An instruction format must include an opcode and, implicitly or explicitly, zero or more operands. Each explit operand is referenced using one of the addressing mode that is available for that  machine.  The  format  must,  implicitly  or  explictly,  indicate  the  addressing mode  of  each operand."
  },
  {
    "subject": "books",
    "text": "For  most  instruction  sets,  more  than  one  instruction  format  is  used.  Four  common instruction format are shown in the figure on the next slide . On some machines, all instructions have the same length; on others there may be many different lengths."
  },
  {
    "subject": "books",
    "text": "Instructions may be shorter than, the same length as, or more than the word length. Having all the instructions be the same length is simpler and make decoding easier but often wastes space, since all instructions then have to be as long as the longest one."
  },
  {
    "subject": "books",
    "text": "Possible relationship between instruction length and word length is shown in the figure. Generally there is a correlation between memory transfer length and the instruction length. Either the instruction length should be equal to the memory transfer length or one should be a multiple of the other."
  },
  {
    "subject": "books",
    "text": "Also in most of the case there is a correlation between memory transfer length and word For a given instruction length, there is a clearly a trade-off between the number of opcodes and the power of the addressing capabilities. More opcodes obviously mean more bits in the opcode field."
  },
  {
    "subject": "books",
    "text": "With a single user-visible register (usually called the accumulator), one operand address is implicit and consumes no instruction bits. Even with multiple registers, only a few bits are needed to specify the register. The more that registers can be used for operand references, the fewer bits are needed."
  },
  {
    "subject": "books",
    "text": "For addresses that reference memory, the range of addresses that can be referenced is related to the number of address bits. With displacement addressing, the range is opened up to the length of the In a system with 16- or 32-bit words, an address can reference a word or a byte at the designer's choice."
  },
  {
    "subject": "books",
    "text": "Byte addressing is convenient for character manipulation but requires, for a fixed size Instead of looking for fixed length instruction format, designer may choose to provide a variety of instructions formats of different lengths. This tectic makes it easy to provide a large repertoire of opcodes, with different opcode lengths."
  },
  {
    "subject": "books",
    "text": "Addressing can be more flexible, with various combinations of register and memory references plus addressing modes. With variable length instructions, many variations can be provided efficiently and compactly. The principal price to pay for variable length instructions is an increase in the complexity of the CPU."
  },
  {
    "subject": "books",
    "text": "The processor architecture is described in terms of the number of addresses contained in each instruction. Most of the arithmatic and logic instructions will require more operands. All arithmatic and  logic  operations  are  either  unary  (one  source  operand,  e.g.  NOT)  or  binary  (two  source Thus, we  need  a maximum  of two  addresses  to  reference  source  operands."
  },
  {
    "subject": "books",
    "text": "The  result  of an operation must be stored, suggesting a third reference. Three address instruction formats are not common because they require a relatively long instruction With two address instructions, and for binary operations, one address must do double duty as both In one address instruction format, a second address must be implicit for a binary operation."
  },
  {
    "subject": "books",
    "text": "For implicit reference, a processor register is used and it is termed as accumulator(AC). the accumulator contains one of the operands and is used to store the result. Consider a simple arithmatic expression to evalute:."
  },
  {
    "subject": "books",
    "text": "The operation or task that must perform by CPU are: \uf0b7Fetch Instruction: The CPU reads an instruction from memory. \uf0b7Interprete Instruction: The instruction is decoded to determine what action is required. \uf0b7Fetch Data: The execution of an instruction may require reading data from memory or I/O \uf0b7Process data: The execution of an instruction may require performing some arithmatic or \uf0b7Write data: The result of an execution may require writing data to memory or an I/O To do these tasks, it should be clear that the CPU needs to store some data temporarily."
  },
  {
    "subject": "books",
    "text": "It must remember the location of the last instruction so that it can know where to get the next instruction. It needs to store instructions and data temporarily while an instruction is beign executed. In other These storage location are generally referred as registers."
  },
  {
    "subject": "books",
    "text": "The major components of the CPU are an arithmatic and logic unit (ALU) and a control unit (CU). The ALU does the actual computation or processing of data. The CU controls the movement of data and instruction into and out of the CPU and controls the operation of the ALU."
  },
  {
    "subject": "books",
    "text": "The CPU is connected to the rest of the system through system bus. Through system bus, data or information gets transferred between the CPU and the other component of the system. The system Data bus is used to transfer the data between main memory and CPU."
  },
  {
    "subject": "books",
    "text": "Address bus is used to access a particular memory location by putting the address of the memory Control bus is used to provide the different control signal generated by CPU to different part of the system. As for example, memory read is a signal generated by CPU to indicate that a memory read operation has to be performed."
  },
  {
    "subject": "books",
    "text": "Through control bus this signal is transferred to memory module to There are three basic components of CPU: register bank, ALU and Control Unit. There are several data movements between these units and for that an internal CPU bus is used."
  },
  {
    "subject": "books",
    "text": "Internal CPU bus is needed to transfer data between the various registers and the ALU, because the ALU in fact operates A computer system employs a memory hierarchy. At the highest level of hierarchy, memory is more expensive. Within the CPU, there is a set of registers which can be treated as a memory in the hierarchy."
  },
  {
    "subject": "books",
    "text": "The registers in the CPU can be categorized into two groups: \uf0b7User-visible registers: These enables the machine - or assembly-language programmer to minimize main memory reference by optimizing use of registers. \uf0b7Control and status registers: These are used by the control unit to control the operation of the Operating system programs may also use these in privileged mode to control the execution of The user-visible registers can be categorized as follows: General-purpose registers  can be assigned to a variety of functions by the programmer."
  },
  {
    "subject": "books",
    "text": "In some cases,  general-purpose  registers  can  be  used  for  addressing  functions  (e.g.,  register  indirect, displacement). In other cases, there is a partial or clean separation between data registers and Data registers may be used to hold only data and cannot be employed in the calculation of an Address registers  may be somewhat general purpose, or they may be devoted to a particular \uf0b7Segment  pointer: In a  machine  with segment  addressing, a segment  register  holds  the address of the base of the segment."
  },
  {
    "subject": "books",
    "text": "There may be multiple registers, one for the code \uf0b7Index registers: These are used for indexed addressing and may be autoindexed. \uf0b7Stack pointer: If there is user visible stack addressing, then typically the stack is in memory and there is a dedicated register that points to the top of the stack."
  },
  {
    "subject": "books",
    "text": "Condition Codes (also referred to as flags) are bits set by the CPU hardware as the result of the operations. For example, an arithmatic operation may produce a positive, negative, zero or overflow result. In addition to the result itself beign stored in a register or memory, a condition code is also set."
  },
  {
    "subject": "books",
    "text": "The code may be subsequently be tested as part of a condition branch operation. Condition code There are a variety of CPU registers that are employed to control the operation of the CPU. Most of these, on most machines, are not visible to the user."
  },
  {
    "subject": "books",
    "text": "Different machines will have different register organizations and use different terminology. We will discuss here the most commonly used registers which are part of most of the machines. Four registers are essential to instruction execution: Program Counter (PC):  Contains the address of an instruction to be fetched."
  },
  {
    "subject": "books",
    "text": "Typically, the PC is updated by the CPU after each instruction fetched so that it always points to the next instruction to be executed. A branch or skip instruction will also modify the contents of the PC. Instruction Register (IR):  Contains the instruction most recently fetched."
  },
  {
    "subject": "books",
    "text": "The fetched instruction is loaded into an IR, where the opcode and operand specifiers are analyzed. Memory Address Register (MAR):  Containts the address of a location of main memory from where information has to be fetched or information has to be stored."
  },
  {
    "subject": "books",
    "text": "Contents of MAR is directly Memory Buffer Register (MBR):  Contains a word of data to be written to memory or the word most recently read. Contents of MBR is directly connected to the data bus. It is also known as Apart from these specific register, we may have some temporary registers which are not visible to the user."
  },
  {
    "subject": "books",
    "text": "The PSW typically contains condition codes plus other status information. Common fields or flags include the following: \u25cf Sign : Contains the sign bit of the result of the last arithmatic operation. \u25cf Carry : Set if an operation resulted in a carry (addition) into or borrow (subtraction) out of a high \u25cf Equal : Set if a logical campare result is equal."
  },
  {
    "subject": "books",
    "text": "\u25cf Overflow : Used to indicate arithmatic overflow. \u25cf Interrupt enable/disable : Used to enable or disable interrupts. \u25cf Supervisor : Indicate whether the CPU is executing in supervisor or user mode. Certain privileged instructions can be executed only in supervisor mode, and certain areas of Apart from these, a number of other registers related to status and control might be found in a particular CPU design."
  },
  {
    "subject": "books",
    "text": "In addition to the PSW, there may be a pointer to a block of memory containing additional status information (e.g. process control blocks). The instructions constituting a program to be executed by a computer are loaded in sequential locations in its main memory."
  },
  {
    "subject": "books",
    "text": "To execute this program, the CPU fetches one instruction at a time and performs the functions specified. Instructions are fetched from successive memory locations until the execution of a branch or a jump instruction. The CPU keeps track of the address of the memory location where the next instruction is located through the use of a dedicated CPU register, referred to as the program counter (PC)."
  },
  {
    "subject": "books",
    "text": "After fetching an instruction, the contents of the PC are updated to point at the next instruction in sequence. For simplicity, let us assume that each instruction occupies one memory word. Therefore, execution of one instruction requires the following three steps to be performed by the CPU: 1."
  },
  {
    "subject": "books",
    "text": "Fetch the contents of the memory location pointed at by the PC. The contents of this location are interpreted as an instruction to be executed. Hence, they are stored in the instruction register (IR). 3. Carry out the actions specified by the instruction stored in the IR."
  },
  {
    "subject": "books",
    "text": "The first two steps are usually referred to as the fetch phase and the step 3 is known as the execution phase. Fetch cycle basically involves read the next instruction from the memory into the CPU and along with that update the contents of the program counter."
  },
  {
    "subject": "books",
    "text": "In the execution phase, it interpretes the opcode and perform the indicated operation. The instruction fetch and execution phase together known as instruction cycle. The basic instruction cycle is shown in the figure. In cases, where an instruction occupies more than one word, step 1 and step 2 can be repeated as many times as necessary to fetch the complete instruction."
  },
  {
    "subject": "books",
    "text": "In these cases, the execution of a instruction may involve one or more operands in memory, each of which requires a memory access. Further, if indirect addressing is used, then additional memory access are required. The fetched instruction is loaded into the instruction register."
  },
  {
    "subject": "books",
    "text": "\uf0b7Control: An instruction may specify that the sequence of execution be altered. The main line of activity consists of alternating instruction fetch and instruction execution activities. After an instruction is fetched, it is examined to determine if any indirect addressing is involved."
  },
  {
    "subject": "books",
    "text": "If so, the required operands are fetched using indirect addressing. The execution cycle of a perticular instruction may involve more than one reference to memory. Also, instead of memory references, an instruction  may specify  an I/O  operation. With these additional considerations the basic instruction cycle can be expanded with more details view in this figure."
  },
  {
    "subject": "books",
    "text": "The figure is in the form of a state diagram. There are several components inside a CPU, namely, ALU, control unit, general purpose register, Instruction registers etc. Now we will see how these components are organized inside CPU. There are several ways to place these components and inteconnect them."
  },
  {
    "subject": "books",
    "text": "One such organization is shown In this case, the arithmatic and logic unit (ALU), and all CPU registers are connected via a single common bus. This bus is internal to CPU and this internal bus is used to transfer the information between different components of the CPU."
  },
  {
    "subject": "books",
    "text": "This organization is termed as single bus organization, since only one internal bus is used for transferring of information between different components of CPU. We have external bus or buses to CPU also to connect the CPU with the memory module and I/O devices."
  },
  {
    "subject": "books",
    "text": "The external memory bus is also shown in the figure A connected to the CPU via the The number and function of registers R0 to R(n-1) vary considerably from one machine to another. They may be given for general-purpose for the use of the programmer."
  },
  {
    "subject": "books",
    "text": "Alternatively, some of them may be dedicated as special-purpose registers, such as index register or stack pointers . In this organization, two registers, namely Y and Z are used which are transperant to the user. Programmer can not directly access these two registers."
  },
  {
    "subject": "books",
    "text": "These are used as input and output buffer to the ALU which will be used in ALU operations. They will be used by CPU as temporary storage for For the execution of an instruction, we need to perform an instruction cycle."
  },
  {
    "subject": "books",
    "text": "3.Transfer a word of data from one CPU register to another or to the ALU. 4.Perform an arithmatic or logic operation, and store the result in a CPU register. Now we will examine the way in which each of the above functions is implemented in a computer."
  },
  {
    "subject": "books",
    "text": "Information is  stored in memory  location  indentified  by their  address. To fetch  a word from memory, the CPU has to specify the address of the memory location where this information is stored and request a Read operation. The information may include both, the data for an operation or the instruction of a program which is available in main memory."
  },
  {
    "subject": "books",
    "text": "To perform a memory fetch operation, we need to complete the following tasks: The CPU transfers the address of the required memory location to the Memory Address Register The MAR is connected to the memory address line of the memory bus, hence the address of the Next, CPU uses the control lines of the memory bus to indicate that a Read operation is initiated."
  },
  {
    "subject": "books",
    "text": "After issuing this request, the CPU waits until it receives an answer from the memory, indicating This  is  accomplished  by  another  control  signal  of  memory  bus  known  as  Memory-Function- The memory set this signal to 1 to indicate that the contents of the specified memory location are As soon as MFC signal is set to 1, the information available in the data bus is loaded into the Memory Data Register (MDR) and this is available for use inside the CPU."
  },
  {
    "subject": "books",
    "text": "As an example, assume that the address of the memory location to be accessed is kept in register R2 memory  contents  to  be  loaded  into  register  R1.  This  is  done  by  the  following  sequence  of The time required for step 3 depends on the speed of the memory unit."
  },
  {
    "subject": "books",
    "text": "In general, the time required to access a word from the memory is longer than the time required to perform any operation within The scheme that is used here to transfer data from one device (memory) to another device (CPU) is This asynchronous transfer enables transfer of data between two independent devices that have different speeds of operation."
  },
  {
    "subject": "books",
    "text": "The data transfer is synchronised with the help of some control signals. In this example, Read request and MFC signal are doing the synchronization task. An alternative scheme is synchronous transfer. In this case all the devices are controlled by a common  clock  pulse  (continously  running  clock  of  a  fixed  frequency)."
  },
  {
    "subject": "books",
    "text": "These  pulses  provide common timing signal to the CPU and the main memory. A memory operation is completed during every  clock  period.  Though  the  synchronous  data  transfer  scheme  leads  to  a  simpler implementation, it is difficult to accommodate devices with widely varying speed."
  },
  {
    "subject": "books",
    "text": "In such cases, the duration of the clock pulse will be synchronized to the slowest device. It reduces the speed of all the The procedure of writing a word into memory location is similar to that for reading one from memory."
  },
  {
    "subject": "books",
    "text": "The only difference is that the data word to be written is first loaded into the MDR, the write command is issued. As an example, assumes that the data word to be stored in the memory is in register R1 and that the memory address is in register R2."
  },
  {
    "subject": "books",
    "text": "The memory write operation requires - In this case step 1 and step 2 are independent and so they can be carried out in any order. In fact, step 1 and 2 can be carried out simultaneously, if this is allowed by the architecture, that is, if these two data transfers (memory address and data) do not use the same data path."
  },
  {
    "subject": "books",
    "text": "In case of both memory read and memory write operation, the total time duration depends on wait for the MFC signal, which depends on the speed of the memory module. There is a scope to improve the performance of the CPU , if CPU is allowed to perform some other operation  while  waiting  for  MFC  signal."
  },
  {
    "subject": "books",
    "text": "D  uring  the  period,  CPU  can  perform  some  other instructions which do not require the use of MAR and MDR. Register transfer operations enable data transfer between various blocks connected to the common bus of CPU . We have several registers inside CPU and it is needed to transfer information from one register another."
  },
  {
    "subject": "books",
    "text": "As for example during memory write operation data from appropriate register must be moved to MDR. Since the input output lines of all the register are connected to the common internal bus, we need appropriate input output gating. The input and output gates for register R i are controlled by the signal R i in and R i out respectively."
  },
  {
    "subject": "books",
    "text": "Thus, when Riin set to 1 the data available in the common bus is loaded into Ri. Similarly when, Riout is set to 1, the contents of the register Ri are placed on the bus. To transfer data from one register to other register, we need to generate the appropriate register gating signal."
  },
  {
    "subject": "books",
    "text": "For example, to transfer the contents of register R1 to register R2 , the following actions are needed: \uf0b7Enable the output gate of register R1 by setting R1out to 1. \uf0b7Enable the input gate of register R2 by setting R2in to 1."
  },
  {
    "subject": "books",
    "text": "-- This loads data from the CPU bus into the register R2 . Generally,  ALU  is  used  inside  CPU  to  perform  arithmetic  and  logic  operation.  ALU  is  a combinational logic circuit which does not have any internal storage. Therefore, to perform any arithmetic or logic operation (say binary operation) both the input should be made available at the two inputs of the ALU simultaneously."
  },
  {
    "subject": "books",
    "text": "Once both the inputs are available then appropriate signal is generated to perform the required operation. We may have to use temporary storage (register) to carry out the operation in ALU . The sequence of operations that have to carried out to perform one ALU operation depends on the organization of the CPU."
  },
  {
    "subject": "books",
    "text": "Consider an organization in which one of the operand of ALU is stored in some temporary register Y and other operand is directly taken from CPU internal bus. The result of the ALU operation is stored in another temporary register Z."
  },
  {
    "subject": "books",
    "text": "Till now we have considered only one internal bus of CPU. The single-bus organization, which is only one of the possibilities for interconnecting different building blocks of CPU. An alternative structure is the two bus structure, where two different internal buses are used in CPU."
  },
  {
    "subject": "books",
    "text": "All register outputs are connected to bus A, add all registered inputs are connected to bus B. There is a special arrangement to transfer the data from one bus to the other bus. The buses are connected through the bus tie G."
  },
  {
    "subject": "books",
    "text": "When this tie is enabled data on bus A is transfer to bus B. When G is disabled, the two buses are electrically isolated. Since two buses are used here the temporary register Z is not required here which is used in single bus organization to store the result of ALU."
  },
  {
    "subject": "books",
    "text": "Now result can be directly transferred to bus B, since one of the inputs is in bus A. With the bus tie disabled, the result can directly be transferred to For example, for the operation, [R3] \u2190 [R1] + [R2] can now be performed as In this case source register R2 and destination register R3 has to be different, because the two operations R2 in and R2 out can not be performed together."
  },
  {
    "subject": "books",
    "text": "If the registers are made of simple We  may  have  another  CPU  organization,  where  three  internal  CPU  buses  are  used.  In  this organization each bus connected to only one output and number of inputs. The elimination of the need for connecting more than one output to the same bus leads to faster bus transfer and simple control."
  },
  {
    "subject": "books",
    "text": "A simple three-bus organization is shown in the figure D. A multiplexer is provided at the input to each of the two work registers A and B, which allow them to be loaded from either the input data bus or the register data bus."
  },
  {
    "subject": "books",
    "text": "In the diagram, a possible interconnection of three-bus organization is  presented, there may be different interconnections possible. In this three bus organization, we are keeping two input data buses instead of one that is Two separate input data buses are present \u2013 one is for external data transfer, i.e."
  },
  {
    "subject": "books",
    "text": "retrieving from memory and the second one is for internal data transfer that is transferring data from general purpose register to other building block inside the CPU. We have discussed about four different types of basic operations: \uf0b7Perform arithmetic or logic operation and store the result in CPU registers."
  },
  {
    "subject": "books",
    "text": "To execute a complete instruction we need to take help of these basic operations and we need to execute these operation in some particular order to execute an instruction. As for example, consider the instruction : \"Add contents of memory location NUM to the contents of register R1 and store the result in register R1.\" For simplicity, assume that the address NUM is given explicitly in the address field of the instruction .That is, in this instruction, direct addressing Execution of this instruction requires the following action : 2.Fetch first operand (Contents of memory location pointed at by the address field of the The instruction fetch operation is initiated by loading the contents of the PC into the MAR and To perform this task first of all the contents of PC have to be brought to internal bus and then it is loaded to MAR.To perform this task control circuit has to generate the PC out signal and MAR in signal."
  },
  {
    "subject": "books",
    "text": "After issuing the read signal, CPU has to wait for some time to get the MFC signal. During that time PC is updated by 1 through the use of the ALU. This is accomplished by setting one of the inputs to the ALU (Register Y) to 0 and the other input is available in bus which is current value of PC."
  },
  {
    "subject": "books",
    "text": "At the same time, the carry-in to the ALU is set to 1 and an add operation is specified. The updated value is moved from register Z back into the PC. Step 2 is initiated immediately after issuing the memory Read request without waiting for completion of memory function."
  },
  {
    "subject": "books",
    "text": "This is possible, because step 2 does not use the memory bus and its execution does not depend on the Step3 has been delayed until the MFC is received. Once MFC is received, the word fetched from the memory is transfered to IR (Instruction Register), Because it is an instruction."
  },
  {
    "subject": "books",
    "text": "Step 1 through 3 constitute the instruction fetch phase of the control sequence. The instruction fetch portion is same for all instructions. Next step onwards, instruction execution As soon as the IR is loaded with instruction, the instruction decoding circuits interprets its contents."
  },
  {
    "subject": "books",
    "text": "enables the control circuitry to choose the appropriate signals for the remainder of the control which we referred to as the execution phase. To design the control sequence of execution phase, it is have the knowledge of the internal structure and instruction format of the PU."
  },
  {
    "subject": "books",
    "text": "Secondly , the length In this example , we have assumed the following instruction format : The destination field of IR, which contains the address of the register R1, is used to transfer the contents of register R1 to register Y and wait for Memory function Complete."
  },
  {
    "subject": "books",
    "text": "When the read operation is completed, the memory operand is available in MDR. The result of addition operation is performed in this step. The result of addition operation is transferred from temporary register Z to the destination register It indicates the end of the execution of the instruction by generating End signal."
  },
  {
    "subject": "books",
    "text": "This indicates completion of execution of the current instruction and causes a new fetch cycle to be started by With the help of branching instruction, the control of the execution of the program is transfered from one particular position to some other position, due to which the sequence flow of control is broken."
  },
  {
    "subject": "books",
    "text": "Branching is accomplished by replacing the current contents of the PC by the branch address, that is, the address of the instruction to which branching is required. Consider a branch instruction in which branch address is obtained by adding an offset X, which is given in the address field of the branch instruction, to the current value of PC."
  },
  {
    "subject": "books",
    "text": "Most of these techniques, howeve, fall into one of the two categories, In this hardwired control techniques, the control signals are generated by means of hardwired circuit. The main objective of control unit is to generate the control signal in proper sequence."
  },
  {
    "subject": "books",
    "text": "Consider the sequence of control signal required to execute the ADD instruction that is explained in previous  lecture.  It  is  obvious  that  eight  non-overlapping  time  slots  are  required  for  proper execution of the instruction represented by this sequence. Each time slot must be at least long enough for the function specified in the corresponding step to be completed."
  },
  {
    "subject": "books",
    "text": "Since, the control unit is implemented by hardwire device and every device is having a propagation delay, due to which it requires some time to get the stable output signal at the output port after giving the input signal. So, to find out the time slot is a complicated design task."
  },
  {
    "subject": "books",
    "text": "For the moment, for simplicity, let us assume that all slots are equal in time duration. Therefore the required controller may be implemented based upon the use of a counter driven by a clock. Each state, or count, of this counter corresponds to one of the steps of the control sequence of the In the previous lecture, we have mentioned control sequence for execution of two instructions only (one is for add and other one is for branch)."
  },
  {
    "subject": "books",
    "text": "Like that we need to design the control sequence of all By looking into the design of the CPU, we may say that there are various instruction for add ADD NUM R1 Add the contents of memory location specified by NUM to the contents of register ADD R2 R1 Add the contents of register R 2 to the contents of register R 1 ."
  },
  {
    "subject": "books",
    "text": "The control sequence for execution of these two ADD instructions are different. Of course, the fetch It is clear that control signals depend on the instruction, i.e., the contents of the instruction register. It is also observed that execution of some of the instructions depend on the contents of condition code or status flag register, where the control sequence depends in conditional branch instruction."
  },
  {
    "subject": "books",
    "text": "Hence, the required control signals are uniquely determined by the following information: \uf0b7Contents of the condition code and other status flags. The external inputs represent the state of the CPU and various control lines connected to it, such as MFC status signal."
  },
  {
    "subject": "books",
    "text": "Similarly, the output of the instructor decoder consists of a separate line for each machine instruction loaded in the IR, one of the output line INS 1 to INS m is All input signals to the encoder block should be combined to generate the individual control signals."
  },
  {
    "subject": "books",
    "text": "Consder those three CPU instruction ADD_MD, BR, BRN. It is required to generate many control signals by the control unit. These are basically coming out from the encoder circuit of the control signal generator. The control signals are: PC in , PC out , Z By looking into the above three instructions, we can write the logic function for Z in as : Z in = T 1 + T 6 ."
  },
  {
    "subject": "books",
    "text": "Similarly, the Boolean logic function for ADD signal is ADD = T 1 + T 6 . ADD_MD + T 5 . BR + . . . . . . . . . . . . . . These logic functions can be implemented by a two level combinational circuit of AND and OR gates."
  },
  {
    "subject": "books",
    "text": "Similarly, the END control signal is generated by the logic function : END = T 8 . ADD_MD + T 7 . BR + ( T 7 . N + T 4 . N^) . BRN + . . . ."
  },
  {
    "subject": "books",
    "text": "The signal ADD_MD, BR, BRN etc. are coming from instruction decoder circuits which depends The signal T 1 , T 2 , T 3 etc are coming out from step decoder depends on control step counter. The signal N (Negative) is coming from condition code register."
  },
  {
    "subject": "books",
    "text": "When wait for MFC (WMFC) signal is generated, then CPU does not do any works and it waits for an MFC signal from memory unit. In this case, the desired effect is to delay the initiation of the next control step until the MFC signal is received from the main memory."
  },
  {
    "subject": "books",
    "text": "This can be incorporated by inhibiting the advancement of the control step counter for the required period. Let us assume that the control step counter is controlled by a signal called RUN. By looking at the control sequence of all the instructions, the WMFC signal is generated as: WMFC = T 2 + T 5 ."
  },
  {
    "subject": "books",
    "text": "ADD_MD + . . . . . . . . . . . . . . The RUN signal is generated with the help of WMFC signal and MFC signal. The arrangement is The MFC signal is generated by the main memory whose operation is independent of CPU clock."
  },
  {
    "subject": "books",
    "text": "Hence MFC is an asynchronous signal that may arrive at any time relative to the CPU clock. It is possible to synchronized with CPU clock with the help of a D flip-flop. When WMFC signal is high, then RUN signal is low."
  },
  {
    "subject": "books",
    "text": "This run signal is used with the master clock pulse through an AND gate. When RUN is low, then the CLK signal remains low, and it does not When the MFC signal is received, the run signal becomes high and the CLK signal becomes same with the MCLK signal and due to which the control step counter progresses."
  },
  {
    "subject": "books",
    "text": "Therefore, in the next control step, the WMFC signal goes low and control unit operates normally till the next memory In hardwired control, we saw how all the control signals required inside the CPU can be generated There is an alternative approach by which the control signals required inside the CPU can be generated  ."
  },
  {
    "subject": "books",
    "text": "This  alternative  approach  is  known  as  microprogrammed  control  unit.  In microprogrammed control unit, the logic of the control unit is specified by a microprogram. A microprogram consists of a sequence of instructions in a microprogramming language. These are A microprogrammed control unit is a relatively simple logic circuit that is capable of (1) sequencing through microinstructions and (2) generating control signals to execute each microinstruction."
  },
  {
    "subject": "books",
    "text": "The concept of microprogram is similar to computer program. In computer program the complete instructions  of  the  program  is  stored  in  main  memory  and  during  execution  it  fetches  the instructions from main memory one after another. The sequence of instruction fetch is controlled by program counter (PC) ."
  },
  {
    "subject": "books",
    "text": "Microprogram are stored in microprogram memory and the execution is Microprogram consists of microinstructions which are nothing but the strings of 0's and 1's. In a particular instance, we read the contents of one location of microprogram memory, which is nothing but a microinstruction."
  },
  {
    "subject": "books",
    "text": "Each output line ( data line ) of microprogram memory corresponds to one control signal. If the contents of the memory cell is 0, it indicates that the signal is not generated and if the contents of memory cell is 1, it indicates to generate that control signal at that instant of Control word is defined as a word whose individual bits represent the various control signal."
  },
  {
    "subject": "books",
    "text": "The  individual  control  words  in  this  microprogram  are  referred  to  as  microinstructions.  The microprograms corresponding to the instruction set of a computer are stored ina aspecial memory which will be referred to as the microprogram memory. The control words related to an instructions The control unit can generate the control signals for any instruction by sequencially reading the CWs of the corresponding microprogram from the microprogram memory."
  },
  {
    "subject": "books",
    "text": "To read the control word sequentially from the microprogram memory a microprogram counter ( PC) is needed. The basic organization of a microprogrammed control unit is shown in the figure. The \"starting address generator\" block is responsible for loading the starting address of the microprogram into the PC everytime a new instruction is loaded in the IR."
  },
  {
    "subject": "books",
    "text": "The PC is then automatically incremented by the clock, and it reads the successive microinstruction from memory. microinstruction basically provides the required control signal at that time step. The microprogram counter ensures that the control signal will be delivered to the various parts of the CPU in correct We have some instructions whose execution depends on the status of condition codes and status flag, as for example, the branch instruction."
  },
  {
    "subject": "books",
    "text": "During branch instruction execution, it is required to take  the  decision  between  the  alternative  action.  To  handle  such  type  of  instructions  with microprogrammed  control,  the  design  of  control  unit  is  based  on  the  concept  of  conditional branching  in  the  microprogram.  For  that  it  is  required  to  include  some  conditional  branch microinstructions."
  },
  {
    "subject": "books",
    "text": "In conditional microinstructions, it is required to specify the address of the microprogram memory to which the control must direct. It is known as branch address. Apart from branch address, these microinstructions can specify which of the states flags, condition codes, or possibly, bits of the instruction register should be checked as a condition for branching to take To  support  microprogram  branching,  the  organization  of  control  unit  should  be  modified  to To generate the branch address, it is required to know the status of the condition codes and status To generate the starting address, we need the instruction which is present in IR."
  },
  {
    "subject": "books",
    "text": "But for branch address generation we have to check the content of condition codes and status flag. The organization of control unit to enable conditional branching in the microprogram is shown in The control bits of the microinstructions word which specify the branch conditions and address are fed to the \"Starting and branch address generator\" block."
  },
  {
    "subject": "books",
    "text": "This block performs the function of loading a new address into the satisfied. PC when the condition of branch instruction is In a computer program we have seen that execution of every instruction consists of two part - fetch phase and execution phase of the instruction."
  },
  {
    "subject": "books",
    "text": "It is also observed that the In  microprogrammed  controlled  control  unit,  a  common  microprogram  is  used  to  fetch  the instruction. This microprogram is stored in a specific location and execution of each instruction At the end of fetch microprogram, the starting address generator unit calculate the appropriate starting address of the microprogram for the instruction which is currently present in IR."
  },
  {
    "subject": "books",
    "text": "After the PC controls the execution of microprogram which generates the appropriate control signal in proper During  the  execution  of  a  microprogram,  the  PC  is  always  incremented  everytime  a  new microinstruction is fetched from the microprogram memory, except in the following situations : 1."
  },
  {
    "subject": "books",
    "text": "When an End instruction is encountered, uPC is loaded with the address of the first CW in the 2. When a new instruction is loaded into the IR, the PC is loaded with the starting address of the 3. When a branch microinstruction is encountered, and the branch condition is satisfied, the PC is."
  },
  {
    "subject": "books",
    "text": "Since the development of the stored program computer around 1950, there are few innovations in the area of computer organization and architecture. Some of the major developments are: \uf0b7The Family Concept : Introduced by IBM with its system/360 in 1964 followed by DEC, with  its  PDP-8."
  },
  {
    "subject": "books",
    "text": "The  family  concept  decouples  the  architecture  of  a  machine  from  its implementation.  A  set  of  computers  are  offered,  with  different  price/performance characteristics, that present the same architecture to the user. \uf0b7Microprogrammed Control Unit : Suggested by Wilkes in 1951, and introduced by IBM on the S/360 line in 1964."
  },
  {
    "subject": "books",
    "text": "\uf0b7Pipelining: A means of introducing parallelism into the essentially sequential nature of a machine instruction program. Examples are instruction pipelining and vector processing. \uf0b7Multiple  Processor :  This  category  covers  a  number  of  different  organizations  and When it appeared, RISC architecture was a dramatic departure from the historical trend in processor architecture."
  },
  {
    "subject": "books",
    "text": "An analysis of the RISC architecture brings into focus many of the important issues in Although RISC architectures have been defined and designed in a variety of ways by different groups, the key elements shared by most designs are these: \uf0b7A large number of  general-purpose registers, and/or the use of compiler technology to \uf0b7An emphasis on optimizing the instruction pipeline."
  },
  {
    "subject": "books",
    "text": "Table 1 compares several RISC and non-RISC systems. We begin this chapter with a brief survey of some results on instruction sets, and then examine each of the three topics just listed. This is followed by a description of two of the best-documented RISC designs One of the most visual forms of evolution associated with computers is that of programming languages."
  },
  {
    "subject": "books",
    "text": "As a result the instruction set becomes complex. Such complex instruction sets are intended to- \uf0b7Improve execution efficiency, because complex sequences of operations can be implemented \uf0b7Provide support for even more complex and sophisticated HLLs. To reduce the gap between HLL and the instruction set of computer architecture, the system becomes more and more complex and the resulted system is termed as Complex Instruction Set A number of studies have been done over the years to determine the characteristics and patterns of execution  of  machine  instructions  generated  from  HLL  programs."
  },
  {
    "subject": "books",
    "text": "\uf0b7Execution sequencing : This determines the control and pipeline organization. These results are instructive to the machine instruction set designers, indicating which type of statements occur most often and therefore should be supported in an \u201coptimal\u201d fashion. From these studies one can observe that though a complex and sophisticated instruction set is available in a machine architecture, common programmer may not use those instructions frequently."
  },
  {
    "subject": "books",
    "text": "Researches also studied the dynamic frequency of occurrence of classes of variables. The results showed  that  majority  of  references  are  single  scalar  variables.  In  addition  references  to arrays/structures required a previous reference to their index or pointer, which again is usually a local scalar."
  },
  {
    "subject": "books",
    "text": "Thus there is a predominance of references to scalars, and these are highly localized. It is also observed that operation on local variables is performed frequently and it requires a fast accessing  of  these  operands.  So,  it  suggests  that  a  prime  candidate  for  optimization  is  the mechanism for storing and accessing local scalar variables."
  },
  {
    "subject": "books",
    "text": "The procedure calls and returns are an important aspects of HLL programs. Due to the concept of modular and functional programming, the call/return statements are becoming a predominate factor It is known fact that call/return is a most time consuming and expensive statements."
  },
  {
    "subject": "books",
    "text": "Because during call we have to restore the current state of the program which includes the contents of local variables that are present in general purpose registers. During return, we have to restore the original state of the program from where we start the procedure call."
  },
  {
    "subject": "books",
    "text": "Thus, it will be profitable to consider ways of implementing these operations efficiently. Two aspects are significant, the number of parameters and variables that a procedure deals with, and the A number of groups have looked at these results and have concluded that the attempt to make the instruction set architecture close to HLL is not the most effective design strategy."
  },
  {
    "subject": "books",
    "text": "Generalizing from the work of a number of researchers three element emerge in the computer architecture. \uf0b7First, use a large number of registers or use a compiler to optimize register usage. This is \uf0b7Second, careful attention needs to be paid to the design of instruction pipelines."
  },
  {
    "subject": "books",
    "text": "Because of the high proportion of conditional branch and procedure call instructions, a straight forward instruction  pipeline  will  be  inefficient.  This  manifests  itself  as  a  high  proportion  of instructions that are prefetched but never executed. \uf0b7Third, a simplified (reduced) instruction set is indicated."
  },
  {
    "subject": "books",
    "text": "It is observed that there is no point to design a complex instruction set which will lead to a complex architecture. Due to the fact, a most interesting and important processor architecture evolves which is termed as Reduced Instruction Set Computer (RISC) architecture."
  },
  {
    "subject": "books",
    "text": "The table in the next page compares several RISC and non-RISC Characteristics of Reduced Instruction Set Architecture : Although a variety of different approaches to reduce Instruction set architecture have been taken, certain characteristics are common to all of them: A machine cycle is defined to be the time it takes to fetch two operands from registers, perform an ALU operation, and store the result in a register."
  },
  {
    "subject": "books",
    "text": "With simple, one-cycle instructions there is little or no need of microcode, the machine instructions can  be  hardwired.  Hardware  implementation  of  control  unit  executes  faster  than  the microprogrammed control, because it is not necessary to access a microprogram control store With register\u2013to\u2013register operation, a simple LOAD and STORE operation is required to access the memory, because most of the operation are register\u2013to-register."
  },
  {
    "subject": "books",
    "text": "Generally we do not have memory\u2013 Almost all RISC instructions use simple register addressing. For memory access only, we may include some other addressing, such as displacement and PC-relative. Once the data are fetched inside the CPU, all instruction can be performed with simple register addressing."
  },
  {
    "subject": "books",
    "text": "Generally in most of the RISC machine, only one or few formats are used. Instruction length is fixed and aligned on word boundaries. Field locations, especially the opcode, are fixed. With  fixed  fields,  opcode  decoding  and  register  operand  accessing  can  occur  simultaneously."
  },
  {
    "subject": "books",
    "text": "The reason that register storage is indicated is that it is the fastest available storage device, faster than both main memory and cache. The register file will allow  the most frequently accessed operands to be kept in registers and to minimize register-memory operations."
  },
  {
    "subject": "books",
    "text": "Two basic approaches are possible, one based on software and the other on hardware. The software approach is to rely on the compiler to maximize register usage. The compiler will attempt to allocate registers to those variables that will be used the most in a given time period."
  },
  {
    "subject": "books",
    "text": "This approach requires the use of sophisticated program-analysis algorithms. The hardware approach is simply to use more registers so that more variables can be held in registers for longer periods of time. Here we will discuss the hardware approach. For fast execution of instructions, it is desirable of quick access to operands."
  },
  {
    "subject": "books",
    "text": "There is large proportion of assignment statements in HLL programs, and many of these are of the simple form A\u2190B. Also there are significant number of operand accesses per HLL Statement. Also it is observed that most of the accesses are local scalars."
  },
  {
    "subject": "books",
    "text": "To get a fast response, we must have an easy excess to these local scalars, and so the use of register storage is suggested. Since registers are the fastest available storage devices, faster than both main memory and cache, so the uses of registers are preferable."
  },
  {
    "subject": "books",
    "text": "The register file is physically small, and on the same chip as the ALU and Control Unit. A strategy is needed that will allow the most frequently accessed operands to be kept in registers and to minimize register-memory operations. Two basic approaches are possible, one is based on software and the other on hardware."
  },
  {
    "subject": "books",
    "text": "\uf0b7The software approach is to rely on the compiler to maximize register uses. The compiler will attempt to allocate registers to those variables that will be used the most in a given time \uf0b7The hardware approach is simply to use more registers so that more variables can be held in The use of a large set of registers should decrease the need to access memory."
  },
  {
    "subject": "books",
    "text": "The design task is to organize the registers in such a way that this goal is realized. Due to the use of the concept of modular programming, the present day programs are dominated by call/return statements. There are some local variables present in each function or procedure."
  },
  {
    "subject": "books",
    "text": "3.There are also some global variables which are used by the module or procedure. Thus the variables that are used in a program can be categorized as follows : \uf0b7Global variables : which is visible to all the procedures. \uf0b7Local variables : which is local to a procedure and it can be accessed inside the procedure \uf0b7Passed parameters : which are passed to a subroutine from the calling program."
  },
  {
    "subject": "books",
    "text": "So, these are \uf0b7Returned  variable  :  variable  to  transfer  the  results  from  called  program  to  the  calling program. These are also visible to both called and calling program. CISC has richer instruction sets, which include a larger number of instructions and more complex instructions."
  },
  {
    "subject": "books",
    "text": "Two principal reasons have motivated this trend: a desire to simplify compilers and a The first of the reasons cited, compiler simplification, seems obvious. The task of the compiler writer is to generate a sequence of machine instructions for each HLL statement."
  },
  {
    "subject": "books",
    "text": "If there are machine instructions that resemble HLL statements, this task is simplified. This reasoning has been disputed by the RISC researchers. They have found that complex machine instructions are often hard to exploit because the compiler must find those cases that exactly fit the construct."
  },
  {
    "subject": "books",
    "text": "The task of optimizing the generated code to minimize code size, reduce instruction execution count, and enhance pipelining is much more difficult with a complex instruction set. The other major reason cited is the expectation that a CISC will yield smaller, faster programs."
  },
  {
    "subject": "books",
    "text": "Let us examine both aspects of this assertion: that program will be smaller and that they will execute faster. There are two advantages to smaller programs. \uf0b7First, because the program takes up less memory, there is a savings in that resource."
  },
  {
    "subject": "books",
    "text": "\uf0b7Second, in a paging environment, smaller programs occupy fewer pages, reducing page The problem with this line of reasoning is that it is far from certain that a CISC program will be smaller than a corresponding RISC program. Thus it is far from clear that a trend to increasingly complex instruction sets is appropriate."
  },
  {
    "subject": "books",
    "text": "The result is that the more recent RISC designs, notably the PowerPC, are no longer \u201cpure\u201d RISC and the more recent CISC designs, notably the Pentium II and later Pentium models, do incorporate some RISC characteristics. For purposes of this comparison, the following are considered typical of a classic RISC: 3.A small number of data addressing modes,typically less than five.This parameter is difficult to pin down."
  },
  {
    "subject": "books",
    "text": "In the table, register and literal modes are not counted and different formats with different offset sizes are counted separately. 4.No indirect addressing that requires you to make one memory access to get the address of 5.No operations  that combine load/store with arithmetic (e.g., add from memory, add to 6.No more than one memory-addressed operand per instruction."
  },
  {
    "subject": "books",
    "text": "10.Number of bits for floating-point register specifier equal to four or more.This means that at least 16 floating-point registers can be explicitly referenced at a time. Items 1 through 3 are an indication of instruction decode complexity. Items 4 through 8 suggest the ease or difficulty of pipelining, especially in the presence of virtual memory requirements."
  },
  {
    "subject": "books",
    "text": "Items 9 and 10 are related to the ability to take good advantage of compilers. In the table, the first eight processors are clearly RISC architectures, the next five are clearly CISC, and  the  last  two  are  processors  often  thought  of  as  RISC  that  in  fact  have  many  CISC."
  },
  {
    "subject": "books",
    "text": "It is observed that organization enhancements to the CPU can improve performance. We have already seen that use of multiple registers rather than a single a accumulator, and use of cache memory improves the performance considerably. Another organizational approach, which is quite Pipelining is a particularly effective way of organizing parallel activity in a computer system."
  },
  {
    "subject": "books",
    "text": "The basic idea is very simple. It is frequently encountered in manufacturing plants, where pipelining is By laying the production process out in an assembly line, product at various stages can be worked on simultaneously. This process is also referred to as pipelining, because, as in a pipeline, new inputs are accepted at one end before previously accepted inputs appear as outputs at the other end."
  },
  {
    "subject": "books",
    "text": "To apply the concept of instruction execution in pipeline, it is required to break the instruction in different task. Each task will be executed in different processing elements of the CPU. As we know that there are two distinct phases of instruction execution: one is instruction fetch and the other one is instruction execution."
  },
  {
    "subject": "books",
    "text": "Therefore, the processor executes a program by fetching and Let Fi and Ei refer to the fetch and execute steps for instruction Ii. Execution of a program consists of a sequence of fetch and execute steps is shown in the figure on the next slide."
  },
  {
    "subject": "books",
    "text": "Now consider a CPU that has two separate hardware units, one for fetching instructions and another for executing The instruction fetch by the fetch unit is stored in an intermediate storage buffer B1. The results of execution are stored in the destination location specified by the instruction."
  },
  {
    "subject": "books",
    "text": "For simplicity it is assumed that fetch and execute steps of any instruction can be completed in one clock cycle. The operation of the computer proceeds as follows: \uf0b7In the first clock cycle, the fetch unit fetches an instruction (instruction I1, step F1) and stored it in buffer \uf0b7In the second clock cycle, the instruction fetch unit proceeds with the fetch operation for instruction I2 \uf0b7Meanwhile, the execution unit performs the operation specified by instruction  I1which is already fetched \uf0b7By the end of the second clock cycle, the execution of the instruction I1 is completed and instruction  I2 is \uf0b7Instruction I2 is stored in buffer B1 replacing I1 which is no longer needed."
  },
  {
    "subject": "books",
    "text": "\uf0b7Step  E2 is performed by the execution unit during the third clock cycle, while instruction  I3 is being \uf0b7Both the fetch and execute units are kept busy all the time and one instruction is completed after each \uf0b7If a long sequence of instructions is executed, the completion rate of instruction execution will be twice that achievable by the sequential operation with only one unit that performs both fetch and execute."
  },
  {
    "subject": "books",
    "text": "Basic idea of instruction pipelining with hardware organization is shown in the figure on the next slide. The processing of an instruction need not be divided into only two steps. To gain further speed up, the pipeline Let us consider the following decomposition of the instruction execution: \uf0b7Fetch Instruction (FI): Read the next expected instruction into a buffer."
  },
  {
    "subject": "books",
    "text": "For the sake of simplicity, let us assume the equal duration to perform all the subtasks. It the six stages are not of equal duration, there will be some waiting involved at The timing diagram for the execution of instruction in pipeline fashion is shown in the figure on the next slide."
  },
  {
    "subject": "books",
    "text": "From this timing diagram it is clear that the total execution time of 8 instructions in this 6 stages pipeline is 13-time unit. The first instruction gets completed after 6 time unit, and there after in each time unit it completes one instruction."
  },
  {
    "subject": "books",
    "text": "Without pipeline, the total time required to complete 8 instructions would have been 48 (6 X 8) time unit. Therefore, there is a speed up in pipeline processing and the speed up is related to the number of stages. i.e. We have a k fold speed up, the speed up factor is a function of the number of stages in the Though, it has been seen that the speed up is proportional to number of stages in the pipeline, but in speed up is less due to some practical reason."
  },
  {
    "subject": "books",
    "text": "The factors that affect the pipeline performance is Consider a pipeline processor, which process each instruction in four steps; D: Decode, decode the instruction and fetch the source operand (S) W: Write, store the result in the destination location. The hardware organization of this four-stage pipeline processor is shown next."
  },
  {
    "subject": "books",
    "text": "In the preceding section we have seen that the speed up of pipeline processor is related to number of stages in the pipeline, i.e, the greater the number of stages in the pipeline, the faster the execution rate. But the organization of the stages of a pipeline is a complex task and if affects the performance At each stage of the pipeline, there is some overhead involved in moving data from buffer to buffer and  in  performing  various  preparation  and  delivery  functions."
  },
  {
    "subject": "books",
    "text": "This  overhead  can  appreciably lengthen the total execution time of a single instruction. The amount of control logic required to handle memory and register dependencies and to optimize the use of the pipeline increases enormously with the number of stages. Apart from hardware organization, there are some other reasons which may effect the performance Consider the four-stage pipeline with processing step Fetch, Decode, Operand and write."
  },
  {
    "subject": "books",
    "text": "The stage-3 of the pipeline is responsible for arithmetic and logic operation, and in general one Although this may be sufficient for most operations, but some operations like divide may require more time to complete. Following figure shows the effect of an operation that takes more than one clock cycle to complete an operation in operate stage."
  },
  {
    "subject": "books",
    "text": "The operate stage for instruction I2 takes 3 clock cycle to perform the specified operation. Clock cycle 4 to 6 required to perform this operation and so write stage is doing nothing during the clock cycle 5 and 6, because no data is available to write."
  },
  {
    "subject": "books",
    "text": "Meanwhile, the information in buffer B2 must remain intake until the operate stage has completed its operation. This means that stage 2 and stage 1 are blocked from accepting new instructions because the information in B1 cannot be overwritten by a new fetch instruction."
  },
  {
    "subject": "books",
    "text": "The contents of B1, B2 and B3 must always change at the same clock edge. Due to that reason, pipeline operation is said to have been stalled for two clock cycle. Normal pipeline operation resumes in clock cycle 7. Whenever the pipeline stalled, some degradation in The use of cache memory solves the memory access problem."
  },
  {
    "subject": "books",
    "text": "Occasionally, a memory request results in a cache miss. This causes the pipeline stage that issued the memory request to take much longer time to complete its task and in this case the pipeline stalls. The effect of cache miss in Function performed by each stage as a function of time In this example, instruction  I1  is fetched from the cache in cycle 1 and its execution proceeds normally."
  },
  {
    "subject": "books",
    "text": "The fetch operation for instruction I2 which starts in cycle 2, results in a cache miss. The instruction fetch unit must now suspend any further fetch requests and wait for I2 to arrive. We assume that instruction I2 is received and loaded into buffer B1 at the end of cycle 5, It appears that cache memory used here is four time faster than the main memory."
  },
  {
    "subject": "books",
    "text": "The pipeline resumes its normal operation at that point and it will remain in normal operation mode for some times, because a cache miss generally transfer a block from main memory to cache. From the figure, it is clear that Decode unit, Operate unit and Write unit remain idle for three clock cycle."
  },
  {
    "subject": "books",
    "text": "Such idle periods are sometimes referred to as bubbles in the pipeline. Once created as a result of a delay in one of the pipeline stages, a bubble moves downstream until it reaches the last unit. A pipeline can not stall as long as the instructions and data being accessed reside in the cache."
  },
  {
    "subject": "books",
    "text": "This is facilitated by providing separate on chip instruction and data caches. Consider the following program that contains two instructions, I1 followed by I2 When this program is executed in a pipeline, the execution of I2 can begin before the execution of In clock cycle 3, the specific operation of instruction I1 i.e."
  },
  {
    "subject": "books",
    "text": "addition takes place and at that time only the new updated value of A is available. But in the clock cycle 3, the instruction I2 is fetching the operand that is required for the operation of  I2. Since in clock cycle 3 only, operation of instruction I1 is taking place, so the instruction will get operation of the old value of A , it will not get the updated value of A , and will produce a wrong result."
  },
  {
    "subject": "books",
    "text": "Consider that the initial value of A is 4. But due to the pipeline action, we will get the result as Due to the data dependency, these two instructions can not be performed in parallel. Therefore, no two operations that depend on each other can be performed in parallel."
  },
  {
    "subject": "books",
    "text": "For correct execution, it is required to satisfy the following: \uf0b7The operation of the fetch stage must not depend on the operation performed during the \uf0b7The operation of fetching an instruction must be independent of the execution results of the \uf0b7The dependency of data arises when the destination of one instruction is used as a source in In general when we are executing a program the next instruction to be executed is brought from the next memory location."
  },
  {
    "subject": "books",
    "text": "Therefore, in pipeline organization, we are fetching instructions one after But in case of conditional branch instruction, the address of the next instruction to be fetched depends on the result of the execution of the instruction. Since the execution of next instruction depends on the previous branch instruction, sometimes it may  be  required  to  invalidate  several  instruction  fetches."
  },
  {
    "subject": "books",
    "text": "Consider  the  following  instruction In this instruction sequence, consider that I3 is a conditional branch instruction. The result of the instruction will be available at clock cycle 5. But by that time the fetch unit has If the branch condition is false, then branch won't take place and the next instruction to be executed is I4 which is already fetched and available for execution."
  },
  {
    "subject": "books",
    "text": "Now consider that when the condition is true, we have to execute the instruction I10 after clock cycle 5, it is known that branch condition is true and now instruction I 10 has to be executed. But already the processor has fetched instruction I4 and I5 it is required to invalidate these two fetched instruction and the pipe line must be loaded with new destination instruction I 10."
  },
  {
    "subject": "books",
    "text": "Due to this reason, the pipeline will stall for some time. The time lost due to branch instruction is The effect of branch takes place is shown in the figure in the previous slide. Due to the effect of branch takes place, the instruction I4 and I5 which has already been fetched is not executed and new There is not effective output in clock cycle 7 and 8, and so the branch penalty is 2."
  },
  {
    "subject": "books",
    "text": "The branch penalty depends on the number of stages in the pipeline. More numbers of stages results in more One of the major problems in designing an instruction pipe line is assuming a steady flow of instructions to the initial stages of the pipeline."
  },
  {
    "subject": "books",
    "text": "The primary problem is the conditional brancho instruction until the instruction is actually executed, it is impossible to determine whether the A variety of approaches have been taken for dealing with conditional branches: A single pipeline suffers a penalty for a branch instruction because it must choose one of two instructions to fetch next and sometimes it may make the wrong choice."
  },
  {
    "subject": "books",
    "text": "A brute-force approach is to replicate the initial portions of the pipeline and allow the pipeline to fetch both instructions, making use of two streams. \uf0b7With multiple pipelines there are contention delays for access to the registers and to memory \uf0b7Additional branch instructions may enter the pipeline (either stream) before the original branch decision is resolved."
  },
  {
    "subject": "books",
    "text": "Each such instruction needs as additional stream. When a conditional branch is recognized, the target of the branch is prefetced, in addition to the instruction following the branch. This target is then saved until the branch instruction is executed. If the branch is taken, the target has already been prefetched,."
  },
  {
    "subject": "books",
    "text": "A top buffer is a small, very high speed memory maintained by the instruction fetch stage of the pipeline and containing the most recently fetched instructions, in sequence. If a branch is to be taken, the hardware first cheeks whether the branch target is within the buffer."
  },
  {
    "subject": "books",
    "text": "This is usual for the common occurrence of IF-THEN and 3. This strategy is particularly well suited for dealing with loops, or iterations; hence the name loop buffer. If the loop buffer is large enough to contain all the instructions in a loop, then those instructions need to be fetched from memory only once, for the first iteration."
  },
  {
    "subject": "books",
    "text": "For subsequent iterations, all the needed instructions are already in the buffer. The loop buffer is similar in principle to a cache dedicated to instructions. The differences are that the loop buffer only retains instructions in sequence and is much smaller in size and hence lower in Various techniques can be used to predict whether a branch will be taken or not."
  },
  {
    "subject": "books",
    "text": "The most common The first three approaches are static; they do not depend on the execution history upto the time of the conditional branch instructions. The later two approaches are dynamic- they depend on the Predict  never  taken  always  assumes  that  the  branch  will  not  be  taken  and  continue  to  fetch instruction in sequence."
  },
  {
    "subject": "books",
    "text": "Predict always taken assumes that the branch will be taken and always fetch the branet target In these two approaches it is also possible to minimize the effect of a wrong If the fetch of an instruction after the branch will cause a page fault or protection violation, the processor  halts  its  prefetching  until  it  is  sure  that  the  instruction  should  be  fetched."
  },
  {
    "subject": "books",
    "text": "Studies analyzing program behaviour have shown that conditional branches are taken more than 50% of the time, and so if the cost of prefetching from either path is the same, then always prefetching from the branch target address should give better performance than always prefetching from the sequential However, in a paged machine, prefetching the branch target is more likely to cause a page fault than prefetching the next instruction in the sequence and so this performance penalty should be taken Predict by opcode approach makes the decision based on the opcade of the branch instruction."
  },
  {
    "subject": "books",
    "text": "The processor assumes that the branch will be taken for certain branch opcodes and not for others. Studies reported in showed that success rate is greater than 75% with the strategy. Dynamic branch strategies attempt to improve the accuracy of prediction by recording the history of conditional branch instructions in a program."
  },
  {
    "subject": "books",
    "text": "Scheme to maintain the history information: \uf0b7One or more bits can be associated with each conditional branch instruction that reflect the \uf0b7These bits are referred to as a taken/not taken switch that directs the processor to make a particular decision the next time the instruction is encountered."
  },
  {
    "subject": "books",
    "text": "\uf0b7Generally these history bits are not associated with the instruction in main memory. It will unnecessarily increase the size of the instruction. With a single bit we can record whether the last execution of this instruction resulted a branch or not."
  },
  {
    "subject": "books",
    "text": "\uf0b7With only one bit of history, an error in prediction will occur twice for each use of the loop: If two bits are used, they can be used to record the result of the last two instances of the execution The history information is not kept in main memory, it can be kept in a temporary high speed memory."
  },
  {
    "subject": "books",
    "text": "One possibility is to associate these bits with any conditional branch instruction that is in a cache. When the instruction is replaced in the cache, its history is lost. Another possibility is to maintain a small table for recently executed branch instructions with one or more bits in each entry."
  },
  {
    "subject": "books",
    "text": "The branch history table is a small cache memory associated with the instruction fetch stage of the pipeline. Each entry in the table consists of three elements: \uf0b7Some member of history bits that record the state of use of that instruction."
  },
  {
    "subject": "books",
    "text": "\uf0b7Information about the target instruction, it may be the address of the target instruction, or Consider that the instruction Ij is a branch instruction. The processor begins fetching instruction Ij+1 before it determine whether the current instruction, Ij , is a branch instruction."
  },
  {
    "subject": "books",
    "text": "When execution of is completed and a branch must be made, the processor must discard the instruction that was fetched and now fetch the instruction at the branch target. The location following a branch instruction is called a branch delay slot."
  },
  {
    "subject": "books",
    "text": "There may be more than one branch delay slot, depending on the time it takes to execute a branch instruction. The instructions in the delay slots are always fetched and at least partially executed before the branch decision is made and the branch target address is computed."
  },
  {
    "subject": "books",
    "text": "Delayed branching is a technique to minimize the penalty incurred as a result of conditional branch instructions. The instructions in the delay slots are always fetched, so we can arrange the instruction in delay slots to be fully executed whether or not the branch is taken."
  },
  {
    "subject": "books",
    "text": "The objective is to plane useful instruction in these slots. If no useful instructions can be placed in the delay slots, these slots must  be  filled  with  NOP (no  operation)  instructions.  While  feeling  up  the  delay  slots  with instructions, it is required to maintain the original semantics of the program."
  },
  {
    "subject": "books",
    "text": "Here register R2 is used as a counter to determine the number of times the contents of register R1 are sifted left. Consider a processor with a two-stage pipeline and one delay slot. During the execution phase of the instruction I3 the fetch unit will fetch the instruction I4."
  },
  {
    "subject": "books",
    "text": "During the loop execution, every time there is a wrong fetch of instruction I4. The code segment can be recognized without disturbing the original meaning of the program. In this case, the shift instruction is fetched while the branch instruction is being executed."
  },
  {
    "subject": "books",
    "text": "After evaluating  the  branch  condition,  the  processor  fetches  the  instruction  at  LOOP or  at  NEXT, depending on whether the branch condition is true or false, respectively. In either case, it completes execution of the shift instruction. Logically the program is executed as if the branch instruction was placed after the shift instruction."
  },
  {
    "subject": "books",
    "text": "Difference: \u2022 Fetch and Execution are part of normal CPU operation, while interrupts cause deviation from the normal execution cycle.  d) Discuss the difference between ALU and Control Unit. 1. ALU (Arithmetic Logic Unit): o Performs arithmetic (addition, subtraction) and logic (AND, OR, NOT) operations."
  },
  {
    "subject": "books",
    "text": "o It is a computation unit. 2. Control Unit (CU): o Directs the operations of the processor by generating control signals. o It fetches, decodes, and sends signals to coordinate data flow between CPU, memory, and I/O devices. Difference: \u2022 ALU performs computations, while the Control Unit manages the execution and control of instructions."
  },
  {
    "subject": "books",
    "text": "e) Define cache mapping function. \u2022 A cache mapping function determines how memory blocks are mapped to cache lines. Key Mapping Techniques: 1. Direct Mapping: o Each memory block is mapped to a single cache line using a modulo operation. 2."
  },
  {
    "subject": "books",
    "text": "Associative Mapping: o A memory block can be placed in any cache line (fully flexible). 3. Set-Associative Mapping: o Combines both approaches. Cache lines are divided into sets, and a memory block can map to any line within a set. Example (Given in question): \u2022 A computer system uses four-way set-associative mapping with 128-byte cache and 32-bit addresses."
  },
  {
    "subject": "books",
    "text": "o Examples: Program Counter (PC), Instruction Register (IR), Status Register (flags). Difference: \u2022 User-visible registers are for program data manipulation, while control-status registers are for CPU operation management.  c) Explain the concept of program execution. \u2022 Program execution involves fetching, decoding, and executing instructions stored in memory."
  },
  {
    "subject": "books",
    "text": "\u2022 It follows a sequence of instruction cycles: o Fetch \u2192 Decode \u2192 Execute \u2192 Write Back. \u2022 During execution, the PC advances, and operations are performed by ALU and registers.  d) Define cache mapping function and explain the differences among direct, associative, and set-associative mappings.."
  },
  {
    "subject": "books",
    "text": "Silberschatz, Galvin and Gagne \u00a92013 Operating System Concepts \u2013 9th Edition \uf06eTo provide a detailed description of various ways of \uf06eTo discuss various memory -management techniques, \uf06eTo provide a detailed description of the Intel Pentium, which supports both pure segmentation and segmentation with paging \uf06eProgram must be brought (from disk)  into memory and \uf06eMain memory and registers are only storage CPU can access directly \uf06eMemory unit only sees a stream of addresses + read requests, or address + data and write requests \uf06eMain memory can take many cycles, causing a stall \uf06eProtection of memory required to ensure correct operation \uf06eA pair of base and limit registers define the logical address space \uf06eCPU must check every memory access generated in user mode to be sure it is between base and limit for that user \uf06ePrograms on disk, ready to be brought into memory to execute form an \uf06cWithout support, must be loaded into address 0000 \uf06eInconvenient to have first user process physical address always at 0000 \uf06eFurther, addresses represented in different ways at different stages of a \uf06cCompiled code addresses bind to relocatable addresses \uf06cLinker or loader will bind relocatable addresses to absolute addresses \uf06eAddress binding of instructions and data to memory addresses \uf06cCompile time :  If memory location known a priori, absolute code  can be generated; must recompile code if starting \uf06cLoad time :  Must generate relocatable code if memory \uf06cExecution time:  Binding delayed until run time if the process can be moved during its execution from one memory segment to another \uf034Need hardware support for address maps (e.g., base and limit registers) \uf06eThe concept of a logical address space that is bound to a separate physical address space is central to proper memory \uf06cLogical address \u2013 generated by the CPU; also referred to \uf06cPhysical address \u2013 address seen by the memory unit \uf06eLogical and physical addresses are the same in compile-time and load-time address -binding schemes; logical (virtual) and physical addresses differ in execution-time address -binding \uf06eLogical address space is the set of all logical addresses \uf06ePhysical address space is the set of all physical addresses generated by a program \uf06eHardware device that at run time maps virtual to physical \uf06eMany methods possible, covered in the rest of this chapter \uf06eTo start, consider simple scheme where the value in the relocation register is added to every address generated by a user process at the time it is sent to memory \uf06cMS-DOS on Intel 80x86 used 4 relocation registers \uf06eThe user program deals with logical  addresses; it never sees the \uf06cExecution-time binding occurs when reference is made to location in memory \uf06e All routines kept on disk in relocatable load format \uf06e Useful when large amounts of code are needed to handle infrequently occurring cases \uf06e No special support from the operating system is required \uf06c OS can help by providing libraries to implement dynamic loading \uf06eStatic linking \u2013 system libraries and program code combined by \uf06eDynamic linking \u2013linking postponed until execution time \uf06eSmall piece of code, stub , used to locate the appropriate \uf06eStub replaces itself with the address of the routine, and executes \uf06eOperating system checks if routine is in processes \u2019 memory \uf06eDynamic linking is particularly useful for libraries \uf06eConsider applicability to patching system libraries \uf06eA process can be swapped  temporarily out of memory to a backing store, and then brought back into memory for continued \uf06cTotal physical memory space of processes can exceed physical memory \uf06eBacking store \u2013 fast disk large enough to accommodate copies of all memory images for all users; must provide direct access to these memory images \uf06eRoll out, roll in \u2013 swapping variant used for priority -based scheduling algorithms; lower -priority process is swapped out so higher -priority process can be loaded and executed \uf06eMajor part of swap time is transfer time; total transfer time is directly proportional to the amount of memory swapped \uf06eSystem maintains a ready queue  of ready -to-run processes \uf06eDoes the swapped out process need to swap back in to same \uf06cPlus consider pending I/O to / from process memory space \uf06eModified versions of swapping are found on many systems (i.e., UNIX, Linux, and Windows) \uf06cStarted if more than threshold amount of memory allocated \uf06eIf next processes to be put on CPU is not in memory, need to \uf06e100MB process swapping to hard disk with transfer rate of 50MB/sec \uf06cTotal context switch swapping component time of 4000ms (4 seconds) \uf06eCan reduce if reduce size of memory swapped \u2013 by knowing \uf06cPending I/O \u2013 can\u2019t swap out as I/O would occur to wrong \uf06cOr always transfer I/O to kernel space, then to I/O device \uf06eStandard swapping not used in modern operating systems \uf034Poor throughput between flash memory and CPU on mobile \uf06ciOS asks apps to voluntarily relinquish allocated memory \uf034Read-only data thrown out and reloaded from flash if needed \uf06cAndroid terminates apps if low free memory, but first writes application state to flash for fast restart \uf06eMain memory must support both OS and user processes \uf06cResident operating system, usually held in low memory with \uf06cEach process contained in single contiguous section of memory \uf06eRelocation registers used to protect user processes from each other, and from changing operating-system code and data \uf06cBase register contains value of smallest physical address \uf06cLimit register contains range of logical addresses \u2013 each logical address must be less than the limit register \uf06cCan then allow actions such as kernel code being transient Hardware Support for Relocation and Limit Registers \uf06cDegree of multiprogramming limited by number of partitions \uf06cVariable- partition sizes for efficiency (sized to a given process\u2019 needs) \uf06cHole \u2013 block of available memory; holes of various size are scattered \uf06cWhen a process arrives, it is allocated memory from a hole large enough to accommodate it \uf06cProcess exiting frees its partition, adjacent free partitions combined \uf06cOperating system maintains information about: a) allocated partitions    b) free partitions (hole) \uf06eFirst -fit:  Allocate the first hole that is big enough \uf06eBest -fit:  Allocate the smallest  hole that is big enough; must \uf06eWorst -fit:  Allocate the largest  hole; must also search entire list First-fit and best -fit better than worst -fit in terms of speed and storage \uf06eExternal Fragmentation  \u2013 total memory space exists to \uf06eInternal Fragmentation  \u2013 allocated memory may be slightly larger than requested memory; this size difference is memory \uf06cShuffle memory contents to place all free memory together \uf06cCompaction is possible only if relocation is dynamic, and is \uf06eNow consider that backing store has same fragmentation problems \uf06eMemory -management scheme that supports user view of memory \uf06eSegment table \u2013 maps two-dimensional physical addresses; each \uf06cbase \u2013 contains the starting physical address where the \uf06eSegment -table base register (STBR)  points to the segment \uf06eSegment -table length register (STLR)  indicates number of \uf06eProtection bits associated with segments; code sharing \uf06eSince segments vary in length, memory allocation is a dynamic storage-allocation problem \uf06eA segmentation example is shown in the following diagram \uf06ePhysical  address space of a process can be noncontiguous; process is allocated physical memory whenever the latter is available \uf06eDivide physical memory into fixed-sized blocks called frames \uf06cSize is power of 2, between 512 bytes and 16 Mbytes \uf06eDivide logical memory into blocks of same size called pages \uf06eTo run a program of size N  pages, need to find N  free frames and \uf06eSet up a page table to translate logical to physical addresses \uf06cPage number (p) \u2013 used as an index into a page table which contains base address of each page in physical memory physical memory address that is sent to the memory unit \uf06cFor given logical address space 2m and page size 2n page numberpage offset \uf06cInternal fragmentation of 2,048 - 1,086 = 962 bytes \uf06eProcess view and physical memory now very different \uf06eBy implementation process can only access its own memory \uf06ePage-table base register (PTBR) points to the page table \uf06ePage-table length register (PTLR ) indicates size of the page \uf06eIn this scheme every data/instruction access requires two \uf06cOne for the page table and one for the data / instruction \uf06eThe two memory access problem can be solved by the use of a special fast -lookup hardware cache called associative \uf06eSome TLBs store  address-space identifiers (ASIDs ) in each TLB entry \u2013 uniquely identifies each process to provide \uf06eOn a TLB miss, value is loaded into the TLB for faster access \uf06cSome entries can be wired down for permanent fast \uf06cHit ratio \u2013 percentage of times that a page number is found in the associative registers; ratio related to number of associative \uf06eConsider \u03b1 = 80%, \u03b5 = 20ns for TLB search, 100ns for memory access \uf06e Consider \u03b1 = 80%, \u03b5 = 20ns for TLB search, 100ns for memory access \uf06eConsider more realistic hit ratio ->  \u03b1 = 99%, \u03b5 = 20ns for TLB search, \uf06eMemory protection implemented by associating protection bit with each frame to indicate if read-only or read- write access is \uf06cCan also add more bits to indicate page execute-only, and so on \uf06eValid-invalid bit attached to each entry in the page table: \uf06c\u201cvalid \u201d indicates that the associated page is in the process \u2019 logical address space, and is thus a legal page \uf06c\u201cinvalid \u201d indicates that the page is not in the process \u2019 \uf06cOne copy of read-only ( reentrant ) code shared among processes (i.e., text editors, compilers, window systems) \uf06cSimilar to multiple threads sharing the same process space \uf06cAlso useful for interprocess communication if sharing of \uf06cEach process keeps a separate copy of the code and data \uf06cThe pages for the private code and data can appear anywhere in the logical address space \uf06eMemory structures for paging can get huge using straight - \uf06cConsider a 32-bit logical address space as on modern \uf06cPage table would have 1 million entries (232 / 212) \uf06cIf each entry is 4 bytes -> 4 MB of physical address space / \uf034Don\u2019t want to allocate that contiguously in main memory \uf06eBreak up the logical address space into multiple page \uf06eA logical address (on 32-bit machine with 1K page size) is divided into: \uf06eSince the page table is paged, the page number is further divided into: \uf06ewhere p1 is an index into the outer page table, and p2 is the displacement within the page of the inner page table \uf06cIf two level scheme, inner page tables could be 210 4-byte entries \uf06cBut in the following example the 2nd outer page table is still 234 bytes in \uf034And possibly 4 memory access to get to one physical memory \uf06eThe virtual page number is hashed into a page table \uf06cThis page table contains a chain of elements hashing to the same \uf06eEach element contains (1) the virtual page number (2) the value of the mapped page frame (3) a pointer to the next element \uf06eVirtual page numbers are compared in this chain searching for a match \uf06cIf a match is found, the corresponding physical frame is extracted \uf06eVariation for 64-bit addresses is clustered page tables \uf06cSimilar to hashed but each entry refers to several pages (such as 16) rather than 1 \uf06cEspecially useful for sparse address spaces (where memory \uf06eRather than each process having a page table and keeping track of all possible logical pages, track all physical pages \uf06eEntry consists of the virtual address of the page stored in that real memory location, with information about the process that owns that page \uf06eDecreases memory needed to store each page table, but increases time needed to search the table when a page reference occurs \uf06eUse hash table to limit the search to one \u2014 or at most a few \u2014 \uf06cOne mapping of a virtual address to the shared physical address \uf06eConsider modern, 64-bit operating system example with tightly \uf06cEach maps memory addresses from virtual to physical memory \uf06cEach entry represents a contiguous area of mapped virtual memory, \uf034More efficient than having a separate hash-table entry for each page \uf06cEach entry has  base address and  span (indicating the number of pages the entry represents) \uf06eTLB holds translation table entries (TTEs) for fast hardware lookups \uf06cA cache of TTEs reside in a translation storage buffer (TSB) \uf06cIf miss, hardware walks the in-memory TSB looking for the TTE \uf034If match found, the CPU copies the TSB entry into the TLB and translation completes \uf034If no match found, kernel interrupted to search the hash table \u2013The kernel then creates a TTE from the appropriate hash table and stores it in the TSB, Interrupt handler returns control to the MMU, which completes the address translation."
  },
  {
    "subject": "books",
    "text": "\uf06ePentium CPUs are 32-bit and called IA -32 architecture \uf06eCurrent Intel CPUs are 64-bit and called IA -64 architecture \uf06eMany variations in the chips, cover the main ideas here \uf06eSupports both segmentation and segmentation with paging \uf034First partition of up to 8 K segments are private to \uf034Second partition of up to 8K segments shared among all processes (kept in global descriptor table (GDT )) \uf06e 32-bit address limits led Intel to create page address extension (PAE), allowing 32- bit apps access to more than 4GB of memory space \uf06cTop two bits refer to a page directory pointer table \uf06cPage- directory and page- table entries moved to 64- bits in size \uf06cNet effect is increasing address space to 36 bits \u2013 64GB of physical \uf06e Can also use PAE so virtual addresses are 48 bits and physical (Apple iOS and Google Android devices for example) \uf06c Outer level has two micro TLBs (one data, one instruction) \uf06c First inner is checked, on miss outers are checked, and on miss page table walk performed by CPU Silberschatz, Galvin and Gagne \u00a92013 Operating System Concepts \u2013 9th Edition."
  },
  {
    "subject": "books",
    "text": "\u25aaIllustrate how deadlock can occur when mutex locks are used \u25aaDefine the four necessary conditions that characterize deadlock \u25aaIdentify a deadlock situation in a resource allocation graph \u25aaEvaluate the four different approaches for preventing deadlocks \u25aaApply the banker\u2019s algorithm for deadlock avoidance \u25aaA deadlock incomputer system may happen iftwoormore processes \u25aaExample one process waiting for a resource being held by another \u25aaIn OS when any process enters a waiting state because another waiting process is holding the demanded resource."
  },
  {
    "subject": "books",
    "text": "Deadlock is a common problem in multi -processing where several processes share a specific \u25aaA real -world example isatraffic, which is going only in one direction . \u25aaMutual exclusion :only one thread at a time can use a \u25aaHold and wait :a thread holding at least one resource is waiting to acquire additional resources held by other threads \u25aaNo preemption :a resource can be released only voluntarily by the thread holding it, after that thread has completed its \u25aaCircular wait :there exists a set { T0, T1, \u2026, Tn} of waiting threads such that T0  is waiting for a resource that is held by T1, T1is waiting for a resource that is held by T2, \u2026, Tn\u20131is waiting for a resource that is held by Tn, and Tnis waiting for a resource that is held by T0.Deadlock can arise if four conditions hold simultaneously."
  },
  {
    "subject": "books",
    "text": "\u2022Low resource utilization; starvation possibleInvalidate one of the four necessary conditions for deadlock: \u2022If a process that is holding some resources requests another resource that cannot be immediately allocated to it, then all \u2022Preempted resources are added to the list of resources for which \u2022Thread will be restarted only when it can regain its old resources, \u2022Impose a total ordering of all resource types, and require that each thread requests resources in an increasing order of enumeration \u25aaInvalidating the circular wait condition is most common."
  },
  {
    "subject": "books",
    "text": "\u25aaSimply assign each resource (i.e., mutex locks) a unique number. \u25aaSimplest and most useful model requires that each thread declare the maximum number of resources of each type that it may need \u25aaThe deadlock -avoidance algorithm dynamically examines the resource -allocation state to ensure that there can never be a \u25aaResource -allocation state is defined by the number of available and allocated resources, and the maximum demands of the processesRequires that the system has some additional a priori information \u25aaWhen a thread requests an available resource, system must decide if immediate allocation leaves the system in a safe state \u25aaSystem is in safe state if there exists a sequence < T1, T2, \u2026, Tn> of ALL the threads  in the systems such that  for each Ti, the resources that Tican still request can be satisfied by currently available resources + resources held by all the Tj, with j < I \u2022If Tiresource needs are not immediately available, then Tican \u2022When Tjis finished, Tican obtain needed resources, execute, \u2022When Titerminates, Ti+1can obtain its needed resources, and \u25aaIf a system is in unsafe state \uf0depossibility of deadlock \u25aaAvoidance \uf0deensure that a system will never enter an unsafe state."
  },
  {
    "subject": "books",
    "text": "\u25aaClaim edge Ti\u2192Rjindicated that process Tjmay request resource \u25aaClaim edge converts to request edge when a thread requests a \u25aaRequest edge converted to an assignment edge when the  resource \u25aaWhen a resource is released by a thread , assignment edge \u25aaThe request can be granted only if converting the request edge to an assignment edge does not result in the formation of a cycle in the \u25aaWhen a thread requests a resource, it may have to wait \u25aaWhen a thread gets all its resources it must return them in a finite \u25aaAvailable :Vector of length m."
  },
  {
    "subject": "books",
    "text": "If available [ j] = k, there are k \u25aaMax: n x m matrix.  If Max [i,j] = k, then process Timay request at \u25aaAllocation :  n xmmatrix.  If Allocation[ i,j] = kthen Tiis currently \u25aaNeed :  n xmmatrix. If Need [i,j] =k, then Timay need kmore Need [i,j]= Max[i,j] \u2013Allocation [i,j]Let n= number of processes, and m = number of resources types."
  },
  {
    "subject": "books",
    "text": "1.Let Work and Finish be vectors of length mandn, respectively. 4.If Finish [i] == true for all i, then the system is in a safe state Requesti= request vector for process Ti.  If Requesti[j] = kthen 1.If Requesti\uf0a3Needigo to step 2."
  },
  {
    "subject": "books",
    "text": "Otherwise, raise error condition, since process has exceeded its maximum claim 2.If Requesti\uf0a3Available , go to step 3.  Otherwise Timust wait, 3.Pretend to allocate requested resources to Tiby modifying the \u2022If unsafe \uf0deTimust wait, and the old resource -allocation state A(10 instances),  B(5instances), and C(7 instances) \u25aaThe content of the matrix Need is defined to be Max \u2013Allocation \u25aaThe system is in a safe state since the sequence < T1, T3, T4, T2, T0> \u25aaCheck that Request \uf0a3Available (that is, (1,0,2) \uf0a3(3,3,2) \uf0detrue \u25aaExecuting safety algorithm shows that sequence < T1, T3, T4, T0, T2> \u25aaPeriodically invoke an algorithm that searches for a cycle in the graph."
  },
  {
    "subject": "books",
    "text": "If Request [i][j] = k, then thread Tiis requesting kmore 1.Let Work and Finish be vectors of length mand n, respectively 4.If Finish[i] == false , for some i, 1 \uf0a3i\uf0a3n, then the system is in deadlock state. Moreover, if Finish [i] == false , then Tiis A (7 instances), B (2 instances), and C(6 instances) \u25aaSequence < T0, T2, T3, T1, T4> will result in Finish[i] = true for all i \u2022Can reclaim resources held by thread T0, but insufficient resources \u2022Deadlock exists, consisting of processes T1, T2, T3, and T4 \u25aaIf detection algorithm is invoked arbitrarily, there may be many cycles in the resource graph and so we would not be able to tell which of the \u25aaAbort one process at a time until the deadlock cycle is eliminated 2.How long has the thread computed, and how much longer to \u25aaRollback \u2013return to some safe state, restart the thread for \u25aaStarvation \u2013same thread may always be picked as victim, \u25aaDeadlock is a situation that occurs in OS when any process enters a waiting state because another waiting process is holding the demanded \u25aaCircular waiting happens when one process is waiting for the resource, which is held by the second process, which is also waiting for the \u25aaA deadlock occurrence can be detected by the resource scheduler ."
  },
  {
    "subject": "books",
    "text": "\u25aaA resource can be released only voluntarily by the process holding it \u25aaMutual Exclusion is a full form of Mutex. It is a special type of binary semaphore which used for controlling access to the shared resource . \u25aaDeadlock avoidance is the simplest and most useful model that each process declares the maximum number of resources of each type that it \u25aaThe deadlock -avoidance algorithm helps you to dynamically assess the resource -allocation state so that there can never be a circular -wait."
  },
  {
    "subject": "books",
    "text": "\u25aaAssess CPU scheduling algorithms based on scheduling criteria \u25aaExplain the issues related to multiprocessor and multicore scheduling \u25aaDescribe various real -time scheduling algorithms \u25aaDescribe the scheduling algorithms used in the Windows and Linux \u25aaCPU Scheduling is a process that allows one process to use the CPU while another process is delayed (in standby) due to unavailability of any resources such as I / O etc, thus making full use of the CPU."
  },
  {
    "subject": "books",
    "text": "The purpose of Processor Scheduling is to make the system more efficient , \u25aaCPU scheduling is a key part of how an operating system works. It decides which task (or process) the CPU should work on at any given time. This is important because a CPU can only handle one task at a time, but there are usually many tasks that need to be processed \u25aaWhenever the CPU becomes idle, the operating system must select one of the processes in the line ready for take -off."
  },
  {
    "subject": "books",
    "text": "The selection process is done by a temporary (CPU) scheduler. The Scheduler selects between memory processes ready to launch and assigns the \u25aaTheCPU scheduler selects from among the processes in ready \u25aaCPU scheduling decisions may take place when a process: \u25aaFor situations 1 and 4, there is no choice in terms of scheduling."
  },
  {
    "subject": "books",
    "text": "A new process (if one exists in the ready queue) must be selected \u25aaFor situations 2 and 3, however, there is  a choice. (preemptive) \u2022Consider interrupts occurring during crucial OS activities \u25aaWhen scheduling takes place only under circumstances 1 and \u25aaUnder Nonpreemptive scheduling, once the CPU has been allocated to a process, the process keeps the CPU until it releases it either by terminating or by switching to the waiting \u25aaVirtually all modern operating systems including Windows, \u25aaPreemptive scheduling can result in race conditions \u25aaConsider the case of two processes that share data."
  },
  {
    "subject": "books",
    "text": "While one process is updating the data, it is preempted so that the second process can run. The second process then tries to read the data, which are in an inconsistent \u25aaUtilization of CPU at maximum level. Keep CPU as busy as \u25aaThroughput should be Maximum ."
  },
  {
    "subject": "books",
    "text": "\u25aaTurn Around Time: Time Difference between completion time and \u25aaWaiting Time(W.T): Time Difference between turn around time and \u25aaDifferent CPU Scheduling algorithms have different structures and the choice of a particular algorithm depends on a variety of factors. Many conditions have been raised to compare CPU \u25aaCPU utilization \u2013The main purpose of CPU scheduling algorithm is to keep the CPU as busy as possible."
  },
  {
    "subject": "books",
    "text": "Theoretically CPU usage range from 0 -100, but in real time system is 40 - \u25aaThroughput \u2013# of processes that complete their execution per \u25aaTurnaround time \u2013amount of time to execute a particular \u25aaWaiting time \u2013amount of time a process has been waiting in \u25aaResponse time \u2013amount of time it takes from when a request was submitted until the first response is produced."
  },
  {
    "subject": "books",
    "text": "\u25aaSuppose that the processes arrive in the order: P1, P2, P3 \u2022Consider one CPU -bound and many I/O -bound processes \u25aaAssociate with each process the length of its next CPU burst \u2022Use these lengths to schedule the process with the \u25aaSJF is optimal \u2013gives minimum average waiting time for a \u25aaPreemptive version called shortest -remaining -time-first \u25aaWhenever a new process arrives in the ready queue, the decision on which process to schedule next is redone using \u25aaIs SRT more \u201coptimal\u201d than SJN in terms of the minimum \u25aaNow we add the concepts of varying arrival times and preemption to \u25aaEach process gets a small unit of CPU time ( time quantum q), usually 10 -100 milliseconds."
  },
  {
    "subject": "books",
    "text": "After this time has elapsed, the process is preempted and added to the end of the ready queue. \u25aaIf there are nprocesses in the ready queue and the time quantum is q, then each process gets 1/ nof the CPU time in chunks of at most qtime units at once."
  },
  {
    "subject": "books",
    "text": "No process waits more than ( n-1)q \u25aaTimer interrupts every quantum to schedule next process \u25aaNote that q must be large with respect to context switch, otherwise \u25aaTypically, higher average turnaround than SJF, but better response \u25aaq should be large compared to context switch time \u25aaA priority number (integer) is associated with each process \u25aaThe CPU is allocated to the process with the highest priority (smallest \u25aaSJF is priority scheduling where priority is the inverse of predicted next \u25aaProblem \uf0baStarvation \u2013low priority processes may never execute \u25aaSolution \uf0baAging \u2013as time progresses increase the priority of the \u25aaRun the process with the highest priority."
  },
  {
    "subject": "books",
    "text": "Processes with the same \u25aaHRRN is a non -preemptive CPU Scheduling algorithm and it is considered as one of the most optimal scheduling algorithms. The name itself states that we need to find the response ratio of all available processes and select the one with the highest Response Ratio."
  },
  {
    "subject": "books",
    "text": "A process once selected will run till completion \u25aaHRRN is considered as a modification for SJF to reduce the issue of starvation. During the HRRN scheduling algorithm, the CPU is allotted to the next process which has the highest response ratio and not to \u25aaResponse Ratio = (W + S)/S  ( Here, W is the waiting time of the process so far and S is the Burst time of the process)."
  },
  {
    "subject": "books",
    "text": "\u25aaSchedule the process in the highest -priority queue! \u25aaMultilevel -feedback -queue scheduler defined by the following \u2022Method used to determine when to upgrade a process \u2022Method used to determine when to demote a process \u2022Method used to determine which queue a process will enter \u25aaAging can be implemented using multilevel feedback queue \u25aaDistinction between user -level and kernel -level threads \u25aaWhen threads supported, threads scheduled, not processes \u25aaMany -to-one and many -to-many models, thread library schedules \u2022Known as process -contention scope (PCS)since scheduling \u25aaKernel thread scheduled onto available CPU is system -contention scope (SCS) \u2013competition among all threads in system \u25aaAPI allows specifying either PCS or SCS during thread creation \u2022PTHREAD_SCOPE_PROCESS schedules threads using PCS fprintf(stderr, \"Unable to get scheduling scope \\n\"); pthread_attr_setscope (&attr, PTHREAD_SCOPE_SYSTEM); /* Each thread will begin control in this function */ \u25aaCPU scheduling more complex when multiple CPUs are available \u25aaMulti_process may be any one of the following architectures: \u25aaSymmetric multiprocessing (SMP) is where each processor is self \u25aaRecent trend to place multiple processor cores on same physical chip \u2022Takes advantage of memory stall to make progress on another \u25aaIf one thread has a memory stall, switch to another thread! \u25aaIf symmetric multiprocessing (SMP), need to keep all CPUs \u25aaLoad balancing attempts to keep workload evenly distributed \u25aaPush migration \u2013periodic task checks load on each processor, and if found pushes task from overloaded CPU to other CPUs \u25aaPull migration \u2013idle processors pulls waiting task from busy Multiple -Processor Scheduling \u2013Processor Affinity \u25aaWhen a thread has been running on one processor, the cache contents of that processor stores the memory accesses by that thread."
  },
  {
    "subject": "books",
    "text": "\u25aaWe refer to this as a thread having affinity for a processor (i.e., \u25aaLoad balancing may affect processor affinity as a thread may be moved from one processor to another to balance loads, yet that thread loses the contents of what it had in the cache of the processor it was moved \u25aaSoft affinity \u2013the operating system attempts to keep a thread running \u25aaHard affinity \u2013allows a process to specify a set of processors it may If the operating system is NUMA -aware (non-uniform memory access), it will assign memory closes to the CPU the thread is running \u25aaSoft real -time systems \u2013Critical real -time tasks have the highest priority, but no guarantee as to when tasks will be scheduled \u25aaHard real -time systems \u2013task must be serviced by its deadline \u25aaFor real -time scheduling, scheduler must support preemptive, priority - \u25aaFor hard real -time must also provide ability to meet deadlines \u25aaProcesses have new characteristics: periodic ones require CPU at \u25aaA priority is assigned based on the inverse of its period \u25aaProcess P2misses finishing its deadline at time 80 \u2022The earlier the deadline, the higher the priority \u25aaAPI provides functions for managing real -time threads \u25aaDefines two scheduling classes for real -time threads: 1.SCHED_FIFO -threads are scheduled using a FCFS strategy with a FIFO queue."
  },
  {
    "subject": "books",
    "text": "There is no time -slicing for threads of equal priority 2.SCHED_RR -similar to SCHED_FIFO except time -slicing occurs \u25aaDefines two functions for getting and setting scheduling policy: if (pthread_attr_getschedpolicy (&attr, &policy) != 0) if (policy == SCHED_OTHER) printf(\"SCHED_OTHER \\n\"); else if (policy == SCHED_RR) printf(\"SCHED_RR \\n\"); else if (policy == SCHED_FIFO) printf(\"SCHED_FIFO \\n\"); /* set the scheduling policy -FIFO, RR, or OTHER */ if (pthread_attr_setschedpolicy (&attr, SCHED_FIFO) != 0) /* Each thread will begin control in this function */ \u2022Two priority ranges: time -sharing and real -time \u2022Real -time range from 0 to 99 and nice value from 100 to 140 \u2022Map into  global priority with numerically lower values indicating higher \u2022Task run -able as long as time left in time slice ( active ) \u2022If no time left ( expired ), not run -able until all other tasks use their slices \u2022All run -able tasks tracked in per -CPU runqueue data structure \u2022Worked well, but poor response times for interactive processes \u2022Scheduler picks highest priority task in highest scheduling class \u2022Rather than quantum based on fixed time allotments, based on \u2022Two scheduling classes included, others can be added \u25aaQuantum calculated based on nice value from -20 to +19 \u2022Calculates target latency \u2013interval of time during which task \u2022Target latency can increase if say number of active tasks \u25aaCFS scheduler maintains per task virtual run time in variable \u2022Associated with decay factor based on priority of task \u2013lower \u2022Normal default priority yields virtual run time = actual run time \u25aaTo decide next task to run, scheduler picks task with lowest virtual \u25aaReal-time plus normal map into global priority scheme \u25aaLinux supports load balancing, but is also NUMA -aware."
  },
  {
    "subject": "books",
    "text": "\u25aaScheduling domain is a set of CPU cores that can be balanced \u25aaDomains are organized by what they share (i.e., cache memory.) Goal is to keep threads from migrating between domains. \u25aaWindows uses priority -based preemptive scheduling \u25aaThread runs until (1) blocks, (2) uses time slice, (3) \u25aaWin32 API identifies several priority classes to which a process can \u25aaA thread within a given priority class has a relative priority \u25aaPriority class and relative priority combine to give numeric priority \u25aaIf quantum expires, priority lowered, but never below base \u25aaIf wait occurs, priority boosted depending on what was waited for \u2022Applications create and manage threads independent of kernel \u2022UMS schedulers come from programming language libraries like \u2022Takes a particular predetermined workload and defines the performance of each algorithm  for that workload \u25aaFor each algorithm, calculate minimum average waiting time \u25aaSimple and fast, but requires exact numbers for input, applies \u25aaDescribes the arrival of processes, and CPU and I/O bursts \u2022Computes average throughput, utilization, waiting time, etc."
  },
  {
    "subject": "books",
    "text": "\u25aaDescribe the general organization of a computer system and the role \u25aaDescribe the components in a modern, multiprocessor computer \u25aaIllustrate the transition from user mode to kernel mode \u25aaDiscuss how operating systems are used in various computing \u25aaProvide examples of free and open -source operating systems \u25aaA program that acts as an intermediary between a user of a \u2022Execute user programs and make solving user problems \u25aaComputer system can be divided into four components: \uf034Controls and coordinates use of hardware among various \u2022Application programs \u2013define the ways in which the system resources are used to solve the computing problems of the users \uf034Word processors, compilers, web browsers, database systems, \u25aaUsers want convenience, ease of use andgood performance \u25aaBut shared computer such as mainframe or minicomputer must keep \u2022Operating system is a resource allocator and control program making efficient use of HW and managing execution of user \u25aaUsers of dedicate systems such as workstations have dedicated resources but frequently use shared resources from servers \u25aaMobile devices like smartphones and tables are resource poor, \u2022Mobile user interfaces such as touch screens, voice recognition \u25aaSome computers have little or no user interface, such as embedded \u25aa\u201cThe one program running at all times on the computer \u201dis the kernel, \u2022A system program (ships with the operating system, but not part of \u2022An application program , all programs not associated with the \u25aaToday\u2019s OSes for general purpose and mobile computing also include middleware \u2013a set of software frameworks that provide additional services to application developers such as databases, multimedia, \u2022One or more CPUs, device controllers connect through common \u2022Concurrent execution of CPUs and devices competing for memory \u25aaEach device controller is in charge of a particular device type \u25aaEach device controller type has an operating system device driver \u25aaCPU moves data from/to main memory to/from local buffers \u25aaI/O is from the device to local buffer of controller \u25aaDevice controller informs CPU that it has finished its operation by \u25aaInterrupt transfers control to the interrupt service routine generally, through the interrupt vector , which contains the \u25aaInterrupt architecture must save the address of the interrupted \u25aaA trap or exception is a software -generated interrupt caused \u25aaThe operating system preserves the state of the CPU by \u25aaSeparate segments of code determine what action should \u2022After I/O starts, control returns to user program only \u2022After I/O starts, control returns to user program without \u25aaAfter I/O starts, control returns to user program only upon I/O \u2022Wait instruction idles the CPU until the next interrupt \u2022At most one I/O request is outstanding at a time, no \u25aaAfter I/O starts, control returns to user program without waiting for \u2022System call \u2013request to the OS to allow user to wait for I/O \u2022Device -status table contains entry for each I/O device \u2022OS indexes into I/O device table to determine device status \u25aaMain memory \u2013only large storage media that the CPU can \u25aaSecondary storage \u2013extension of main memory that provides \u25aaHard Disk Drives (HDD ) \u2013rigid metal or glass platters covered \u2022Disk surface is logically divided into tracks , which are subdivided \u2022The disk controller determines the logical interaction between \u25aaNon-volatile memory (NVM )devices \u2013faster than hard disks, \u2022Becoming more popular as capacity and performance increases, The basic unit of computer storage is the bit."
  },
  {
    "subject": "books",
    "text": "A bit can contain one of two values, 0 and 1. All other storage in a computer is based on collections of bits. Given enough bits, it is amazing how many things a computer can represent: numbers, letters, images, movies, sounds, documents, and programs, to name a few."
  },
  {
    "subject": "books",
    "text": "A byteis 8 bits, and on most computers it is the smallest convenient chunk of storage. For example, most computers don\u2019t have an instruction to move a bit but do have one to move a byte. A less common term is word, which is a given computer architecture\u2019s native unit of data."
  },
  {
    "subject": "books",
    "text": "A word is made up of one or more bytes. For example, a computer that has 64 -bit registers and 64-bit memory addressing typically has 64 -bit (8 -byte) words. A computer executes many operations in its native word size rather than a byte at a time."
  },
  {
    "subject": "books",
    "text": "Computer storage, along with most computer throughput, is generally measured and manipulated in bytes and collections of bytes. A kilobyte , or KB , is 1,024 bytes; a megabyte , or MB, is 1,0242bytes; a gigabyte , or GB, is 1,0243bytes; a terabyte , or TB, is 1,0244bytes; and a petabyte , or PB, is 1,0245 bytes."
  },
  {
    "subject": "books",
    "text": "Computer manufacturers often round off these numbers and say that a megabyte is 1 million bytes and a gigabyte is 1 billion bytes. Networking measurements are an exception to this general rule; they are given in bits \u25aaCaching \u2013copying information into faster storage system; main memory can be viewed as a cache for secondary storage \u25aaDevice Driver for each device controller to manage I/O \u2022Provides uniform interface between controller and kernel \u25aaUsed for high -speed I/O devices able to transmit information \u25aaDevice controller transfers blocks of data from buffer storage \u25aaOnly one interrupt is generated per block, rather than the one \u25aaBootstrap program \u2013simple code to initialize the system, load the \u25aaStarts system daemons (services provided outside of the kernel) \uf034Request for operating system service \u2013system call \uf034Other process problems include infinite loop, processes \u25aaSingle user cannot always keep CPU and I/O devices busy \u25aaMultiprogramming organizes jobs (code and data) so CPU \u25aaA subset of total jobs in system is kept in memory \u25aaWhen job has to wait (for I/O for example), OS switches to \u25aaA logical extension of Batch systems \u2013the CPU switches jobs so frequently that users can interact with each job while it is \u2022Each user has at least one program executing in memory \u2022If several jobs ready to run at the same time \uf05bCPU \u2022If processes don \u2019t fit in memory, swapping moves them \u25aaDual -mode operation allows OS to protect itself and other \u2022Provides ability to distinguish when system is running user \u2022When kernel code is executing \uf05bmode bit is \u201ckernel\u201d \u25aaHow do we guarantee that user does not explicitly set the mode \u2022System call changes mode to kernel, return from call resets \u25aaSome instructions designated as privileged , only executable in \u25aaTimer to prevent infinite loop (or process hogging resources) \u2022Timer is set to interrupt the computer after some time period \u2022Keep a counter that is decremented by the physical clock \u2022Operating system set the counter (privileged instruction) \u2022Set up before scheduling process to regain control or terminate \u25aaA process is a program in execution."
  },
  {
    "subject": "books",
    "text": "It is a unit of work within the system. Program is a passive entity; process is an active entity . \u25aaProcess termination requires reclaim of any reusable resources \u25aaSingle -threaded process has one program counter specifying location \u2022Process executes instructions sequentially, one at a time, until \u25aaMulti -threaded process has one program counter per thread \u25aaTypically system has many processes, some user, some operating \u2022Concurrency by multiplexing the CPUs among the processes / \u25aaCreating and deleting both user and system processes \u25aaProviding mechanisms for deadlock handlingThe operating system is responsible for the following activities in \u25aaTo execute a program all (or part) of the instructions must be in \u25aaAll  (or part) of the data that is needed by the program must be in \u25aaMemory management determines what is in memory and when \u2022Optimizing CPU utilization and computer response to users \u2022Keeping track of which parts of memory are currently being used \u2022Deciding which processes (or parts thereof) and data to move into \u2022Allocating and deallocating memory space as needed \u25aaOS provides uniform, logical view of information storage \u2022Abstracts physical properties to logical storage unit  -file \u2022Each medium is controlled by device (i.e., disk drive, tape drive) \uf034Varying properties include access speed, capacity, data - transfer rate, access method (sequential or random) \u2022Access control on most systems to determine who can access \uf034Backup files onto stable (non -volatile) storage media \u25aaUsually disks used to store data that does not fit in main memory or data that must be kept for a \u201clong\u201dperiod of time \u25aaEntire speed of computer operation hinges on disk subsystem \u25aaImportant principle, performed at many levels in a computer \u25aaInformation in use copied from slower to faster storage \u25aaFaster storage (cache) checked first to determine if \u2022If it is, information used directly from the cache (fast) Movement between levels of storage hierarchy can be explicit or implicit \u25aaMultitasking environments must be careful to use most recent value, no matter where it is stored in the storage hierarchy \u25aaMultiprocessor environment must provide cache coherency in hardware such that all CPUs have the most recent value in their \u25aaDistributed environment situation even more complex \u25aaOne purpose of OS is to hide peculiarities of hardware devices from \u2022Memory management of I/O including buffering (storing data temporarily while it is being transferred), caching (storing parts of data in faster storage for performance), spooling (the overlapping \u25aaProtection \u2013any mechanism for controlling access of processes or \u25aaSecurity \u2013defense of the system against internal and external attacks \u2022Huge range, including denial -of-service, worms, viruses, identity \u25aaSystems generally first distinguish among users, to determine who \u2022User identities ( user IDs , security IDs) include name and \u2022User ID then associated with all files, processes of that user to \u2022Group identifier ( group ID ) allows set of users to be defined and controls managed, then also associated with each process, file \u2022Privilege escalation allows user to change to effective ID with \u25aaAllows operating systems to run applications within other OSes \u25aaEmulation used when source CPU type different from target type (i.e."
  },
  {
    "subject": "books",
    "text": "\u2022When computer language not compiled to native code \u2013 \u25aaVirtualization \u2013OS natively compiled for CPU, running guest OSes \u2022Consider VMware running WinXP guests, each running \u2022VMM (virtual machine Manager) provides virtualization services \u25aaUse cases involve laptops and desktops running multiple OSes for \u2022Apple laptop running Mac OS X host, Windows as a guest \u2022Developing apps for multiple OSes without having multiple \u2022Quality assurance testing applications without having multiple \u2022Executing and managing compute environments within data \u25aaVMM can run natively, in which case they are also the host \u2022There is no general -purpose host then (VMware ESX and Citrix \u25aaCollection of separate, possibly heterogeneous, systems networked \u2022Network is a communications path, TCP/IP most common \u25aaNetwork Operating System provides features between systems \u2022Communication scheme allows systems to exchange messages \u25aaMost systems use a single general -purpose processor \u2022Most systems have special -purpose processors as well \u25aaMultiprocessors systems growing in use and importance \u2022Also known as parallel systems , tightly -coupled systems 3.Increased reliability \u2013graceful degradation or fault tolerance 1.Asymmetric Multiprocessing \u2013each processor is assigned 2.Symmetric Multiprocessing \u2013each processor performs all \u25aaLike multiprocessor systems, but multiple systems working together \u2022Usually sharing storage via a storage -area network (SAN ) \u2022Provides a high -availability service which survives failures \uf034Asymmetric clustering has one machine in hot -standby mode \uf034Symmetric clustering has multiple nodes running applications, \u2022Some clusters are for high -performance computing (HPC ) \uf034Applications must be written to use parallelization \u2022Some have distributed lock manager (DLM ) to avoid conflicting \u25aaBut blurred as most systems interconnect with others (i.e., \u25aaNetwork computers (thin clients ) are like Web terminals \u25aaMobile computers interconnect via wireless networks \u25aaNetworking becoming ubiquitous \u2013even home systems use firewalls to protect home computers from Internet \u25aaWhat is the functional difference between them and a \u2022Many systems now servers , responding to requests generated by \uf034Compute -server system provides an interface to client to \uf034File-server system provides interface for clients to store and \u25aaDelivers computing, storage, even apps as a service \u25aaLogical extension of virtualization because it uses \u2022Public cloud \u2013available via Internet to anyone willing to pay \u2022Private cloud \u2013run by a company for the company\u2019s own use \u2022Hybrid cloud \u2013includes both public and private cloud components \u2022Software as a Service ( SaaS ) \u2013one or more applications available \u2022Platform as a Service ( PaaS ) \u2013software stack ready for application \u2022Infrastructure as a Service ( IaaS) \u2013servers or storage available over Internet (i.e., storage available for backup use) \u25aaCloud computing environments composed of traditional OSes, plus \u2022Internet connectivity requires security like firewalls \u2022Load balancers spread traffic across multiple applications \u25aaReal-time embedded systems most prevalent form of computers \u2022Vary considerable, special purpose, limited purpose OS,  real- \u25aaMany other special computing environments as well \u25aaReal-time OS has well -defined fixed time constraints \u25aaOperating systems made available in source -code format rather than \u25aaCounter to the copy protection and Digital Rights Management \u25aaStarted by Free Software Foundation (FSF), which has \u201ccopyleft\u201d \u2022Free software and open -source software are two different ideas \u25aaExamples include GNU/Linux and BSD UNIX (including core of Mac \u25aaCan use VMM like VMware Player (Free on Windows), Virtualbox \u2022Use to run guest operating systems for exploration There has never been a more interesting time to study operating systems, and it has never been easier."
  },
  {
    "subject": "books",
    "text": "Operating systems that are no longer commercially viable have been open -sourced as well, enabling us to study how systems operated in a time of fewer CPU, memory, and storage resources. An extensive but incomplete list of open -source operating -system projects is available from https://curlie.org/Computers/Software/Operating_Systems/Open_Source/ In addition, the rise of virtualization as a mainstream (and frequently free) computer function makes it possible to run many operating systems on top of one core system."
  },
  {
    "subject": "books",
    "text": "With some knowledge, some effort, and an Internet connection, a student can even create a new operating -system distribution. Just a few years ago, it was difficult or impossible to get access to source code. Now, such access is limited only by how much interest, time, and disk space a student has.."
  },
  {
    "subject": "books",
    "text": "\u25aaIdentify the separate components of a process and illustrate how they are represented and scheduled in an operating system. \u25aaDescribe how processes are created and terminated in an operating system, including developing programs using the appropriate system \u25aaDescribe and contrast interprocess communication using shared \u25aaDesign programs that uses pipes and POSIX shared memory to \u25aaDescribe client -server communication using sockets and remote \u25aaAn operating system executes a variety of programs that run as a \u25aaProcess \u2013a program in execution; process execution must progress in sequential fashion."
  },
  {
    "subject": "books",
    "text": "No parallel execution of instructions of a  single \u2022Current activity including program counter , processor registers \uf034Function parameters, return addresses, local variables \u2022Heap containing memory dynamically allocated during run time \u25aaProgram is passive entity stored on disk ( executable file); \u2022Program becomes process when an executable file is \u25aaExecution of program started via GUI mouse clicks, command \u2022Consider multiple users executing the same program \u25aaFormally, You can define a process is an executing program, including the current values of the program counter, registers, and variables."
  },
  {
    "subject": "books",
    "text": "The refined difference between a process and a program is that the program is a group of instructions whereas \u2022Waiting :  The process is waiting for some event to occur \u2022Ready :  The process is waiting to be assigned to a processor \u25aaCPU scheduling information -priorities, scheduling Information associated with each process(also called task unsigned int time_slice /* scheduling information */ struct task_struct *parent;/* this process \u2019s parent */ struct list_head children; /* this process \u2019s children */ struct files_struct *files;/* list of open files */ \u25aaProcess scheduler selects among available processes \u25aaGoal --Maximize CPU use, quickly switch processes onto \u2022Ready queue \u2013set of all processes residing in main \u2022Wait queues \u2013set of processes waiting for an event A context switch occurs when the CPU  switches from \u25aaWhen CPU switches to another process, the system must save thestate of the old process and load the saved state \u25aaContext -switch time is pure overhead; the system does no \u2022Some hardware provides multiple sets of registers per \u25aaSome mobile systems (e.g., early version of iOS)  allow only one \u25aaDue to screen real estate, user interface limits iOS provides for a \u2022Single foreground process -controlled via user interface \u2022Multiple background processes \u2013in memory, running, but not \u2022Limits include single, short task, receiving notification of events, \u25aaAndroid runs foreground and background, with fewer limits \u2022Background process uses a service to perform tasks \u2022Service can keep running even if background process is \u25aaParent process create children processes, which, in turn create other processes, forming a tree of processes \u25aaGenerally, process identified and managed via a process \u2022exec() system call used after a fork() to replace the process \u2019 \u2022Parent process calls wait() waiting for the child to terminate \u25aaProcess executes last statement and then asks the operating \u2022Returns  status data from child to parent (via wait() ) \u2022Process\u2019resources are deallocated by operating system \u25aaParent may terminate the execution of children processes  using the abort() system call."
  },
  {
    "subject": "books",
    "text": "Some reasons for doing so: \u2022The parent is exiting, and the operating systems does not allow  a child to continue if its parent terminates \u25aaSome operating systems do not allow child to exists if its parent has terminated.  If a process terminates, then all its children \u2022cascading termination."
  },
  {
    "subject": "books",
    "text": "All children, grandchildren, etc., \u2022The termination is initiated by the operating system. \u25aaThe parent process may wait for termination of a child process by using the wait() system call . The call returns status \u25aaIf no parent waiting (did not invoke wait() ) process is a \u25aaIf parent terminated without invoking wait() , process is an \u25aaMobile operating systems often have to terminate processes to reclaim system resources such as memory."
  },
  {
    "subject": "books",
    "text": "From most to least important: \u25aaAndroid will begin terminating processes that are least important. \u25aaMany web browsers ran as single process (some still do) \u2022If one web site causes trouble, entire browser can hang or crash \u25aaGoogle Chrome Browser is multiprocess with 3 different types of \u2022Browser process manages user interface, disk and network I/O \u2022Renderer process renders web pages, deals with HTML, Javascript ."
  },
  {
    "subject": "books",
    "text": "A new renderer created for each website opened \uf034Runs in sandbox restricting disk and network I/O, minimizing \u25aaProcesses within a system may be independent or cooperating \u25aaCooperating process can affect or be affected by other processes, \u25aaCooperating processes need interprocess communication (IPC) \u2022producer process produces information that is consumed \u2022unbounded -buffer places no practical limit on the size of \u2022bounded -buffer assumes that there is a fixed buffer size \u25aaAn area of memory shared among the processes that wish to \u25aaThe communication is under the control of the users processes \u25aaMajor issues is to provide mechanism that will allow the user processes to synchronize their actions when they access shared \u25aaIf processes Pand Qwish to communicate, they need to: \u2022How many links can there be between every pair of \u2022Is the size of a message that the link can accommodate \u2022receive (Q, message ) \u2013receive a message from process Q \u2022A link is associated with exactly one pair of communicating \u2022The link may be unidirectional, but is usually bi -directional \u25aaMessages are directed and received from mailboxes (also referred \u2022Processes can communicate only if they share a mailbox \u2022Link established only if processes share a common mailbox \u2022Each pair of processes may share several communication links \u2022receive (A, message ) \u2013receive a message from mailbox AIndirect Communication (Cont.) \u2022Allow a link to be associated with at most two processes \u2022Allow only one process at a time to execute a receive \u2022Allow the system to select arbitrarily the receiver."
  },
  {
    "subject": "books",
    "text": "Sender is notified who the receiver was.Indirect Communication (Cont.) \u2022Blocking send --the sender is blocked until the message is \u2022Blocking receive --the receiver is  blocked until a message is \u2022Non-blocking send --the sender sends the message and \u2022If both send and receive are blocking, we have a rendezvousMessage passing may be either blocking or non -blocking 1.Zero capacity \u2013no messages are queued on a link."
  },
  {
    "subject": "books",
    "text": "\u2022Use mmap() to memory -map a file pointer to the shared memory \u2022Reading and writing to shared memory is done by using the \u25aaMessage -passing centric via advanced local procedure call \u2022Uses ports (like mailboxes) to establish and maintain \uf034The server creates two private communication ports and returns the handle to one of them to the client."
  },
  {
    "subject": "books",
    "text": "Typically, a parent process creates a pipe and uses it to \u25aaNamed pipes \u2013can be accessed without a parent -child relationship. \u25aaOrdinary Pipes allow communication in standard producer -consumer \u25aaProducer writes to one end (the write -endof the pipe) \u25aaConsumer reads from the other end (the read -endof the pipe) \u25aaRequire parent -child relationship between communicating processes \u25aaNamed Pipes are more powerful than ordinary pipes \u25aaNo parent -child relationship is necessary between the communicating \u25aaSeveral processes can use the named pipe for communication \u25aaA socket is defined as an endpoint for communication \u25aaConcatenation of IP address and port \u2013a number included at start of message packet to differentiate network services on a host \u25aaAll ports below 1024 are well known , used for standard services \u25aaRemote procedure call (RPC) abstracts procedure calls between \u25aaStubs \u2013client -side proxy for the actual procedure on the server \u25aaThe client -side stub locates the server and marshalls the parameters \u25aaThe server -side stub receives this message, unpacks the marshalled parameters, and performs the procedure on the server \u25aaOn Windows, stub code compile from specification written in \u25aaData representation handled via External Data Representation (XDL) format to account for different architectures \u25aaRemote communication has more failure scenarios than local \u2022Messages can be delivered exactly once rather than at most \u25aaOS typically provides a engagements (or matchmaker ) service to."
  },
  {
    "subject": "books",
    "text": "\u25aaIdentify services provided by an operating system \u25aaIllustrate how system calls are used to provide operating \u25aaCompare and contrast monolithic, layered, microkernel, modular, and hybrid strategies for designing operating \u25aaIllustrate the process for booting an operating system \u25aaApply tools for monitoring operating system performance \u25aaDesign and implement kernel modules for interacting with a \u25aaOperating systems provide an environment for execution of programs \u25aaOne set of operating -system services provides functions that are \u2022User interface -Almost all operating systems have a user \uf034Varies between Command -Line (CLI), Graphics User \u2022Program execution -The system must be able to load a program into memory and to run that program, end execution, either \u2022I/O operations -A running program may require I/O, which may \u2022File-system manipulation -The file system is of particular interest."
  },
  {
    "subject": "books",
    "text": "Programs need to read and write files and directories, create and delete them, search them, list file Information, \u25aaOne set of operating -system services provides functions that are \u2022Communications \u2013Processes may exchange information, on the \uf034Communications may be via shared memory or through \u2022Error detection \u2013OS needs to be constantly aware of possible \uf034May occur in the CPU and memory hardware, in I/O devices, in \uf034For each type of error, OS should take the appropriate action \uf034Debugging facilities can greatly enhance the user \u2019s and programmer \u2019s abilities to efficiently use the system \u25aaAnother set of OS functions exists for ensuring the efficient operation \u2022Resource allocation -When  multiple users or multiple jobs running concurrently, resources must be allocated to each of them \uf034Many types of resources -CPU cycles, main memory, file \u2022Logging -To keep track of which users use how much and what \u2022Protection and security -The owners of information stored in a multiuser or networked computer system may want to control use of that information, concurrent processes should not interfere with \uf034Protection involves ensuring that all access to system \uf034Security of the system from outsiders requires user authentication, extends to defending external I/O devices from \u2022Various mouse buttons over objects in the interface cause various actions (provide information, options, execute function, open \u25aaMany systems now include both CLI and GUI interfaces \u2022Microsoft Windows is GUI with CLI \u201ccommand \u201dshell \u2022Apple Mac OS X is \u201cAqua\u201dGUI interface with UNIX kernel \u2022Unix and Linux have CLI with optional GUI interfaces (CDE, KDE, \u25aaProgramming interface to the services provided by the OS \u25aaTypically written in a high -level language (C or C++) \u25aaMostly accessed by programs via a high -level Application Programming Interface (API)rather than direct system call use \u25aaThree most common APIs are Win32 API for Windows, POSIX API for POSIX -based systems (including virtually all versions of UNIX, Linux, and Mac OS X), and Java API for the Java virtual machine (JVM) Note that the system -call names used throughout this text are \u25aaSystem call sequence to copy the contents of one file to another file \u25aaTypically, a number is  associated with each system call \u2022System -callinterface maintains a table indexed according to \u25aaThe system call interface invokes  the intended system call in OS kernel and returns status of the system call and any return values \u25aaThe caller need know nothing about how the system call is \u2022Just needs to obey API and understand what OS will do as a \u2022Most details of  OS interface hidden from programmer by API \uf034Managed by run -time support library (set of functions built into \u25aaOften, more information is required than simply identity of desired \u2022Exact type and amount of information vary according to OS and \u25aaThree general methods used to pass parameters to the OS \uf034In some cases, may be more parameters than registers \u2022Parameters stored in a block , or table, in memory, and address of \u2022Parameters placed, or pushed , onto the stack by the program and \u2022Block and stack methods do not limit the number or length of \u2022Debugger for determining bugs , single step execution \u2022Locks for managing access to shared data between processes \u2022logically attach or detach devicesTypes of System Calls (Cont.) \u2022send, receive messages if message passing model to host \u2022Shared -memory model create and gain access to memory \u25aaC program invoking printf() library call, which calls write() system call \u25aaSystem programs provide a convenient environment for program development and execution."
  },
  {
    "subject": "books",
    "text": "They can be divided into: \u25aaMost users \u2019view of the operating system is defined by system \u25aaProvide a convenient environment for program development and \u2022Some of them are simply user interfaces to system calls; others \u25aaFile management -Create, delete, copy, rename, print, dump, list, \u2022Some ask the system for info -date, time, amount of available \u2022Others provide detailed performance, logging, and debugging \u2022Typically, these programs format and print the output to the \u2022Some systems implement  a registry -used to store and \u2022Special commands to search contents of files or perform \u25aaProgramming -language support -Compilers, assemblers, \u25aaProgram loading and execution -Absolute loaders, relocatable loaders, linkage editors, and overlay -loaders, debugging systems for \u25aaCommunications -Provide the mechanism for creating virtual connections among processes, users, and computer systems \u2022Allow users to send messages to one another \u2019s screens, browse web pages, send electronic -mail messages, log in remotely, \u2022Provide facilities like disk checking, process scheduling, error \u2022Launched by command line, mouse click, finger poke \u25aaApps compiled on one system usually not executable on other \u25aaEach operating system provides its own unique system calls \u2022Written in interpreted language like Python, Ruby, and interpreter \u2022App written in language that includes a VM containing the running \u2022Use standard language (like C), compile separately on each \u25aaApplication Binary Interface (ABI) is architecture equivalent of API, defines how different components of binary code can interface for a given operating system on a given architecture, CPU, etc."
  },
  {
    "subject": "books",
    "text": "\u25aaDesign and Implementation of OS is not \u201csolvable\u201d, but some \u25aaInternal structure of different Operating Systems  can vary widely \u25aaStart the design by defining goals and specifications \u2022User goals \u2013operating system should be convenient to use, \u2022System goals \u2013operating system should be easy to design, implement, and maintain, as well as flexible, reliable, error -free, \u25aaSpecifying and designing an OS is highly creative task of software \u25aaImportant principle: separate policy from mechanism \u25aaThe separation of policy from mechanism is a very important principle, it allows maximum flexibility if policy \u2022Then system programming languages like Algol, PL/1 \u2022Systems programs in C, C++, scripting languages like PERL, \u25aaMore high -level language easier to port to other hardware \u25aaEmulation can allow an OS to run on non -native hardware \u25aaUNIX \u2013limited by hardware functionality, the original UNIX operating \uf034Consists of everything below the system -call interface and management, and other operating -system functions; a large \u25aaCommunication takes place between user modules using \u2022Easier to port the operating system to new architectures \u2022More reliable (less code is running in kernel mode) \u2022Performance overhead of user space to kernel space \u25aaMany modern operating systems implement loadable kernel \u25aaOverall, similar to layers but with more flexible \u25aaMost modern operating systems are not one pure model \u2022Hybrid combines multiple approaches to address performance, \u2022Linux and Solaris kernels in kernel address space, so monolithic, \u2022Windows mostly monolithic, plus microkernel for different \u25aaApple Mac OS X hybrid, layered, Aqua UI plus Cocoa programming \u2022Below is kernel consisting of Mach microkernel and BSD Unix parts, plus I/O kit and dynamically loadable modules (called \u25aaDeveloped by Open Handset Alliance (mostly Google) \u2022Provides process, memory, device -driver management \u25aaRuntime environment includes core set of libraries and Dalvik \uf034Java class files compiled to Java bytecode then translated \u25aaLibraries include frameworks for web browser ( webkit ), database \u25aaOperating systems generally designed to run on a class of systems \u25aaCommonly, operating system already installed on purchased \u2022But can build and install some other operating systems \uf034Configure the operating system for the system on which it will \u2022Install new kernel on the system via \u201c make install \u201d \u25aaWhen power initialized on system, execution starts at a fixed memory \u25aaOperating system must be made available to hardware so hardware \u2022Small piece of code \u2013bootstrap loader , BIOS , stored in ROM or EEPROM locates the kernel, loads it into memory, and starts it \u2022Sometimes two -step process where boot block at fixed location loaded by ROM code, which loads bootstrap loader from disk \u2022Modern systems replace BIOS with Unified Extensible \u25aaCommon bootstrap loader, GRUB , allows selection of kernel from \u25aaBoot loaders frequently allow various boot states, such as single user \u25aaOS generate logfiles containing error information \u25aaFailure of an application can generate core dump file capturing \u25aaOperating system failure can generate crash dump file containing \u25aaBeyond crashes, performance tuning can optimize system performance \u2022Sometimes using trace listings of activities, recorded for analysis \u2022Profiling is periodic sampling of instruction pointer to look for Kernighan \u2019s Law: \u201cDebugging is twice as hard as writing the code in the first place."
  },
  {
    "subject": "books",
    "text": "Therefore, if you write the code as cleverly as possible, you are, \u25aaOS must provide means of computing and displaying measures of \u25aaFor example, \u201ctop\u201d program or Windows Task Manager \u25aaCollects data for a specific event, such as steps involved \u25aaDebugging interactions between user -level and kernel code nearly impossible without toolset that understands both and an instrument \u25aaBCC (BPF Compiler Collection) is a rich toolkit providing tracing \u25aaFor example, disksnoop.py traces disk I/O activity."
  },
  {
    "subject": "books",
    "text": "Silberschatz, Galvin and Gagne \u00a92013 Operating System Concepts \u2013 9th Edition \uf06eTo introduce CPU scheduling, which is the basis for \uf06eTo discuss evaluation criteria for selecting a CPU -scheduling \uf06eTo examine the scheduling algorithms of several operating systems \uf06eShort -term scheduler selects from among the processes in \uf06eCPU scheduling decisions may take place when a process: \uf06cConsider interrupts occurring during crucial OS activities \uf06eDispatcher module gives control of the CPU to the process selected by the short -term scheduler; this involves: \uf06cjumping to the proper location in the user program to restart that program \uf06eDispatch latency \u2013 time it takes for the dispatcher to stop \uf06eCPU utilization \u2013 keep the CPU as busy as possible \uf06eThroughput  \u2013 # of processes that complete their execution per \uf06eTurnaround time \u2013 amount of time to execute a particular \uf06eWaiting time \u2013 amount of time a process has been waiting in the \uf06eResponse time \u2013 amount of time it takes from when a request was submitted until the first response is produced, not output  (for \uf06eSuppose that the processes arrive in the order: P1 , P2 , P3 \uf06eAverage waiting time:  (0 + 24 + 27)/3 = 17 P P P1 2 3 \uf06eConvoy effect - short process behind long process \uf06cConsider one CPU -bound and many I/O -bound processes  P1 \uf06eAssociate with each process the length of its next CPU burst \uf06c Use these lengths to schedule the process with the shortest \uf06eSJF is optimal \u2013 gives minimum average waiting time for a given \uf06cThe difficulty is knowing the length of the next CPU request \uf06eAverage waiting time = (3 + 16 + 9 + 0) / 4 = 7 P3 \uf06eCan only estimate the length \u2013 should be similar to the previous one \uf06cThen pick process with shortest predicted next CPU burst \uf06eCan be done by using the length of previous CPU bursts, using \uf06ePreemptive version called shortest -remaining -time -first \uf06eSince both \u03b1  and (1 - \u03b1) are less than or equal to 1, each successive term has less weight than its predecessor \uf06eNow we add the concepts of varying arrival times and preemption to \uf06eA priority number (integer) is associated with each process \uf06eThe CPU is allocated to the process with the highest priority \uf06eSJF is priority scheduling where priority is the inverse of predicted next CPU burst time \uf06eProblem \u2261 Starvation  \u2013 low priority processes may never execute \uf06eSolution \u2261 Aging  \u2013 as time progresses increase the priority of the \uf06eEach process gets a small unit of CPU time ( time quantum  q), usually 10-100 milliseconds."
  },
  {
    "subject": "books",
    "text": "After this time has elapsed, the process is preempted and added to the end of the ready queue. \uf06eIf there are n processes in the ready queue and the time quantum is q , then each process gets 1/ n of the CPU time in chunks of at most q  time units at once."
  },
  {
    "subject": "books",
    "text": "No process waits more \uf06eTimer interrupts every quantum to schedule next process \uf06cq small \u21d2 q must be large with respect to context switch, \uf06eTypically, higher average turnaround than SJF, but better response \uf06eq should be large compared to context switch time \uf06eq usually 10ms to 100ms, context switch < 10 usec  P P P1 1 1 \uf06eReady queue is partitioned into separate queues, eg: \uf06cFixed priority scheduling; (i.e., serve all from foreground then \uf06cTime slice \u2013 each queue gets a certain amount of CPU time which it can schedule amongst its processes; i.e., 80% to foreground in RR \uf06eA process can move between the various queues; aging can be \uf06eMultilevel -feedback -queue scheduler defined by the following \uf06cmethod used to determine when to upgrade a process \uf06cmethod used to determine when to demote a process \uf06cmethod used to determine which queue a process will enter when that process needs service \uf034If it does not finish in 8 milliseconds, job is moved to queue Q \uf034If it still does not complete, it is preempted and moved to queue Q \uf06eDistinction between user -level and kernel -level threads \uf06eWhen threads supported, threads scheduled, not processes \uf06eMany -to-one and many -to-many models, thread library schedules \uf06cKnown as process-contention scope (PCS ) since scheduling \uf06eKernel thread scheduled onto available CPU is system -contention scope (SCS ) \u2013 competition among all threads in system \uf06eAPI allows specifying either PCS or SCS during thread creation \uf06cPTHREAD_SCOPE_SYSTEM schedules threads using SCS scheduling \uf06eCan be limited by OS \u2013 Linux and Mac OS X only allow fprintf(stderr, \"Unable to get scheduling scope \\n\"); pthread_attr_setscope(&attr, PTHREAD_SCOPE_SYSTEM); /* Each thread will begin control in this function */ \uf06eCPU scheduling more complex when multiple CPUs are \uf06eAsymmetric multiprocessing \u2013 only one processor accesses the system data structures, alleviating the need for data sharing \uf06eSymmetric multiprocessing (SMP) \u2013 each processor is self - scheduling, all processes in common ready queue, or each has its own private queue of ready processes \uf06eProcessor affinity \u2013  process has affinity for processor on which Note that memory -placement algorithms can also consider affinity \uf06eIf SMP, need to keep all CPUs loaded for efficiency \uf06eLoad balancing attempts to keep workload evenly distributed \uf06ePush migration \u2013 periodic task checks load on each processor, and if found pushes task from overloaded CPU to other CPUs \uf06ePull migration \u2013 idle processors pulls waiting task from busy \uf06eRecent trend to place multiple processor cores on same \uf06cTakes advantage of memory stall to make progress on another thread while memory retrieve happens guarantee as to when critical real-time process will be schedule to take current process off CPU and switch to another 1.Preemption of any process running in kernel mode priority process of resources needed by high-priority processes \uf06eFor real -time scheduling, scheduler must support preemptive, priority - \uf06eFor hard real -time must also provide ability to meet deadlines \uf06eProcesses have new characteristics: periodic  ones require CPU at \uf06eVirtualization software schedules multiple guests onto \uf06eCan undo good scheduling algorithm efforts of guests \uf06eA priority is assigned based on the inverse of its period the earlier the deadline, the higher the priority; \uf06eT shares are allocated among all processes in the system \uf06eThis ensures each application will receive N  / T of the total \uf06eAPI provides functions for managing real -time threads \uf06eDefines two scheduling classes for real -time threads : 1.SCHED_FIFO - threads are scheduled using a FCFS strategy with a FIFO queue."
  },
  {
    "subject": "books",
    "text": "There is no time-slicing for threads of equal priority 2.SCHED_RR - similar to SCHED_FIFO except time -slicing occurs for \uf06eDefines two functions for getting and setting scheduling policy: 1.pthread_attr_getsched_policy(pthread_attr_t  *attr, 2.pthread_attr_setsched _policy(pthread_attr_t  *attr, if (pthread_attr_getschedpolicy(&attr, &policy) != 0) if (policy == SCHED_OTHER) printf(\"SCHED_OTHER\\n\"); else if (policy == SCHED_RR) printf(\"SCHED_RR\\n\"); else if (policy == SCHED_FIFO) printf(\"SCHED_FIFO\\n\"); /* set the scheduling policy - FIFO, RR, or OTHER */ if (pthread_attr_setschedpolicy(&attr, SCHED_FIFO) != 0) /* Each thread will begin control in this function */ \uf06cTwo priority ranges: time- sharing and real -time \uf06cReal- time range from 0 to 99 and nice value from 100 to 140 \uf06cMap into  global priority with numerically lower values indicating higher \uf06cTask run -able as long as time left in time slice ( active ) \uf06cIf no time left ( expired ), not run- able until all other tasks use their slices \uf06cAll run -able tasks tracked in per -CPU runqueue data structure \uf06cWorked well, but poor response times for interactive processes \uf06cScheduler picks highest priority task in highest scheduling class \uf06cRather than quantum based on fixed time allotments, based on proportion of CPU \uf06c2 scheduling classes included, others can be added \uf06eQuantum calculated based on nice value from -20 to +19 \uf06cCalculates target latency \u2013 interval of time during which task should run at least \uf06cTarget latency can increase if say number of active tasks increases \uf06eCFS scheduler maintains per task virtual run time in variable vruntime \uf06cAssociated with decay factor based on priority of task \u2013 lower priority is higher \uf06cNormal default priority yields virtual run time = actual run time \uf06eTo decide next task to run, scheduler picks task with lowest virtual run time \uf06eReal-time plus normal map into global priority scheme \uf06eWindows uses priority -based preemptive scheduling \uf06eThread runs until (1) blocks, (2) uses time slice, (3) \uf06eWin32 API identifies several priority classes to which a process can belong ABOVE_NORMAL_PRIORITY_CLASS,NORMAL_PRIORITY_CLASS, BELOW_NORMAL_PRIORITY_CLASS, IDLE_PRIORITY_CLASS \uf06eA thread within a given priority class has a relative priority \uf06cTIME_CRITICAL, HIGHEST, ABOVE_NORMAL, NORMAL, BELOW_NORMAL, LOWEST, IDLE \uf06ePriority class and relative priority combine to give numeric priority \uf06eIf quantum expires, priority lowered, but never below base \uf06eIf wait occurs, priority boosted depending on what was waited for \uf06cApplications create and manage threads independent of kernel \uf06cUMS schedulers come from programming language libraries like \uf06eScheduler converts class -specific priorities into a per -thread global \uf06cRuns until (1) blocks, (2) uses time slice, (3) preempted by \uf06cMultiple threads at same priority selected via RR \uf06cTakes a particular predetermined workload and defines the \uf06eFor each algorithm, calculate minimum average waiting time \uf06eSimple and fast, but requires exact numbers for input, applies only to \uf06eDescribes the arrival of processes, and CPU and I/O bursts \uf06cComputes average throughput, utilization, waiting time, etc \uf06eComputer system described as network of servers, each with queue of waiting processes \uf06cComputes utilization, average queue length, average wait time, etc \uf06eLittle \u2019s law \u2013 in steady state, processes leaving queue must equal \uf06cValid for any scheduling algorithm and arrival distribution \uf06eFor example, if on average 7 processes arrive per second, and normally 14 processes in queue, then average wait time per process = 2 seconds \uf06cGather statistics  indicating algorithm performance \uf034Random number generator according to probabilities \uf034Distributions defined mathematically or empirically \uf034Trace tapes record sequences of real events in real systems \uf06e Just implement new scheduler and test in real systems \uf06e Most flexible schedulers can be modified per -site or per -system Silberschatz, Galvin and Gagne \u00a92013 Operating System Concepts \u2013 9th Edition."
  },
  {
    "subject": "books",
    "text": "Silberschatz, Galvin and Gagne \u00a92013 Operating System Concepts \u2013 9th Edition \uf06eTo develop a description of deadlocks, which prevent sets of concurrent processes from completing their tasks \uf06eTo present a number of different methods for preventing or avoiding deadlocks in a computer system \uf06eMutual exclusion :  only one process at a time can use a \uf06eHold and wait :  a process holding at least one resource is waiting to acquire additional resources held by other \uf06eNo preemption :  a resource can be released only voluntarily by the process holding it, after that process has completed its task \uf06eCircular wait :  there exists a set { P0, P1, \u2026, Pn} of waiting processes such that P0 is waiting for a resource that is held by P1, P1 is waiting for a resource that is held by P2, \u2026, Pn\u20131 is waiting for a resource that is held by Pn, and Pn is waiting Deadlock can arise if four conditions hold simultaneously."
  },
  {
    "subject": "books",
    "text": "\uf06cLow resource utilization; starvation possible Restrain the ways request can be made \uf06cIf a process that is holding some resources requests another resource that cannot be immediately allocated to it, then all resources currently being held are released \uf06cPreempted resources are added to the list of resources for which the process is waiting \uf06cProcess will be restarted only when it can regain its old resources, as well as the new ones that it is requesting \uf06eCircular Wait  \u2013 impose a total ordering of all resource types, and require that each process requests resources in an increasing order of enumeration void transaction(Account from, Account to, double amount) Transactions 1 and 2 execute concurrently."
  },
  {
    "subject": "books",
    "text": "Transaction  1 transfers $25 from account A to account B, and Transaction 2 transfers $50 from account \uf06eSimplest and most useful model requires that each process declare the maximum number of resources of each type \uf06eThe deadlock -avoidance algorithm dynamically examines the resource-allocation state to ensure that there can never be a circular -wait condition \uf06eResource-allocation state  is defined by the number of available and allocated resources, and the maximum demands of the processes  Requires that the system has some additional a priori information \uf06eWhen a process requests an available resource, system must decide if immediate allocation leaves the system in a safe state \uf06eSystem is in safe state if there exists a sequence < P1, P2, \u2026, Pn> of ALL the  processes  in the systems such that  for each Pi, the resources that Pi can still request can be satisfied by currently available resources + resources held by all the Pj, with  j < I \uf06cIf Pi resource needs are not immediately available, then Pi can \uf06cWhen Pj is finished, Pi can obtain needed resources, execute, \uf06cWhen Pi terminates, Pi +1 can obtain its needed resources, and \uf06eIf a system is in unsafe state \u21d2 possibility of deadlock \uf06eAvoidance \u21d2 ensure that a system will never enter an \uf06eClaim edge Pi \u2192 Rj indicated that process Pj may request \uf06eClaim edge converts to request edge when a process requests \uf06eRequest edge converted to an assignment edge when the  resource is allocated to the process \uf06eWhen a resource is released by a process, assignment edge reconverts to a claim edge \uf06eResources must be claimed a priori  in the system \uf06eThe request can be granted only if converting the request edge to an assignment edge does not result in the formation of a cycle in the resource allocation graph \uf06eWhen a process requests a resource it may have to wait \uf06eWhen a process gets all its resources it must return them in a \uf06eAvailable :  Vector of length m."
  },
  {
    "subject": "books",
    "text": "If available [ j] = k, there are k \uf06eMax: n x m  matrix.  If Max [i,j] = k, then process Pi may request at \uf06eAllocation:  n x  m matrix.  If Allocation[ i,j] = k then Pi is currently \uf06eNeed :  n x m matrix."
  },
  {
    "subject": "books",
    "text": "4. If Finish [i] == true for all i, then the system is in a safe state Requesti = request vector for process Pi.  If Requesti [j] = k then 1. If Requesti \u2264 Needi go to step 2.  Otherwise, raise error condition, 2."
  },
  {
    "subject": "books",
    "text": "If Requesti \u2264 Available, go to step 3.  Otherwise Pi  must wait, 3. Pretend to allocate requested resources to Pi by modifying the \uf06cIf unsafe \u21d2 Pi must wait, and the old resource-allocation state A (10 instances),  B (5instances), and C  (7 instances) \uf06eThe content of the matrix Need  is defined to be Max \u2013 Allocation \uf06eThe system is in a safe state since the sequence < P1, P3, P4, P2, P0> \uf06eCheck that Request \u2264 Available (that is, (1,0,2) \u2264  (3,3,2) \u21d2 true \uf06eExecuting safety algorithm shows that sequence < P1, P3, P4, P0, P2> \uf06ePeriodically invoke an algorithm that searches for a cycle in the graph."
  },
  {
    "subject": "books",
    "text": "If there is a cycle, there exists a deadlock \uf06eAn algorithm to detect a cycle in a graph requires an order of  n2 operations, where n is the number of vertices in the graph Resource-Allocation Graph Corresponding wait -for graph \uf06eAvailable :  A vector of length m indicates the number of \uf06eAllocation:   An n x m matrix defines the number of resources \uf06eRequest :  An n x m matrix indicates the current request  of each process."
  },
  {
    "subject": "books",
    "text": "If Request [i][j] = k, then process  Pi is 1. Let Work  and Finish be vectors of length m and n, respectively 4. If Finish[i] == false , for some i, 1 \u2264 i \u2264  n, then the system is in deadlock state."
  },
  {
    "subject": "books",
    "text": "Moreover, if Finish[i ] == false, then Pi is Algorithm requires an order of O( m x n2) operations to detect \uf06eFive processes P0 through P4; three resource types A (7 instances), B (2 instances), and C  (6 instances) \uf06eSequence < P0, P2, P3, P1, P4> will result in Finish[i] = true for all i \uf06cCan reclaim resources held by process P0, but insufficient \uf06cDeadlock exists, consisting of processes P1,  P2, P3, and P4 \uf06eIf detection algorithm is invoked arbitrarily, there may be many cycles in the resource graph and so we would not be able to tell which of the many deadlocked processes \u201ccaused\u201d the \uf06eAbort one process at a time until the deadlock cycle is eliminated 2.How long process has computed, and how much longer to completion \uf06eRollback \u2013 return to some safe state, restart process for that \uf06eStarvation  \u2013  same process may always be picked as victim, Silberschatz, Galvin and Gagne \u00a92013 Operating System Concepts \u2013 9th Edition."
  }
]